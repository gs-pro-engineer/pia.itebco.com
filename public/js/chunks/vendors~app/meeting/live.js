(window["webpackJsonp"] = window["webpackJsonp"] || []).push([["vendors~app/meeting/live"],{

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

/* global fetch, btoa, Headers */
const core = __webpack_require__(/*! ./core */ "./node_modules/bent/src/core.js")

class StatusError extends Error {
  constructor (res, ...params) {
    super(...params)

    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, StatusError)
    }

    this.name = 'StatusError'
    this.message = res.statusMessage
    this.statusCode = res.status
    this.res = res
    this.json = res.json.bind(res)
    this.text = res.text.bind(res)
    this.arrayBuffer = res.arrayBuffer.bind(res)
    let buffer
    const get = () => {
      if (!buffer) buffer = this.arrayBuffer()
      return buffer
    }
    Object.defineProperty(this, 'responseBody', { get })
    // match Node.js headers object
    this.headers = {}
    for (const [key, value] of res.headers.entries()) {
      this.headers[key.toLowerCase()] = value
    }
  }
}

const mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {
  _url = baseurl + (_url || '')
  let parsed = new URL(_url)

  if (!headers) headers = {}
  if (parsed.username) {
    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password)
    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search)
  }
  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {
    throw new Error(`Unknown protocol, ${parsed.protocol}`)
  }

  if (body) {
    if (body instanceof ArrayBuffer ||
      ArrayBuffer.isView(body) ||
      typeof body === 'string'
    ) {
      // noop
    } else if (typeof body === 'object') {
      body = JSON.stringify(body)
      headers['Content-Type'] = 'application/json'
    } else {
      throw new Error('Unknown body type.')
    }
  }

  _headers = new Headers({ ...(headers || {}), ..._headers })

  const resp = await fetch(parsed, { method, headers: _headers, body })
  resp.statusCode = resp.status

  if (!statusCodes.has(resp.status)) {
    throw new StatusError(resp)
  }

  if (encoding === 'json') return resp.json()
  else if (encoding === 'buffer') return resp.arrayBuffer()
  else if (encoding === 'string') return resp.text()
  else return resp
}

module.exports = core(mkrequest)


/***/ }),

/***/ "./node_modules/bent/src/core.js":
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

const encodings = new Set(['json', 'buffer', 'string'])

module.exports = mkrequest => (...args) => {
  const statusCodes = new Set()
  let method
  let encoding
  let headers
  let baseurl = ''

  args.forEach(arg => {
    if (typeof arg === 'string') {
      if (arg.toUpperCase() === arg) {
        if (method) {
          const msg = `Can't set method to ${arg}, already set to ${method}.`
          throw new Error(msg)
        } else {
          method = arg
        }
      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {
        baseurl = arg
      } else {
        if (encodings.has(arg)) {
          encoding = arg
        } else {
          throw new Error(`Unknown encoding, ${arg}`)
        }
      }
    } else if (typeof arg === 'number') {
      statusCodes.add(arg)
    } else if (typeof arg === 'object') {
      if (Array.isArray(arg) || arg instanceof Set) {
        arg.forEach(code => statusCodes.add(code))
      } else {
        if (headers) {
          throw new Error('Cannot set headers twice.')
        }
        headers = arg
      }
    } else {
      throw new Error(`Unknown type: ${typeof arg}`)
    }
  })

  if (!method) method = 'GET'
  if (statusCodes.size === 0) {
    statusCodes.add(200)
  }

  return mkrequest(statusCodes, method, encoding, headers, baseurl)
}


/***/ }),

/***/ "./node_modules/cookie/index.js":
/*!**************************************!*\
  !*** ./node_modules/cookie/index.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/*!
 * cookie
 * Copyright(c) 2012-2014 Roman Shtylman
 * Copyright(c) 2015 Douglas Christopher Wilson
 * MIT Licensed
 */



/**
 * Module exports.
 * @public
 */

exports.parse = parse;
exports.serialize = serialize;

/**
 * Module variables.
 * @private
 */

var decode = decodeURIComponent;
var encode = encodeURIComponent;
var pairSplitRegExp = /; */;

/**
 * RegExp to match field-content in RFC 7230 sec 3.2
 *
 * field-content = field-vchar [ 1*( SP / HTAB ) field-vchar ]
 * field-vchar   = VCHAR / obs-text
 * obs-text      = %x80-FF
 */

var fieldContentRegExp = /^[\u0009\u0020-\u007e\u0080-\u00ff]+$/;

/**
 * Parse a cookie header.
 *
 * Parse the given cookie header string into an object
 * The object has the various cookies as keys(names) => values
 *
 * @param {string} str
 * @param {object} [options]
 * @return {object}
 * @public
 */

function parse(str, options) {
  if (typeof str !== 'string') {
    throw new TypeError('argument str must be a string');
  }

  var obj = {}
  var opt = options || {};
  var pairs = str.split(pairSplitRegExp);
  var dec = opt.decode || decode;

  for (var i = 0; i < pairs.length; i++) {
    var pair = pairs[i];
    var eq_idx = pair.indexOf('=');

    // skip things that don't look like key=value
    if (eq_idx < 0) {
      continue;
    }

    var key = pair.substr(0, eq_idx).trim()
    var val = pair.substr(++eq_idx, pair.length).trim();

    // quoted values
    if ('"' == val[0]) {
      val = val.slice(1, -1);
    }

    // only assign once
    if (undefined == obj[key]) {
      obj[key] = tryDecode(val, dec);
    }
  }

  return obj;
}

/**
 * Serialize data into a cookie header.
 *
 * Serialize the a name value pair into a cookie string suitable for
 * http headers. An optional options object specified cookie parameters.
 *
 * serialize('foo', 'bar', { httpOnly: true })
 *   => "foo=bar; httpOnly"
 *
 * @param {string} name
 * @param {string} val
 * @param {object} [options]
 * @return {string}
 * @public
 */

function serialize(name, val, options) {
  var opt = options || {};
  var enc = opt.encode || encode;

  if (typeof enc !== 'function') {
    throw new TypeError('option encode is invalid');
  }

  if (!fieldContentRegExp.test(name)) {
    throw new TypeError('argument name is invalid');
  }

  var value = enc(val);

  if (value && !fieldContentRegExp.test(value)) {
    throw new TypeError('argument val is invalid');
  }

  var str = name + '=' + value;

  if (null != opt.maxAge) {
    var maxAge = opt.maxAge - 0;

    if (isNaN(maxAge) || !isFinite(maxAge)) {
      throw new TypeError('option maxAge is invalid')
    }

    str += '; Max-Age=' + Math.floor(maxAge);
  }

  if (opt.domain) {
    if (!fieldContentRegExp.test(opt.domain)) {
      throw new TypeError('option domain is invalid');
    }

    str += '; Domain=' + opt.domain;
  }

  if (opt.path) {
    if (!fieldContentRegExp.test(opt.path)) {
      throw new TypeError('option path is invalid');
    }

    str += '; Path=' + opt.path;
  }

  if (opt.expires) {
    if (typeof opt.expires.toUTCString !== 'function') {
      throw new TypeError('option expires is invalid');
    }

    str += '; Expires=' + opt.expires.toUTCString();
  }

  if (opt.httpOnly) {
    str += '; HttpOnly';
  }

  if (opt.secure) {
    str += '; Secure';
  }

  if (opt.sameSite) {
    var sameSite = typeof opt.sameSite === 'string'
      ? opt.sameSite.toLowerCase() : opt.sameSite;

    switch (sameSite) {
      case true:
        str += '; SameSite=Strict';
        break;
      case 'lax':
        str += '; SameSite=Lax';
        break;
      case 'strict':
        str += '; SameSite=Strict';
        break;
      case 'none':
        str += '; SameSite=None';
        break;
      default:
        throw new TypeError('option sameSite is invalid');
    }
  }

  return str;
}

/**
 * Try decoding a string using a decoding function.
 *
 * @param {string} str
 * @param {function} decode
 * @private
 */

function tryDecode(str, decode) {
  try {
    return decode(str);
  } catch (e) {
    return str;
  }
}


/***/ }),

/***/ "./node_modules/core-util-is/lib/util.js":
/*!***********************************************!*\
  !*** ./node_modules/core-util-is/lib/util.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// NOTE: These type checking functions intentionally don't use `instanceof`
// because it is fragile and can be easily faked with `Object.create()`.

function isArray(arg) {
  if (Array.isArray) {
    return Array.isArray(arg);
  }
  return objectToString(arg) === '[object Array]';
}
exports.isArray = isArray;

function isBoolean(arg) {
  return typeof arg === 'boolean';
}
exports.isBoolean = isBoolean;

function isNull(arg) {
  return arg === null;
}
exports.isNull = isNull;

function isNullOrUndefined(arg) {
  return arg == null;
}
exports.isNullOrUndefined = isNullOrUndefined;

function isNumber(arg) {
  return typeof arg === 'number';
}
exports.isNumber = isNumber;

function isString(arg) {
  return typeof arg === 'string';
}
exports.isString = isString;

function isSymbol(arg) {
  return typeof arg === 'symbol';
}
exports.isSymbol = isSymbol;

function isUndefined(arg) {
  return arg === void 0;
}
exports.isUndefined = isUndefined;

function isRegExp(re) {
  return objectToString(re) === '[object RegExp]';
}
exports.isRegExp = isRegExp;

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}
exports.isObject = isObject;

function isDate(d) {
  return objectToString(d) === '[object Date]';
}
exports.isDate = isDate;

function isError(e) {
  return (objectToString(e) === '[object Error]' || e instanceof Error);
}
exports.isError = isError;

function isFunction(arg) {
  return typeof arg === 'function';
}
exports.isFunction = isFunction;

function isPrimitive(arg) {
  return arg === null ||
         typeof arg === 'boolean' ||
         typeof arg === 'number' ||
         typeof arg === 'string' ||
         typeof arg === 'symbol' ||  // ES6 symbol
         typeof arg === 'undefined';
}
exports.isPrimitive = isPrimitive;

exports.isBuffer = __webpack_require__(/*! buffer */ "./node_modules/buffer/index.js").Buffer.isBuffer;

function objectToString(o) {
  return Object.prototype.toString.call(o);
}


/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.



var R = typeof Reflect === 'object' ? Reflect : null
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  }

var ReflectOwnKeys
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
}

function EventEmitter() {
  EventEmitter.init.call(this);
}
module.exports = EventEmitter;
module.exports.once = once;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

function checkListener(listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
}

Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function _getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return _getMaxListeners(this);
};

EventEmitter.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  checkListener(listener);

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = _getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    if (arguments.length === 0)
      return this.listener.call(this.target);
    return this.listener.apply(this.target, arguments);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  checkListener(listener);
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      checkListener(listener);
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      checkListener(listener);

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function once(emitter, name) {
  return new Promise(function (resolve, reject) {
    function errorListener(err) {
      emitter.removeListener(name, resolver);
      reject(err);
    }

    function resolver() {
      if (typeof emitter.removeListener === 'function') {
        emitter.removeListener('error', errorListener);
      }
      resolve([].slice.call(arguments));
    };

    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
    if (name !== 'error') {
      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
    }
  });
}

function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
  if (typeof emitter.on === 'function') {
    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
  }
}

function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
  if (typeof emitter.on === 'function') {
    if (flags.once) {
      emitter.once(name, listener);
    } else {
      emitter.on(name, listener);
    }
  } else if (typeof emitter.addEventListener === 'function') {
    // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
      // IE does not have builtin `{ once: true }` support so we
      // have to do it manually.
      if (flags.once) {
        emitter.removeEventListener(name, wrapListener);
      }
      listener(arg);
    });
  } else {
    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
  }
}


/***/ }),

/***/ "./node_modules/inherits/inherits_browser.js":
/*!***************************************************!*\
  !*** ./node_modules/inherits/inherits_browser.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      ctor.prototype = Object.create(superCtor.prototype, {
        constructor: {
          value: ctor,
          enumerable: false,
          writable: true,
          configurable: true
        }
      })
    }
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      var TempCtor = function () {}
      TempCtor.prototype = superCtor.prototype
      ctor.prototype = new TempCtor()
      ctor.prototype.constructor = ctor
    }
  }
}


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AudioConfig, AudioStreamFormat, AudioInputStream, PullAudioInputStream, PushAudioInputStream, AudioOutputStream, PullAudioOutputStream, PushAudioOutputStream, CancellationReason, PullAudioInputStreamCallback, PushAudioOutputStreamCallback, KeywordRecognitionModel, SessionEventArgs, RecognitionEventArgs, OutputFormat, IntentRecognitionEventArgs, RecognitionResult, SpeechRecognitionResult, IntentRecognitionResult, LanguageUnderstandingModel, SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs, SpeechRecognitionCanceledEventArgs, TranslationRecognitionEventArgs, TranslationSynthesisEventArgs, TranslationRecognitionResult, TranslationSynthesisResult, ResultReason, SpeechConfig, SpeechConfigImpl, SpeechTranslationConfig, SpeechTranslationConfigImpl, PropertyCollection, PropertyId, Recognizer, SpeechRecognizer, IntentRecognizer, VoiceProfileType, TranslationRecognizer, Translations, NoMatchReason, NoMatchDetails, TranslationRecognitionCanceledEventArgs, IntentRecognitionCanceledEventArgs, CancellationDetailsBase, CancellationDetails, CancellationErrorCode, ConnectionEventArgs, ServiceEventArgs, Connection, PhraseListGrammar, DialogServiceConfig, BotFrameworkConfig, CustomCommandsConfig, DialogServiceConnector, ActivityReceivedEventArgs, TurnStatusReceivedEventArgs, ServicePropertyChannel, ProfanityOption, BaseAudioPlayer, ConnectionMessageEventArgs, ConnectionMessage, VoiceProfile, VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails, VoiceProfileResult, VoiceProfileCancellationDetails, VoiceProfilePhraseResult, VoiceProfileClient, SpeakerRecognizer, SpeakerIdentificationModel, SpeakerVerificationModel, AutoDetectSourceLanguageConfig, AutoDetectSourceLanguageResult, SourceLanguageConfig, SpeakerRecognitionResult, SpeakerRecognitionResultType, SpeakerRecognitionCancellationDetails, Conversation, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, ParticipantChangedReason, User, SpeechSynthesisOutputFormat, SpeechSynthesizer, SpeechSynthesisResult, SpeechSynthesisEventArgs, SpeechSynthesisWordBoundaryEventArgs, SpeechSynthesisBookmarkEventArgs, SpeechSynthesisVisemeEventArgs, SpeakerAudioDestination, ConversationTranscriptionCanceledEventArgs, PronunciationAssessmentGradingSystem, PronunciationAssessmentGranularity, PronunciationAssessmentConfig, PronunciationAssessmentResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _src_common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./src/common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./src/sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AudioConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamFormat", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AudioStreamFormat"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioInputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AudioInputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PullAudioInputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioInputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PushAudioInputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioOutputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AudioOutputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioOutputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PullAudioOutputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStream", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PushAudioOutputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationReason", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStreamCallback", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PullAudioInputStreamCallback"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStreamCallback", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PushAudioOutputStreamCallback"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "KeywordRecognitionModel", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["KeywordRecognitionModel"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SessionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SessionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OutputFormat", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["IntentRecognitionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechRecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["IntentRecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "LanguageUnderstandingModel", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["LanguageUnderstandingModel"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechRecognitionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranscriptionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionCanceledEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechRecognitionCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationRecognitionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationSynthesisEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationRecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationSynthesisResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ResultReason", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ResultReason"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechConfigImpl", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechConfigImpl"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechTranslationConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfigImpl", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechTranslationConfigImpl"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PropertyCollection", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PropertyId", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Recognizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Recognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechRecognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["IntentRecognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileType", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationRecognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Translations", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Translations"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "NoMatchReason", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["NoMatchReason"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "NoMatchDetails", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["NoMatchDetails"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionCanceledEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationRecognitionCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionCanceledEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["IntentRecognitionCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationDetailsBase", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationDetailsBase"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationDetails", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationDetails"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationErrorCode", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConnectionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServiceEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Connection", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Connection"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PhraseListGrammar", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PhraseListGrammar"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BotFrameworkConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["BotFrameworkConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CustomCommandsConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CustomCommandsConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConnector", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConnector"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ActivityReceivedEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ActivityReceivedEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TurnStatusReceivedEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["TurnStatusReceivedEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServicePropertyChannel", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ServicePropertyChannel"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ProfanityOption", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ProfanityOption"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BaseAudioPlayer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["BaseAudioPlayer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConnectionMessageEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessage", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConnectionMessage"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfile", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfile"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileEnrollmentResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentCancellationDetails", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileEnrollmentCancellationDetails"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileCancellationDetails", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileCancellationDetails"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfilePhraseResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfilePhraseResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileClient", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["VoiceProfileClient"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerRecognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerIdentificationModel", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerIdentificationModel"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerVerificationModel", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerVerificationModel"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AutoDetectSourceLanguageConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["AutoDetectSourceLanguageResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SourceLanguageConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SourceLanguageConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerRecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResultType", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerRecognitionResultType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionCancellationDetails", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerRecognitionCancellationDetails"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Conversation", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Conversation"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationExpirationEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationExpirationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationParticipantsChangedEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationParticipantsChangedEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationCanceledEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranslationCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranslationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranslationResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslator", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranslator"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriber", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranscriber"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Participant", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Participant"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantChangedReason", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ParticipantChangedReason"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "User", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["User"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisOutputFormat", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisOutputFormat"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesizer", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisWordBoundaryEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisWordBoundaryEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisBookmarkEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisBookmarkEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisVisemeEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisVisemeEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerAudioDestination", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerAudioDestination"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionCanceledEventArgs", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["ConversationTranscriptionCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGradingSystem", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PronunciationAssessmentGradingSystem"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGranularity", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PronunciationAssessmentGranularity"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentConfig", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PronunciationAssessmentConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentResult", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PronunciationAssessmentResult"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


// Common.Storage.SetLocalStorage(new Common.Browser.LocalStorage());
// Common.Storage.SetSessionStorage(new Common.Browser.SessionStorage());
_src_common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.attachListener(new _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ConsoleLoggingListener"]());
// Speech SDK API


//# sourceMappingURL=microsoft.cognitiveservices.speech.sdk.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js ***!
  \*************************************************************************************************************/
/*! exports provided: CertCheckAgent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(process, Buffer) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CertCheckAgent", function() { return CertCheckAgent; });
/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tls */ 4);
/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(tls__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var url_parse__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! url-parse */ "./node_modules/url-parse/index.js");
/* harmony import */ var url_parse__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(url_parse__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../external/ocsp/ocsp */ 5);
/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! agent-base */ 6);
/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(agent_base__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! async-disk-cache */ 7);
/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(async_disk_cache__WEBPACK_IMPORTED_MODULE_5__);
/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! https-proxy-agent */ 8);
/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(https_proxy_agent__WEBPACK_IMPORTED_MODULE_6__);
/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! net */ 9);
/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(net__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _common_OCSPEvents__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common/OCSPEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};





// @ts-ignore




class CertCheckAgent {
    constructor(proxyInfo) {
        if (!!proxyInfo) {
            this.privProxyInfo = proxyInfo;
        }
        // Initialize this here to allow tests to set the env variable before the cache is constructed.
        if (!CertCheckAgent.privDiskCache) {
            CertCheckAgent.privDiskCache = new async_disk_cache__WEBPACK_IMPORTED_MODULE_5___default.a("microsoft-cognitiveservices-speech-sdk-cache", { supportBuffer: true, location: (typeof process !== "undefined" && !!process.env.SPEECH_OCSP_CACHE_ROOT) ? process.env.SPEECH_OCSP_CACHE_ROOT : undefined });
        }
    }
    // Test hook to force the disk cache to be recreated.
    static forceReinitDiskCache() {
        CertCheckAgent.privDiskCache = undefined;
        CertCheckAgent.privMemCache = {};
    }
    GetAgent(disableStapling) {
        const agent = new agent_base__WEBPACK_IMPORTED_MODULE_4___default.a.Agent(this.CreateConnection);
        if (this.privProxyInfo !== undefined &&
            this.privProxyInfo.HostName !== undefined &&
            this.privProxyInfo.Port > 0) {
            const proxyName = "privProxyInfo";
            agent[proxyName] = this.privProxyInfo;
        }
        return agent;
    }
    static GetProxyAgent(proxyInfo) {
        const httpProxyOptions = {
            host: proxyInfo.HostName,
            port: proxyInfo.Port,
        };
        if (!!proxyInfo.UserName) {
            httpProxyOptions.headers = {
                "Proxy-Authentication": "Basic " + new Buffer(proxyInfo.UserName + ":" + (proxyInfo.Password === undefined) ? "" : proxyInfo.Password).toString("base64"),
            };
        }
        else {
            httpProxyOptions.headers = {};
        }
        httpProxyOptions.headers.requestOCSP = "true";
        const httpProxyAgent = new https_proxy_agent__WEBPACK_IMPORTED_MODULE_6___default.a(httpProxyOptions);
        return httpProxyAgent;
    }
    static OCSPCheck(socketPromise, proxyInfo) {
        return __awaiter(this, void 0, void 0, function* () {
            let ocspRequest;
            let stapling;
            let resolved = false;
            const socket = yield socketPromise;
            socket.cork();
            const tlsSocket = socket;
            return new Promise((resolve, reject) => {
                socket.on("OCSPResponse", (data) => {
                    if (!!data) {
                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPStapleReceivedEvent"]());
                        stapling = data;
                    }
                });
                socket.on("error", (error) => {
                    if (!resolved) {
                        resolved = true;
                        socket.destroy();
                        reject(error);
                    }
                });
                tlsSocket.on("secure", () => __awaiter(this, void 0, void 0, function* () {
                    const peer = tlsSocket.getPeerCertificate(true);
                    try {
                        const issuer = yield this.GetIssuer(peer);
                        // We always need a request to verify the response.
                        ocspRequest = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["request"].generate(peer.raw, issuer.raw);
                        // Do we have a result for this certificate in our memory cache?
                        const sig = ocspRequest.id.toString("hex");
                        // Stapled response trumps cached response.
                        if (!stapling) {
                            const cacheEntry = yield CertCheckAgent.GetResponseFromCache(sig, ocspRequest, proxyInfo);
                            stapling = cacheEntry;
                        }
                        yield this.VerifyOCSPResponse(stapling, ocspRequest, proxyInfo);
                        socket.uncork();
                        resolved = true;
                        resolve(socket);
                    }
                    catch (e) {
                        socket.destroy();
                        resolved = true;
                        reject(e);
                    }
                }));
            });
        });
    }
    static GetIssuer(peer) {
        if (peer.issuerCertificate) {
            return Promise.resolve(peer.issuerCertificate);
        }
        return new Promise((resolve, reject) => {
            const ocspAgent = new _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["Agent"]({});
            ocspAgent.fetchIssuer(peer, null, (error, value) => {
                if (!!error) {
                    reject(error);
                    return;
                }
                resolve(value);
            });
        });
    }
    static GetResponseFromCache(signature, ocspRequest, proxyInfo) {
        return __awaiter(this, void 0, void 0, function* () {
            let cachedResponse = CertCheckAgent.privMemCache[signature];
            if (!!cachedResponse) {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPMemoryCacheHitEvent"](signature));
            }
            // Do we have a result for this certificate on disk in %TMP%?
            if (!cachedResponse) {
                try {
                    const diskCacheResponse = yield CertCheckAgent.privDiskCache.get(signature);
                    if (!!diskCacheResponse.isCached) {
                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPDiskCacheHitEvent"](signature));
                        CertCheckAgent.StoreMemoryCacheEntry(signature, diskCacheResponse.value);
                        cachedResponse = diskCacheResponse.value;
                    }
                }
                catch (error) {
                    cachedResponse = null;
                }
            }
            if (!cachedResponse) {
                return cachedResponse;
            }
            try {
                const cachedOcspResponse = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["utils"].parseResponse(cachedResponse);
                const tbsData = cachedOcspResponse.value.tbsResponseData;
                if (tbsData.responses.length < 1) {
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheFetchErrorEvent"](signature, "Not enough data in cached response"));
                    return;
                }
                const cachedStartTime = tbsData.responses[0].thisUpdate;
                const cachedNextTime = tbsData.responses[0].nextUpdate;
                if (cachedNextTime < (Date.now() + this.testTimeOffset - 60000)) {
                    // Cached entry has expired.
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheEntryExpiredEvent"](signature, cachedNextTime));
                    cachedResponse = null;
                }
                else {
                    // If we're within one day of the next update, or 50% of the way through the validity period,
                    // background an update to the cache.
                    const minUpdate = Math.min(24 * 60 * 60 * 1000, (cachedNextTime - cachedStartTime) / 2);
                    if ((cachedNextTime - (Date.now() + this.testTimeOffset)) < minUpdate) {
                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheEntryNeedsRefreshEvent"](signature, cachedStartTime, cachedNextTime));
                        this.UpdateCache(ocspRequest, proxyInfo).catch((error) => {
                            // Well, not much we can do here.
                            this.onEvent(new _common_OCSPEvents__WEBPACK_IMPORTED_MODULE_8__["OCSPCacheUpdateErrorEvent"](signature, error.toString()));
                        });
                    }
                    else {
                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheHitEvent"](signature, cachedStartTime, cachedNextTime));
                    }
                }
            }
            catch (error) {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheFetchErrorEvent"](signature, error));
                cachedResponse = null;
            }
            if (!cachedResponse) {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheMissEvent"](signature));
            }
            return cachedResponse;
        });
    }
    static VerifyOCSPResponse(cacheValue, ocspRequest, proxyInfo) {
        return __awaiter(this, void 0, void 0, function* () {
            let ocspResponse = cacheValue;
            const sig = ocspRequest.certID.toString("hex");
            // Do we have a valid response?
            if (!ocspResponse) {
                ocspResponse = yield CertCheckAgent.GetOCSPResponse(ocspRequest, proxyInfo);
            }
            return new Promise((resolve, reject) => {
                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["verify"]({ request: ocspRequest, response: ocspResponse }, (error, result) => {
                    if (!!error) {
                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPVerificationFailedEvent"](ocspRequest.id.toString("hex"), error));
                        // Bad Cached Value? One more try without the cache.
                        if (!!cacheValue) {
                            this.VerifyOCSPResponse(null, ocspRequest, proxyInfo).then(() => {
                                resolve();
                            }, (error) => {
                                reject(error);
                            });
                        }
                        else {
                            reject(error);
                        }
                    }
                    else {
                        if (!cacheValue) {
                            CertCheckAgent.StoreCacheEntry(ocspRequest.id.toString("hex"), ocspResponse);
                        }
                        resolve();
                    }
                });
            });
        });
    }
    static UpdateCache(req, proxyInfo) {
        return __awaiter(this, void 0, void 0, function* () {
            const signature = req.id.toString("hex");
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheUpdateNeededEvent"](signature));
            const rawResponse = yield this.GetOCSPResponse(req, proxyInfo);
            this.StoreCacheEntry(signature, rawResponse);
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPCacheUpdatehCompleteEvent"](req.id.toString("hex")));
        });
    }
    static StoreCacheEntry(sig, rawResponse) {
        this.StoreMemoryCacheEntry(sig, rawResponse);
        this.StoreDiskCacheEntry(sig, rawResponse);
    }
    static StoreMemoryCacheEntry(sig, rawResponse) {
        this.privMemCache[sig] = rawResponse;
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPMemoryCacheStoreEvent"](sig));
    }
    static StoreDiskCacheEntry(sig, rawResponse) {
        this.privDiskCache.set(sig, rawResponse).then(() => {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPDiskCacheStoreEvent"](sig));
        });
    }
    static GetOCSPResponse(req, proxyInfo) {
        const ocspMethod = "1.3.6.1.5.5.7.48.1";
        let options = {};
        if (!!proxyInfo) {
            const agent = CertCheckAgent.GetProxyAgent(proxyInfo);
            options.agent = agent;
        }
        return new Promise((resolve, reject) => {
            _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["utils"].getAuthorityInfo(req.cert, ocspMethod, (error, uri) => {
                if (error) {
                    reject(error);
                    return;
                }
                const parsedUri = url_parse__WEBPACK_IMPORTED_MODULE_1___default.a(uri);
                parsedUri.path = parsedUri.pathname;
                options = Object.assign(Object.assign({}, options), parsedUri);
                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_2__["utils"].getResponse(options, req.data, (error, raw) => {
                    if (error) {
                        reject(error);
                        return;
                    }
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__["OCSPResponseRetrievedEvent"](req.certID.toString("hex")));
                    resolve(raw);
                });
            });
        });
    }
    CreateConnection(request, options) {
        const enableOCSP = (typeof process !== "undefined" && process.env.NODE_TLS_REJECT_UNAUTHORIZED !== "0" && process.env.SPEECH_CONDUCT_OCSP_CHECK !== "0") && options.secureEndpoint;
        let socketPromise;
        options = Object.assign(Object.assign({}, options), {
            requestOCSP: !CertCheckAgent.forceDisableOCSPStapling,
            servername: options.host
        });
        if (!!this.privProxyInfo) {
            const httpProxyAgent = CertCheckAgent.GetProxyAgent(this.privProxyInfo);
            const baseAgent = httpProxyAgent;
            socketPromise = new Promise((resolve, reject) => {
                baseAgent.callback(request, options, (error, socket) => {
                    if (!!error) {
                        reject(error);
                    }
                    else {
                        resolve(socket);
                    }
                });
            });
        }
        else {
            if (!!options.secureEndpoint) {
                socketPromise = Promise.resolve(tls__WEBPACK_IMPORTED_MODULE_0__["connect"](options));
            }
            else {
                socketPromise = Promise.resolve(net__WEBPACK_IMPORTED_MODULE_7__["connect"](options));
            }
        }
        if (!!enableOCSP) {
            return CertCheckAgent.OCSPCheck(socketPromise, this.privProxyInfo);
        }
        else {
            return socketPromise;
        }
    }
}
// Test hook to enable forcing expiration / refresh to happen.
CertCheckAgent.testTimeOffset = 0;
// Test hook to disable stapling for cache testing.
CertCheckAgent.forceDisableOCSPStapling = false;
// An in memory cache for recived responses.
CertCheckAgent.privMemCache = {};
CertCheckAgent.onEvent = (event) => {
    _common_Exports__WEBPACK_IMPORTED_MODULE_3__["Events"].instance.onEvent(event);
};

//# sourceMappingURL=CertChecks.js.map

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../process/browser.js */ "./node_modules/process/browser.js"), __webpack_require__(/*! ./../../../../../buffer/index.js */ "./node_modules/buffer/index.js").Buffer))

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js ***!
  \*************************************************************************************************************************/
/*! exports provided: ConsoleLoggingListener */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConsoleLoggingListener", function() { return ConsoleLoggingListener; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ConsoleLoggingListener {
    constructor(logLevelFilter = _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Warning) {
        this.onEvent = (event) => {
            if (event.eventType >= this.privLogLevelFilter) {
                const log = this.toString(event);
                switch (event.eventType) {
                    case _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug:
                        // tslint:disable-next-line:no-console
                        console.debug(log);
                        break;
                    case _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info:
                        // tslint:disable-next-line:no-console
                        console.info(log);
                        break;
                    case _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Warning:
                        // tslint:disable-next-line:no-console
                        console.warn(log);
                        break;
                    case _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Error:
                        // tslint:disable-next-line:no-console
                        console.error(log);
                        break;
                    default:
                        // tslint:disable-next-line:no-console
                        console.log(log);
                        break;
                }
            }
        };
        this.toString = (event) => {
            const logFragments = [
                `${event.EventTime}`,
                `${event.Name}`,
            ];
            for (const prop in event) {
                if (prop && event.hasOwnProperty(prop) &&
                    prop !== "eventTime" && prop !== "eventType" &&
                    prop !== "eventId" && prop !== "name" &&
                    prop !== "constructor") {
                    const value = event[prop];
                    let valueToLog = "<NULL>";
                    if (value !== undefined && value !== null) {
                        if (typeof (value) === "number" || typeof (value) === "string") {
                            valueToLog = value.toString();
                        }
                        else {
                            valueToLog = JSON.stringify(value);
                        }
                    }
                    logFragments.push(`${prop}: ${valueToLog}`);
                }
            }
            return logFragments.join(" | ");
        };
        this.privLogLevelFilter = logLevelFilter;
    }
}

//# sourceMappingURL=ConsoleLoggingListener.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js ***!
  \**********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _ConsoleLoggingListener__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConsoleLoggingListener */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConsoleLoggingListener", function() { return _ConsoleLoggingListener__WEBPACK_IMPORTED_MODULE_0__["ConsoleLoggingListener"]; });

/* harmony import */ var _IRecorder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IRecorder */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js");
/* harmony import */ var _IRecorder__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_IRecorder__WEBPACK_IMPORTED_MODULE_1__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IRecorder__WEBPACK_IMPORTED_MODULE_1__) if(["default","ConsoleLoggingListener"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IRecorder__WEBPACK_IMPORTED_MODULE_1__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./MicAudioSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioWorkletSourceURLPropertyName", function() { return _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__["AudioWorkletSourceURLPropertyName"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MicAudioSource", function() { return _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__["MicAudioSource"]; });

/* harmony import */ var _FileAudioSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FileAudioSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "FileAudioSource", function() { return _FileAudioSource__WEBPACK_IMPORTED_MODULE_3__["FileAudioSource"]; });

/* harmony import */ var _PCMRecorder__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./PCMRecorder */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PcmRecorder", function() { return _PCMRecorder__WEBPACK_IMPORTED_MODULE_4__["PcmRecorder"]; });

/* harmony import */ var _WebsocketConnection__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./WebsocketConnection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "WebsocketConnection", function() { return _WebsocketConnection__WEBPACK_IMPORTED_MODULE_5__["WebsocketConnection"]; });

/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "WebsocketMessageAdapter", function() { return _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_6__["WebsocketMessageAdapter"]; });

/* harmony import */ var _ReplayableAudioNode__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ReplayableAudioNode */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ReplayableAudioNode", function() { return _ReplayableAudioNode__WEBPACK_IMPORTED_MODULE_7__["ReplayableAudioNode"]; });

/* harmony import */ var _ProxyInfo__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ProxyInfo */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ProxyInfo", function() { return _ProxyInfo__WEBPACK_IMPORTED_MODULE_8__["ProxyInfo"]; });

/* harmony import */ var _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RestMessageAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RestRequestType", function() { return _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__["RestRequestType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RestMessageAdapter", function() { return _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__["RestMessageAdapter"]; });

/* harmony import */ var _RestConfigBase__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./RestConfigBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RestConfigBase", function() { return _RestConfigBase__WEBPACK_IMPORTED_MODULE_10__["RestConfigBase"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.












//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js ***!
  \******************************************************************************************************************/
/*! exports provided: FileAudioSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "FileAudioSource", function() { return FileAudioSource; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



class FileAudioSource {
    constructor(file, filename, audioSourceId) {
        this.privStreams = {};
        this.privHeaderEnd = 44;
        this.turnOn = () => {
            if (this.privFilename.lastIndexOf(".wav") !== this.privFilename.length - 4) {
                const errorMsg = this.privFilename + " is not supported. Only WAVE files are allowed at the moment.";
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceErrorEvent"](errorMsg, ""));
                return Promise.reject(errorMsg);
            }
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceInitializingEvent"](this.privId)); // no stream id
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceReadyEvent"](this.privId));
            return;
        };
        this.id = () => {
            return this.privId;
        };
        this.attach = (audioNodeId) => __awaiter(this, void 0, void 0, function* () {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachingEvent"](this.privId, audioNodeId));
            const stream = yield this.upload(audioNodeId);
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachedEvent"](this.privId, audioNodeId));
            return Promise.resolve({
                detach: () => __awaiter(this, void 0, void 0, function* () {
                    stream.readEnded();
                    delete this.privStreams[audioNodeId];
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
                    yield this.turnOff();
                }),
                id: () => {
                    return audioNodeId;
                },
                read: () => {
                    return stream.read();
                },
            });
        });
        this.detach = (audioNodeId) => {
            if (audioNodeId && this.privStreams[audioNodeId]) {
                this.privStreams[audioNodeId].close();
                delete this.privStreams[audioNodeId];
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
            }
        };
        this.turnOff = () => {
            for (const streamId in this.privStreams) {
                if (streamId) {
                    const stream = this.privStreams[streamId];
                    if (stream && !stream.isClosed) {
                        stream.close();
                    }
                }
            }
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceOffEvent"](this.privId)); // no stream now
            return Promise.resolve();
        };
        this.onEvent = (event) => {
            this.privEvents.onEvent(event);
            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(event);
        };
        this.privId = audioSourceId ? audioSourceId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privSource = file;
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && this.privSource instanceof Blob) {
            this.privFilename = file.name;
        }
        else {
            this.privFilename = filename || "unknown.wav";
        }
        // Read the header.
        this.privAudioFormatPromise = this.readHeader();
    }
    get format() {
        return this.privAudioFormatPromise;
    }
    get blob() {
        return Promise.resolve(this.privSource);
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return this.privAudioFormatPromise.then((result) => {
            return Promise.resolve({
                bitspersample: result.bitsPerSample,
                channelcount: result.channels,
                connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["connectivity"].Unknown,
                manufacturer: "Speech SDK",
                model: "File",
                samplerate: result.samplesPerSec,
                type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["type"].File,
            });
        });
    }
    readHeader() {
        // Read the wave header.
        const maxHeaderSize = 512;
        const header = this.privSource.slice(0, maxHeaderSize);
        const headerResult = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
        const processHeader = (header) => {
            const view = new DataView(header);
            const getWord = (index) => {
                return String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));
            };
            // RIFF 4 bytes.
            if ("RIFF" !== getWord(0)) {
                headerResult.reject("Invalid WAV header in file, RIFF was not found");
                return;
            }
            // length, 4 bytes
            // RIFF Type & fmt 8 bytes
            if ("WAVE" !== getWord(8) || "fmt " !== getWord(12)) {
                headerResult.reject("Invalid WAV header in file, WAVEfmt was not found");
                return;
            }
            const formatSize = view.getInt32(16, true);
            const channelCount = view.getUint16(22, true);
            const sampleRate = view.getUint32(24, true);
            const bitsPerSample = view.getUint16(34, true);
            // Confirm if header is 44 bytes long.
            let pos = 36 + Math.max(formatSize - 16, 0);
            for (; getWord(pos) !== "data"; pos += 2) {
                if (pos > maxHeaderSize - 8) {
                    headerResult.reject("Invalid WAV header in file, data block was not found");
                    return;
                }
            }
            this.privHeaderEnd = pos + 8;
            headerResult.resolve(_sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__["AudioStreamFormat"].getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));
        };
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && header instanceof Blob) {
            const reader = new FileReader();
            reader.onload = (event) => {
                const header = event.target.result;
                processHeader(header);
            };
            reader.readAsArrayBuffer(header);
        }
        else {
            const h = header;
            processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));
        }
        return headerResult.promise;
    }
    upload(audioNodeId) {
        return __awaiter(this, void 0, void 0, function* () {
            const onerror = (error) => {
                const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeErrorEvent"](this.privId, audioNodeId, errorMsg));
                throw new Error(errorMsg);
            };
            try {
                yield this.turnOn();
                const format = yield this.privAudioFormatPromise;
                const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ChunkedArrayBufferStream"](format.avgBytesPerSec / 10, audioNodeId);
                this.privStreams[audioNodeId] = stream;
                const chunk = this.privSource.slice(this.privHeaderEnd);
                const processFile = (buff) => {
                    if (stream.isClosed) {
                        return; // output stream was closed (somebody called TurnOff). We're done here.
                    }
                    stream.writeStreamChunk({
                        buffer: buff,
                        isEnd: false,
                        timeReceived: Date.now(),
                    });
                    stream.close();
                };
                if (typeof window !== "undefined" && typeof Blob !== "undefined" && chunk instanceof Blob) {
                    const reader = new FileReader();
                    reader.onerror = (ev) => { onerror(ev.toString()); };
                    reader.onload = (event) => {
                        const fileBuffer = event.target.result;
                        processFile(fileBuffer);
                    };
                    reader.readAsArrayBuffer(chunk);
                }
                else {
                    const c = chunk;
                    processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));
                }
                return stream;
            }
            catch (e) {
                onerror(e);
            }
        });
    }
}

//# sourceMappingURL=FileAudioSource.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js ***!
  \************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IRecorder.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js ***!
  \*****************************************************************************************************************/
/*! exports provided: AudioWorkletSourceURLPropertyName, MicAudioSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioWorkletSourceURLPropertyName", function() { return AudioWorkletSourceURLPropertyName; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MicAudioSource", function() { return MicAudioSource; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



const AudioWorkletSourceURLPropertyName = "MICROPHONE-WorkletSourceUrl";
class MicAudioSource {
    constructor(privRecorder, deviceId, audioSourceId, mediaStream) {
        this.privRecorder = privRecorder;
        this.deviceId = deviceId;
        this.privStreams = {};
        this.turnOn = () => {
            if (this.privInitializeDeferral) {
                return this.privInitializeDeferral.promise;
            }
            this.privInitializeDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            try {
                this.createAudioContext();
            }
            catch (error) {
                if (error instanceof Error) {
                    const typedError = error;
                    this.privInitializeDeferral.reject(typedError.name + ": " + typedError.message);
                }
                else {
                    this.privInitializeDeferral.reject(error);
                }
                return this.privInitializeDeferral.promise;
            }
            const nav = window.navigator;
            let getUserMedia = (nav.getUserMedia ||
                nav.webkitGetUserMedia ||
                nav.mozGetUserMedia ||
                nav.msGetUserMedia);
            if (!!nav.mediaDevices) {
                getUserMedia = (constraints, successCallback, errorCallback) => {
                    nav.mediaDevices
                        .getUserMedia(constraints)
                        .then(successCallback)
                        .catch(errorCallback);
                };
            }
            if (!getUserMedia) {
                const errorMsg = "Browser does not support getUserMedia.";
                this.privInitializeDeferral.reject(errorMsg);
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceErrorEvent"](errorMsg, "")); // mic initialized error - no streamid at this point
            }
            else {
                const next = () => {
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceInitializingEvent"](this.privId)); // no stream id
                    if (this.privMediaStream && this.privMediaStream.active) {
                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceReadyEvent"](this.privId));
                        this.privInitializeDeferral.resolve();
                    }
                    else {
                        getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {
                            this.privMediaStream = mediaStream;
                            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceReadyEvent"](this.privId));
                            this.privInitializeDeferral.resolve();
                        }, (error) => {
                            const errorMsg = `Error occurred during microphone initialization: ${error}`;
                            this.privInitializeDeferral.reject(errorMsg);
                            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceErrorEvent"](this.privId, errorMsg));
                        });
                    }
                };
                if (this.privContext.state === "suspended") {
                    // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.
                    // https://github.com/WebAudio/web-audio-api/issues/790
                    this.privContext.resume()
                        .then(next)
                        .catch((reason) => {
                        this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);
                    });
                }
                else {
                    next();
                }
            }
            return this.privInitializeDeferral.promise;
        };
        this.id = () => {
            return this.privId;
        };
        this.attach = (audioNodeId) => {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachingEvent"](this.privId, audioNodeId));
            return this.listen(audioNodeId).then((stream) => {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachedEvent"](this.privId, audioNodeId));
                return {
                    detach: () => __awaiter(this, void 0, void 0, function* () {
                        stream.readEnded();
                        delete this.privStreams[audioNodeId];
                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
                        return this.turnOff();
                    }),
                    id: () => {
                        return audioNodeId;
                    },
                    read: () => {
                        return stream.read();
                    },
                };
            });
        };
        this.detach = (audioNodeId) => {
            if (audioNodeId && this.privStreams[audioNodeId]) {
                this.privStreams[audioNodeId].close();
                delete this.privStreams[audioNodeId];
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
            }
        };
        this.listen = (audioNodeId) => __awaiter(this, void 0, void 0, function* () {
            yield this.turnOn();
            const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ChunkedArrayBufferStream"](this.privOutputChunkSize, audioNodeId);
            this.privStreams[audioNodeId] = stream;
            try {
                this.privRecorder.record(this.privContext, this.privMediaStream, stream);
            }
            catch (error) {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeErrorEvent"](this.privId, audioNodeId, error));
                throw error;
            }
            const result = stream;
            return result;
        });
        this.onEvent = (event) => {
            this.privEvents.onEvent(event);
            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(event);
        };
        this.createAudioContext = () => {
            if (!!this.privContext) {
                return;
            }
            this.privContext = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__["AudioStreamFormatImpl"].getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);
        };
        this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;
        this.privId = audioSourceId ? audioSourceId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privMediaStream = mediaStream || null;
        this.privIsClosing = false;
    }
    get format() {
        return Promise.resolve(MicAudioSource.AUDIOFORMAT);
    }
    get blob() {
        return Promise.reject("Not implemented for Mic input");
    }
    turnOff() {
        return __awaiter(this, void 0, void 0, function* () {
            for (const streamId in this.privStreams) {
                if (streamId) {
                    const stream = this.privStreams[streamId];
                    if (stream) {
                        stream.close();
                    }
                }
            }
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceOffEvent"](this.privId)); // no stream now
            if (this.privInitializeDeferral) {
                // Correctly handle when browser forces mic off before turnOn() completes
                yield this.privInitializeDeferral;
                this.privInitializeDeferral = null;
            }
            yield this.destroyAudioContext();
            return;
        });
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return this.getMicrophoneLabel().then((label) => {
            return {
                bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,
                channelcount: MicAudioSource.AUDIOFORMAT.channels,
                connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["connectivity"].Unknown,
                manufacturer: "Speech SDK",
                model: label,
                samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,
                type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["type"].Microphones,
            };
        });
    }
    setProperty(name, value) {
        if (name === AudioWorkletSourceURLPropertyName) {
            this.privRecorder.setWorkletUrl(value);
        }
        else {
            throw new Error("Property '" + name + "' is not supported on Microphone.");
        }
    }
    getMicrophoneLabel() {
        const defaultMicrophoneName = "microphone";
        // If we did this already, return the value.
        if (this.privMicrophoneLabel !== undefined) {
            return Promise.resolve(this.privMicrophoneLabel);
        }
        // If the stream isn't currently running, we can't query devices because security.
        if (this.privMediaStream === undefined || !this.privMediaStream.active) {
            return Promise.resolve(defaultMicrophoneName);
        }
        // Setup a default
        this.privMicrophoneLabel = defaultMicrophoneName;
        // Get the id of the device running the audio track.
        const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;
        // If the browser doesn't support getting the device ID, set a default and return.
        if (undefined === microphoneDeviceId) {
            return Promise.resolve(this.privMicrophoneLabel);
        }
        const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
        // Enumerate the media devices.
        navigator.mediaDevices.enumerateDevices().then((devices) => {
            for (const device of devices) {
                if (device.deviceId === microphoneDeviceId) {
                    // Found the device
                    this.privMicrophoneLabel = device.label;
                    break;
                }
            }
            deferred.resolve(this.privMicrophoneLabel);
        }, () => deferred.resolve(this.privMicrophoneLabel));
        return deferred.promise;
    }
    destroyAudioContext() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privContext) {
                return;
            }
            this.privRecorder.releaseMediaResources(this.privContext);
            // This pattern brought to you by a bug in the TypeScript compiler where it
            // confuses the ("close" in this.privContext) with this.privContext always being null as the alternate.
            // https://github.com/Microsoft/TypeScript/issues/11498
            let hasClose = false;
            if ("close" in this.privContext) {
                hasClose = true;
            }
            if (hasClose) {
                if (!this.privIsClosing) {
                    // The audio context close may take enough time that the close is called twice
                    this.privIsClosing = true;
                    yield this.privContext.close();
                    this.privContext = null;
                    this.privIsClosing = false;
                }
            }
            else if (null !== this.privContext && this.privContext.state === "running") {
                // Suspend actually takes a callback, but analogous to the
                // resume method, it'll be only fired if suspend is called
                // in a direct response to a user action. The later is not always
                // the case, as TurnOff is also called, when we receive an
                // end-of-speech message from the service. So, doing a best effort
                // fire-and-forget here.
                yield this.privContext.suspend();
            }
        });
    }
}
MicAudioSource.AUDIOFORMAT = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__["AudioStreamFormat"].getDefaultInputFormat();

//# sourceMappingURL=MicAudioSource.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js ***!
  \**************************************************************************************************************/
/*! exports provided: PcmRecorder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PcmRecorder", function() { return PcmRecorder; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class PcmRecorder {
    constructor(stopInputOnRelease) {
        this.record = (context, mediaStream, outputStream) => {
            const desiredSampleRate = 16000;
            const waveStreamEncoder = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["RiffPcmEncoder"](context.sampleRate, desiredSampleRate);
            let needHeader = true;
            const micInput = context.createMediaStreamSource(mediaStream);
            if (!this.privSpeechProcessorScript) {
                const workletScript = `class SP extends AudioWorkletProcessor {
                constructor(options) {
                  super(options);
                }
                process(inputs, outputs) {
                  const input = inputs[0];
                  const output = [];
                  for (let channel = 0; channel < input.length; channel += 1) {
                    output[channel] = input[channel];
                  }
                  this.port.postMessage(output[0]);
                  return true;
                }
              }
              registerProcessor('speech-processor', SP);`; // tslint:disable-line:max-line-length
                const blob = new Blob([workletScript], { type: "application/javascript; charset=utf-8" });
                this.privSpeechProcessorScript = URL.createObjectURL(blob);
            }
            // https://webaudio.github.io/web-audio-api/#audioworklet
            // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread
            if (!!this.privSpeechProcessorScript && !!context.audioWorklet) {
                context.audioWorklet
                    .addModule(this.privSpeechProcessorScript)
                    .then(() => {
                    const workletNode = new AudioWorkletNode(context, "speech-processor");
                    workletNode.port.onmessage = (ev) => {
                        const inputFrame = ev.data;
                        if (outputStream && !outputStream.isClosed) {
                            const waveFrame = waveStreamEncoder.encode(inputFrame);
                            if (!!waveFrame) {
                                outputStream.writeStreamChunk({
                                    buffer: waveFrame,
                                    isEnd: false,
                                    timeReceived: Date.now(),
                                });
                                needHeader = false;
                            }
                        }
                    };
                    micInput.connect(workletNode);
                    workletNode.connect(context.destination);
                    this.privMediaResources = {
                        scriptProcessorNode: workletNode,
                        source: micInput,
                        stream: mediaStream,
                    };
                })
                    .catch(() => {
                    const scriptNode = (() => {
                        let bufferSize = 0;
                        try {
                            return context.createScriptProcessor(bufferSize, 1, 1);
                        }
                        catch (error) {
                            // Webkit (<= version 31) requires a valid bufferSize.
                            bufferSize = 2048;
                            let audioSampleRate = context.sampleRate;
                            while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {
                                bufferSize <<= 1;
                                audioSampleRate >>= 1;
                            }
                            return context.createScriptProcessor(bufferSize, 1, 1);
                        }
                    })();
                    scriptNode.onaudioprocess = (event) => {
                        const inputFrame = event.inputBuffer.getChannelData(0);
                        if (outputStream && !outputStream.isClosed) {
                            const waveFrame = waveStreamEncoder.encode(inputFrame);
                            if (!!waveFrame) {
                                outputStream.writeStreamChunk({
                                    buffer: waveFrame,
                                    isEnd: false,
                                    timeReceived: Date.now(),
                                });
                                needHeader = false;
                            }
                        }
                    };
                    micInput.connect(scriptNode);
                    scriptNode.connect(context.destination);
                    this.privMediaResources = {
                        scriptProcessorNode: scriptNode,
                        source: micInput,
                        stream: mediaStream,
                    };
                });
            }
            else {
                throw new Error("Unable to start audio worklet node for PCMRecorder");
            }
        };
        this.releaseMediaResources = (context) => {
            if (this.privMediaResources) {
                if (this.privMediaResources.scriptProcessorNode) {
                    this.privMediaResources.scriptProcessorNode.disconnect(context.destination);
                    this.privMediaResources.scriptProcessorNode = null;
                }
                if (this.privMediaResources.source) {
                    this.privMediaResources.source.disconnect();
                    if (this.privStopInputOnRelease) {
                        this.privMediaResources.stream.getTracks().forEach((track) => track.stop());
                    }
                    this.privMediaResources.source = null;
                }
            }
        };
        this.privStopInputOnRelease = stopInputOnRelease;
    }
    setWorkletUrl(url) {
        this.privSpeechProcessorScript = url;
    }
}

//# sourceMappingURL=PCMRecorder.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js ***!
  \************************************************************************************************************/
/*! exports provided: ProxyInfo */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ProxyInfo", function() { return ProxyInfo; });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ProxyInfo {
    constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.privProxyHostName = proxyHostName;
        this.privProxyPort = proxyPort;
        this.privProxyUserName = proxyUserName;
        this.privProxyPassword = proxyPassword;
    }
    static fromParameters(parameters) {
        return new ProxyInfo(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceConnection_ProxyUserName), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceConnection_ProxyPassword));
    }
    static fromRecognizerConfig(config) {
        return this.fromParameters(config.parameters);
    }
    get HostName() {
        return this.privProxyHostName;
    }
    get Port() {
        return this.privProxyPort;
    }
    get UserName() {
        return this.privProxyUserName;
    }
    get Password() {
        return this.privProxyPassword;
    }
}

//# sourceMappingURL=ProxyInfo.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js ***!
  \**********************************************************************************************************************/
/*! exports provided: ReplayableAudioNode */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ReplayableAudioNode", function() { return ReplayableAudioNode; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ReplayableAudioNode {
    constructor(audioSource, bytesPerSecond) {
        this.privBuffers = [];
        this.privReplayOffset = 0;
        this.privLastShrinkOffset = 0;
        this.privBufferStartOffset = 0;
        this.privBufferSerial = 0;
        this.privBufferedBytes = 0;
        this.privReplay = false;
        this.privLastChunkAcquiredTime = 0;
        this.id = () => {
            return this.privAudioNode.id();
        };
        this.privAudioNode = audioSource;
        this.privBytesPerSecond = bytesPerSecond;
    }
    // Reads and returns the next chunk of audio buffer.
    // If replay of existing buffers are needed, read() will first seek and replay
    // existing content, and upoin completion it will read new content from the underlying
    // audio node, saving that content into the replayable buffers.
    read() {
        // if there is a replay request to honor.
        if (!!this.privReplay && this.privBuffers.length !== 0) {
            // Find the start point in the buffers.
            // Offsets are in 100ns increments.
            // So how many bytes do we need to seek to get the right offset?
            const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;
            let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
            if (0 !== (bytesToSeek % 2)) {
                bytesToSeek++;
            }
            let i = 0;
            while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
                bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
            }
            if (i < this.privBuffers.length) {
                const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);
                this.privReplayOffset += (retVal.byteLength / this.privBytesPerSecond) * 1e+7;
                // If we've reached the end of the buffers, stop replaying.
                if (i === this.privBuffers.length - 1) {
                    this.privReplay = false;
                }
                return Promise.resolve({
                    buffer: retVal,
                    isEnd: false,
                    timeReceived: this.privBuffers[i].chunk.timeReceived,
                });
            }
        }
        return this.privAudioNode.read()
            .then((result) => {
            if (result && result.buffer) {
                this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));
                this.privBufferedBytes += result.buffer.byteLength;
            }
            return result;
        });
    }
    detach() {
        this.privBuffers = undefined;
        return this.privAudioNode.detach();
    }
    replay() {
        if (this.privBuffers && 0 !== this.privBuffers.length) {
            this.privReplay = true;
            this.privReplayOffset = this.privLastShrinkOffset;
        }
    }
    // Shrinks the existing audio buffers to start at the new offset, or at the
    // beginning of the buffer closest to the requested offset.
    // A replay request will start from the last shrink point.
    shrinkBuffers(offset) {
        if (this.privBuffers === undefined || this.privBuffers.length === 0) {
            return;
        }
        this.privLastShrinkOffset = offset;
        // Find the start point in the buffers.
        // Offsets are in 100ns increments.
        // So how many bytes do we need to seek to get the right offset?
        const offsetToSeek = offset - this.privBufferStartOffset;
        let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
        let i = 0;
        while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
            bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
        }
        this.privBufferStartOffset = Math.round(offset - ((bytesToSeek / this.privBytesPerSecond) * 1e+7));
        this.privBuffers = this.privBuffers.slice(i);
    }
    // Finds the time a buffer of audio was first seen by offset.
    findTimeAtOffset(offset) {
        if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {
            return 0;
        }
        for (const value of this.privBuffers) {
            const startOffset = (value.byteOffset / this.privBytesPerSecond) * 1e7;
            const endOffset = startOffset + ((value.chunk.buffer.byteLength / this.privBytesPerSecond) * 1e7);
            if (offset >= startOffset && offset <= endOffset) {
                return value.chunk.timeReceived;
            }
        }
        return 0;
    }
}
// Primary use of this class is to help debugging problems with the replay
// code. If the memory cost of alloc / dealloc gets too much, drop it and just use
// the ArrayBuffer directly.
// tslint:disable-next-line:max-classes-per-file
class BufferEntry {
    constructor(chunk, serial, byteOffset) {
        this.chunk = chunk;
        this.serial = serial;
        this.byteOffset = byteOffset;
    }
}

//# sourceMappingURL=ReplayableAudioNode.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js ***!
  \*****************************************************************************************************************/
/*! exports provided: RestConfigBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RestConfigBase", function() { return RestConfigBase; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class RestConfigBase {
    static get requestOptions() {
        return RestConfigBase.privDefaultRequestOptions;
    }
    static get configParams() {
        return RestConfigBase.privDefaultParams;
    }
    static get restErrors() {
        return RestConfigBase.privRestErrors;
    }
}
RestConfigBase.privDefaultRequestOptions = {
    headers: {
        Accept: "application/json",
    },
    ignoreCache: false,
    timeout: 10000,
};
RestConfigBase.privRestErrors = {
    authInvalidSubscriptionKey: "You must specify either an authentication token to use, or a Cognitive Speech subscription key.",
    authInvalidSubscriptionRegion: "You must specify the Cognitive Speech region to use.",
    invalidArgs: "Required input not found: {arg}.",
    invalidCreateJoinConversationResponse: "Creating/Joining conversation failed with HTTP {status}.",
    invalidParticipantRequest: "The requested participant was not found.",
    permissionDeniedConnect: "Required credentials not found.",
    permissionDeniedConversation: "Invalid operation: only the host can {command} the conversation.",
    permissionDeniedParticipant: "Invalid operation: only the host can {command} a participant.",
    permissionDeniedSend: "Invalid operation: the conversation is not in a connected state.",
    permissionDeniedStart: "Invalid operation: there is already an active conversation.",
};
RestConfigBase.privDefaultParams = {
    apiVersion: "api-version",
    authorization: "Authorization",
    clientAppId: "X-ClientAppId",
    contentTypeKey: "Content-Type",
    correlationId: "X-CorrelationId",
    languageCode: "language",
    nickname: "nickname",
    profanity: "profanity",
    requestId: "X-RequestId",
    roomId: "roomid",
    sessionToken: "token",
    subscriptionKey: "Ocp-Apim-Subscription-Key",
    subscriptionRegion: "Ocp-Apim-Subscription-Region",
    token: "X-CapitoToken",
};

//# sourceMappingURL=RestConfigBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js ***!
  \*********************************************************************************************************************/
/*! exports provided: RestRequestType, RestMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RestRequestType", function() { return RestRequestType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RestMessageAdapter", function() { return RestMessageAdapter; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! bent */ "./node_modules/bent/src/browser.js");
/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(bent__WEBPACK_IMPORTED_MODULE_1__);
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};


var RestRequestType;
(function (RestRequestType) {
    RestRequestType["Get"] = "GET";
    RestRequestType["Post"] = "POST";
    RestRequestType["Delete"] = "DELETE";
    RestRequestType["File"] = "file";
})(RestRequestType || (RestRequestType = {}));
// accept rest operations via request method and return abstracted objects from server response
class RestMessageAdapter {
    constructor(configParams) {
        if (!configParams) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("configParams");
        }
        this.privHeaders = configParams.headers;
        this.privIgnoreCache = configParams.ignoreCache;
    }
    static extractHeaderValue(headerKey, headers) {
        let headerValue = "";
        try {
            const arr = headers.trim().split(/[\r\n]+/);
            const headerMap = {};
            arr.forEach((line) => {
                const parts = line.split(": ");
                const header = parts.shift().toLowerCase();
                const value = parts.join(": ");
                headerMap[header] = value;
            });
            headerValue = headerMap[headerKey.toLowerCase()];
        }
        catch (e) {
            // ignore the error
        }
        return headerValue;
    }
    set options(configParams) {
        this.privHeaders = configParams.headers;
        this.privIgnoreCache = configParams.ignoreCache;
    }
    setHeaders(key, value) {
        this.privHeaders[key] = value;
    }
    request(method, uri, queryParams = {}, body = null, binaryBody = null) {
        const responseReceivedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
        const requestCommand = method === RestRequestType.File ? "POST" : method;
        const handleRestResponse = (data, j = {}) => {
            const d = data;
            return {
                data: JSON.stringify(j),
                headers: JSON.stringify(data.headers),
                json: j,
                ok: data.statusCode >= 200 && data.statusCode < 300,
                status: data.statusCode,
                statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage
            };
        };
        const blobToArrayBuffer = (blob) => {
            const reader = new FileReader();
            reader.readAsArrayBuffer(blob);
            return new Promise((resolve) => {
                reader.onloadend = () => {
                    resolve(reader.result);
                };
            });
        };
        const send = (postData) => {
            const sendRequest = bent__WEBPACK_IMPORTED_MODULE_1___default()(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);
            const params = this.queryParams(queryParams) === "" ? "" : "?" + this.queryParams(queryParams);
            sendRequest(params, postData).then((data) => __awaiter(this, void 0, void 0, function* () {
                if (method === RestRequestType.Delete || data.statusCode === 204) {
                    // No JSON from Delete and reset (204) operations
                    responseReceivedDeferral.resolve(handleRestResponse(data));
                }
                else {
                    const j = yield data.json();
                    responseReceivedDeferral.resolve(handleRestResponse(data, j));
                }
            })).catch((error) => {
                responseReceivedDeferral.reject(error);
            });
        };
        if (this.privIgnoreCache) {
            this.privHeaders["Cache-Control"] = "no-cache";
        }
        if (method === RestRequestType.File && binaryBody) {
            const contentType = "multipart/form-data";
            this.privHeaders["content-type"] = contentType;
            this.privHeaders["Content-Type"] = contentType;
            if (typeof (Blob) !== "undefined" && binaryBody instanceof Blob) {
                blobToArrayBuffer(binaryBody).then((res) => {
                    send(res);
                }).catch((error) => {
                    responseReceivedDeferral.reject(error);
                });
            }
            else {
                send(binaryBody);
            }
        }
        else {
            if (method === RestRequestType.Post && body) {
                this.privHeaders["content-type"] = "application/json";
                this.privHeaders["Content-Type"] = "application/json";
            }
            send(body);
        }
        return responseReceivedDeferral.promise;
    }
    withQuery(url, params = {}) {
        const queryString = this.queryParams(params);
        return queryString ? url + (url.indexOf("?") === -1 ? "?" : "&") + queryString : url;
    }
    queryParams(params = {}) {
        return Object.keys(params)
            .map((k) => encodeURIComponent(k) + "=" + encodeURIComponent(params[k]))
            .join("&");
    }
}

//# sourceMappingURL=RestMessageAdapter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js ***!
  \**********************************************************************************************************************/
/*! exports provided: WebsocketConnection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "WebsocketConnection", function() { return WebsocketConnection; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};


class WebsocketConnection {
    constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {
        this.privIsDisposed = false;
        this.isDisposed = () => {
            return this.privIsDisposed;
        };
        this.state = () => {
            return this.privConnectionMessageAdapter.state;
        };
        this.open = () => {
            return this.privConnectionMessageAdapter.open();
        };
        this.send = (message) => {
            return this.privConnectionMessageAdapter.send(message);
        };
        this.read = () => {
            return this.privConnectionMessageAdapter.read();
        };
        if (!uri) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("uri");
        }
        if (!messageFormatter) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("messageFormatter");
        }
        this.privMessageFormatter = messageFormatter;
        let queryParams = "";
        let i = 0;
        if (queryParameters) {
            for (const paramName in queryParameters) {
                if (paramName) {
                    queryParams += ((i === 0) && (uri.indexOf("?") === -1)) ? "?" : "&";
                    const val = encodeURIComponent(queryParameters[paramName]);
                    queryParams += `${paramName}=${val}`;
                    i++;
                }
            }
        }
        if (headers) {
            for (const headerName in headers) {
                if (headerName) {
                    queryParams += ((i === 0) && (uri.indexOf("?") === -1)) ? "?" : "&";
                    const val = encodeURIComponent(headers[headerName]);
                    queryParams += `${headerName}=${val}`;
                    i++;
                }
            }
        }
        this.privUri = uri + queryParams;
        this.privId = connectionId ? connectionId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privConnectionMessageAdapter = new _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_1__["WebsocketMessageAdapter"](this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);
    }
    dispose() {
        return __awaiter(this, void 0, void 0, function* () {
            this.privIsDisposed = true;
            if (this.privConnectionMessageAdapter) {
                yield this.privConnectionMessageAdapter.close();
            }
        });
    }
    get id() {
        return this.privId;
    }
    get events() {
        return this.privConnectionMessageAdapter.events;
    }
}

//# sourceMappingURL=WebsocketConnection.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js ***!
  \**************************************************************************************************************************/
/*! exports provided: WebsocketMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "WebsocketMessageAdapter", function() { return WebsocketMessageAdapter; });
/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ws */ 3);
/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(ws__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _CertChecks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./CertChecks */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};


// Node.JS specific web socket / browser support.


class WebsocketMessageAdapter {
    constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {
        this.open = () => {
            if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected) {
                return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);
            }
            if (this.privConnectionEstablishDeferral) {
                return this.privConnectionEstablishDeferral.promise;
            }
            this.privConnectionEstablishDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            this.privCertificateValidatedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connecting;
            try {
                if (typeof WebSocket !== "undefined" && !WebsocketMessageAdapter.forceNpmWebSocket) {
                    // Browser handles cert checks.
                    this.privCertificateValidatedDeferral.resolve();
                    this.privWebsocketClient = new WebSocket(this.privUri);
                }
                else {
                    const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression };
                    // The ocsp library will handle validation for us and fail the connection if needed.
                    this.privCertificateValidatedDeferral.resolve();
                    const checkAgent = new _CertChecks__WEBPACK_IMPORTED_MODULE_3__["CertCheckAgent"](this.proxyInfo);
                    options.agent = checkAgent.GetAgent();
                    this.privWebsocketClient = new ws__WEBPACK_IMPORTED_MODULE_2___default.a(this.privUri, options);
                }
                this.privWebsocketClient.binaryType = "arraybuffer";
                this.privReceivingMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Queue"]();
                this.privDisconnectDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
                this.privSendMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Queue"]();
                this.processSendQueue().catch((reason) => {
                    _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
                });
            }
            catch (error) {
                this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionOpenResponse"](500, error));
                return this.privConnectionEstablishDeferral.promise;
            }
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionStartEvent"](this.privConnectionId, this.privUri));
            this.privWebsocketClient.onopen = (e) => {
                this.privCertificateValidatedDeferral.promise.then(() => {
                    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connected;
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionEstablishedEvent"](this.privConnectionId));
                    this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionOpenResponse"](200, ""));
                }, (error) => {
                    this.privConnectionEstablishDeferral.reject(error);
                });
            };
            this.privWebsocketClient.onerror = (e) => {
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionErrorEvent"](this.privConnectionId, e.message, e.type));
                this.privLastErrorReceived = e.message;
            };
            this.privWebsocketClient.onclose = (e) => {
                if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connecting) {
                    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected;
                    // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));
                    this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionOpenResponse"](e.code, e.reason + " " + this.privLastErrorReceived));
                }
                else {
                    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected;
                    this.privWebsocketClient = null;
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionClosedEvent"](this.privConnectionId, e.code, e.reason));
                }
                this.onClose(e.code, e.reason).catch((reason) => {
                    _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
                });
            };
            this.privWebsocketClient.onmessage = (e) => {
                const networkReceivedTime = new Date().toISOString();
                if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connected) {
                    const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
                    // let id = ++this.idCounter;
                    this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);
                    if (e.data instanceof ArrayBuffer) {
                        const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["RawWebsocketMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary, e.data);
                        this.privMessageFormatter
                            .toConnectionMessage(rawMessage)
                            .then((connectionMessage) => {
                            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionMessageReceivedEvent"](this.privConnectionId, networkReceivedTime, connectionMessage));
                            deferred.resolve(connectionMessage);
                        }, (error) => {
                            // TODO: Events for these ?
                            deferred.reject(`Invalid binary message format. Error: ${error}`);
                        });
                    }
                    else {
                        const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["RawWebsocketMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text, e.data);
                        this.privMessageFormatter
                            .toConnectionMessage(rawMessage)
                            .then((connectionMessage) => {
                            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionMessageReceivedEvent"](this.privConnectionId, networkReceivedTime, connectionMessage));
                            deferred.resolve(connectionMessage);
                        }, (error) => {
                            // TODO: Events for these ?
                            deferred.reject(`Invalid text message format. Error: ${error}`);
                        });
                    }
                }
            };
            return this.privConnectionEstablishDeferral.promise;
        };
        this.send = (message) => {
            if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connected) {
                return Promise.reject(`Cannot send on connection that is in ${_common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"][this.privConnectionState]} state`);
            }
            const messageSendStatusDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            const messageSendDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);
            this.privMessageFormatter
                .fromConnectionMessage(message)
                .then((rawMessage) => {
                messageSendDeferral.resolve({
                    Message: message,
                    RawWebsocketMessage: rawMessage,
                    sendStatusDeferral: messageSendStatusDeferral,
                });
            }, (error) => {
                messageSendDeferral.reject(`Error formatting the message. ${error}`);
            });
            return messageSendStatusDeferral.promise;
        };
        this.read = () => {
            if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Connected) {
                return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);
            }
            return this.privReceivingMessageQueue.dequeue();
        };
        this.close = (reason) => {
            if (this.privWebsocketClient) {
                if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected) {
                    this.privWebsocketClient.close(1000, reason ? reason : "Normal closure by client");
                }
            }
            else {
                return Promise.resolve();
            }
            return this.privDisconnectDeferral.promise;
        };
        this.sendRawMessage = (sendItem) => {
            try {
                // indicates we are draining the queue and it came with no message;
                if (!sendItem) {
                    return Promise.resolve();
                }
                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionMessageSentEvent"](this.privConnectionId, new Date().toISOString(), sendItem.Message));
                // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing
                if (this.isWebsocketOpen) {
                    this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);
                }
                else {
                    return Promise.reject("websocket send error: Websocket not ready " + this.privConnectionId + " " + sendItem.Message.id + " " + new Error().stack);
                }
                return Promise.resolve();
            }
            catch (e) {
                return Promise.reject(`websocket send error: ${e}`);
            }
        };
        this.onEvent = (event) => {
            this.privConnectionEvents.onEvent(event);
            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(event);
        };
        if (!uri) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("uri");
        }
        if (!messageFormatter) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("messageFormatter");
        }
        this.proxyInfo = proxyInfo;
        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privConnectionId = connectionId;
        this.privMessageFormatter = messageFormatter;
        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].None;
        this.privUri = uri;
        this.privHeaders = headers;
        this.privEnableCompression = enableCompression;
        // Add the connection ID to the headers
        this.privHeaders[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__["HeaderNames"].ConnectionId] = this.privConnectionId;
        this.privLastErrorReceived = "";
    }
    get state() {
        return this.privConnectionState;
    }
    get events() {
        return this.privConnectionEvents;
    }
    onClose(code, reason) {
        return __awaiter(this, void 0, void 0, function* () {
            const closeReason = `Connection closed. ${code}: ${reason}`;
            this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected;
            this.privDisconnectDeferral.resolve();
            yield this.privReceivingMessageQueue.drainAndDispose((pendingReceiveItem) => {
                // TODO: Events for these ?
                // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));
            }, closeReason);
            yield this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {
                pendingSendItem.sendStatusDeferral.reject(closeReason);
            }, closeReason);
        });
    }
    processSendQueue() {
        return __awaiter(this, void 0, void 0, function* () {
            while (true) {
                const itemToSend = this.privSendMessageQueue.dequeue();
                const sendItem = yield itemToSend;
                // indicates we are draining the queue and it came with no message;
                if (!sendItem) {
                    return;
                }
                try {
                    yield this.sendRawMessage(sendItem);
                    sendItem.sendStatusDeferral.resolve();
                }
                catch (sendError) {
                    sendItem.sendStatusDeferral.reject(sendError);
                }
            }
        });
    }
    get isWebsocketOpen() {
        return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;
    }
}
WebsocketMessageAdapter.forceNpmWebSocket = false;

//# sourceMappingURL=WebsocketMessageAdapter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js ***!
  \***************************************************************************************************************/
/*! exports provided: AddedLmIntent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AddedLmIntent", function() { return AddedLmIntent; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class AddedLmIntent
 */
// tslint:disable-next-line:max-classes-per-file
class AddedLmIntent {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param modelImpl - The model.
     * @param intentName - The intent name.
     */
    constructor(modelImpl, intentName) {
        this.modelImpl = modelImpl;
        this.intentName = intentName;
    }
}

//# sourceMappingURL=AddedLmIntent.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js ***!
  \*************************************************************************************************************/
/*! exports provided: AgentConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AgentConfig", function() { return AgentConfig; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Represents the JSON used in the agent.config message sent to the speech service.
 */
class AgentConfig {
    toJsonString() {
        return JSON.stringify(this.iPrivConfig);
    }
    get() {
        return this.iPrivConfig;
    }
    /**
     * Setter for the agent.config object.
     * @param value a JSON serializable object.
     */
    set(value) {
        this.iPrivConfig = value;
    }
}

//# sourceMappingURL=AgentConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \****************************************************************************************************************************************/
/*! exports provided: CognitiveSubscriptionKeyAuthentication */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CognitiveSubscriptionKeyAuthentication", function() { return CognitiveSubscriptionKeyAuthentication; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * @class
 */
class CognitiveSubscriptionKeyAuthentication {
    /**
     * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.
     * @constructor
     * @param {string} subscriptionKey - The subscription key
     */
    constructor(subscriptionKey) {
        /**
         * Fetches the subscription key.
         * @member
         * @function
         * @public
         * @param {string} authFetchEventId - The id to fetch.
         */
        this.fetch = (authFetchEventId) => {
            return Promise.resolve(this.privAuthInfo);
        };
        /**
         * Fetches the subscription key.
         * @member
         * @function
         * @public
         * @param {string} authFetchEventId - The id to fetch.
         */
        this.fetchOnExpiry = (authFetchEventId) => {
            return Promise.resolve(this.privAuthInfo);
        };
        if (!subscriptionKey) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("subscriptionKey");
        }
        this.privAuthInfo = new _IAuthentication__WEBPACK_IMPORTED_MODULE_2__["AuthInfo"](_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].AuthKey, subscriptionKey);
    }
}

//# sourceMappingURL=CognitiveSubscriptionKeyAuthentication.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js ***!
  \******************************************************************************************************************************/
/*! exports provided: CognitiveTokenAuthentication */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CognitiveTokenAuthentication", function() { return CognitiveTokenAuthentication; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


const AuthHeader = "Authorization";
class CognitiveTokenAuthentication {
    constructor(fetchCallback, fetchOnExpiryCallback) {
        this.fetch = (authFetchEventId) => {
            return this.privFetchCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__["AuthInfo"](AuthHeader, token));
        };
        this.fetchOnExpiry = (authFetchEventId) => {
            return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__["AuthInfo"](AuthHeader, token));
        };
        if (!fetchCallback) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("fetchCallback");
        }
        if (!fetchOnExpiryCallback) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("fetchOnExpiryCallback");
        }
        this.privFetchCallback = fetchCallback;
        this.privFetchOnExpiryCallback = fetchOnExpiryCallback;
    }
}

//# sourceMappingURL=CognitiveTokenAuthentication.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ConnectionFactoryBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionFactoryBase", function() { return ConnectionFactoryBase; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class ConnectionFactoryBase {
    setCommonUrlParams(config, queryParams, endpoint) {
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_EnableAudioLogging, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].EnableAudioLogging, config, queryParams, endpoint);
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_RequestWordLevelTimestamps, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].EnableWordLevelTimestamps, config, queryParams, endpoint);
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_ProfanityOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].Profanity, config, queryParams, endpoint);
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_InitialSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].InitialSilenceTimeoutMs, config, queryParams, endpoint);
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_EndSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].EndSilenceTimeoutMs, config, queryParams, endpoint);
        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_StablePartialResultThreshold, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__["QueryParameterNames"].StableIntermediateThreshold, config, queryParams, endpoint);
        const serviceProperties = JSON.parse(config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServicePropertiesPropertyName"], "{}"));
        Object.keys(serviceProperties).forEach((value, num, array) => {
            queryParams[value] = serviceProperties[value];
        });
    }
    setUrlParameter(propId, parameterName, config, queryParams, endpoint) {
        const value = config.parameters.getProperty(propId, undefined);
        if (value && (!endpoint || endpoint.search(parameterName) === -1)) {
            queryParams[parameterName] = value.toLocaleLowerCase();
        }
    }
}

//# sourceMappingURL=ConnectionFactoryBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js ***!
  \************************************************************************************************************************/
/*! exports provided: DialogConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogConnectionFactory", function() { return DialogConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var _a;







class DialogConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__["ConnectionFactoryBase"] {
    constructor() {
        super(...arguments);
        this.create = (config, authInfo, connectionId) => {
            const applicationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, "");
            const dialogType = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType);
            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region);
            const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage, "en-US");
            const requestTurnStatus = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_Request_Bot_Status_Messages, "true");
            const queryParams = {};
            queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].ConnectionId] = connectionId;
            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["OutputFormatPropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"].Simple]).toLowerCase();
            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Language] = language;
            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].RequestBotStatusMessages] = requestTurnStatus;
            if (applicationId) {
                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].BotId] = applicationId;
                if (dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConfig"].DialogTypes.CustomCommands) {
                    queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].CustomCommandsAppId] = applicationId;
                }
            }
            const resourceInfix = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConfig"].DialogTypes.CustomCommands ? "commands/"
                : "";
            const version = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConfig"].DialogTypes.CustomCommands ? "v1"
                : dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["DialogServiceConfig"].DialogTypes.BotFramework ? "v3"
                    : "v0";
            const headers = {};
            if (authInfo.token != null && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            // The URL used for connection is chosen in a priority order of specification:
            //  1. If a custom endpoint is provided, that URL is used verbatim.
            //  2. If a custom host is provided (e.g. "wss://my.custom.endpoint.com:1123"), a URL is constructed from it.
            //  3. If no custom connection details are provided, a URL is constructed from default values.
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint, "");
            if (!endpoint) {
                const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
                const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.Constants.BaseUrl}${hostSuffix}`);
                const standardizedHost = host.endsWith("/") ? host : host + "/";
                endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.Constants.ApiKey}/${version}`;
            }
            this.setCommonUrlParams(config, queryParams, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
        };
    }
}
DialogConnectionFactory.Constants = (_a = class {
    },
    _a.ApiKey = "api",
    _a.BaseUrl = "convai.speech",
    _a);

//# sourceMappingURL=DialogConnectorFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js ***!
  \**********************************************************************************************************************/
/*! exports provided: DialogServiceAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceAdapter", function() { return DialogServiceAdapter; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _common_DialogEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/DialogEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./DialogServiceTurnStateManager */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};









class DialogServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_6__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);
        this.sendAgentConfig = (connection) => {
            if (this.agentConfig && !this.agentConfigSent) {
                if (this.privRecognizerConfig
                    .parameters
                    .getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].Conversation_DialogType) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["DialogServiceConfig"].DialogTypes.CustomCommands) {
                    const config = this.agentConfig.get();
                    config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_RecoLanguage, "en-us");
                    this.agentConfig.set(config);
                }
                this.onEvent(new _common_DialogEvents__WEBPACK_IMPORTED_MODULE_1__["SendingAgentContextMessageEvent"](this.agentConfig));
                const agentConfigJson = this.agentConfig.toJsonString();
                // guard against sending this multiple times on one connection
                this.agentConfigSent = true;
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__["MessageType"].Text, "agent.config", this.privRequestSession.requestId, "application/json", agentConfigJson));
            }
            return;
        };
        this.sendAgentContext = (connection) => {
            const guid = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["createGuid"])();
            const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].Conversation_Speech_Activity_Template);
            const agentContext = {
                channelData: "",
                context: {
                    interactionId: guid
                },
                messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,
                version: 0.5
            };
            const agentContextJson = JSON.stringify(agentContext);
            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__["MessageType"].Text, "speech.agent.context", this.privRequestSession.requestId, "application/json", agentContextJson));
        };
        this.handleResponseMessage = (responseMessage) => {
            // "response" messages can contain either "message" (activity) or "MessageStatus" data. Fire the appropriate
            // event according to the message type that's specified.
            const responsePayload = JSON.parse(responseMessage.textBody);
            switch (responsePayload.messageType.toLowerCase()) {
                case "message":
                    const responseRequestId = responseMessage.requestId.toUpperCase();
                    const activityPayload = _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_7__["ActivityPayloadResponse"].fromJSON(responseMessage.textBody);
                    const turn = this.privTurnStateManager.GetTurn(responseRequestId);
                    // update the conversation Id
                    if (activityPayload.conversationId) {
                        const updateAgentConfig = this.agentConfig.get();
                        updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;
                        this.agentConfig.set(updateAgentConfig);
                    }
                    const pullAudioOutputStream = turn.processActivityPayload(activityPayload, _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__["AudioOutputFormatImpl"].fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, undefined)));
                    const activity = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["ActivityReceivedEventArgs"](activityPayload.messagePayload, pullAudioOutputStream);
                    if (!!this.privDialogServiceConnector.activityReceived) {
                        try {
                            this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    break;
                case "messagestatus":
                    if (!!this.privDialogServiceConnector.turnStatusReceived) {
                        try {
                            this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["TurnStatusReceivedEventArgs"](responseMessage.textBody));
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    break;
                default:
                    _common_Exports__WEBPACK_IMPORTED_MODULE_2__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["BackgroundEvent"](`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));
                    break;
            }
        };
        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["EventSource"]();
        this.privDialogServiceConnector = dialogServiceConnector;
        this.receiveMessageOverride = this.receiveDialogMessageOverride;
        this.privTurnStateManager = new _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_5__["DialogServiceTurnStateManager"]();
        this.recognizeOverride = this.listenOnce;
        this.postConnectImplOverride = this.dialogConnectImpl;
        this.configConnectionOverride = this.configConnection;
        this.disconnectOverride = this.privDisconnect;
        this.privDialogAudioSource = audioSource;
        this.agentConfigSent = false;
        this.privLastResult = null;
        this.connectionEvents.attach((connectionEvent) => __awaiter(this, void 0, void 0, function* () {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                this.terminateMessageLoop = true;
            }
        }));
    }
    sendMessage(message) {
        return __awaiter(this, void 0, void 0, function* () {
            const interactionGuid = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["createGuid"])();
            const requestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["createNoDashGuid"])();
            const agentMessage = {
                context: {
                    interactionId: interactionGuid
                },
                messagePayload: JSON.parse(message),
                version: 0.5
            };
            const agentMessageJson = JSON.stringify(agentMessage);
            const connection = yield this.fetchConnection();
            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__["MessageType"].Text, "agent", requestId, "application/json", agentMessageJson));
        });
    }
    privDisconnect() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationErrorCode"].NoError, "Disconnecting");
            this.terminateMessageLoop = true;
            this.agentConfigSent = false;
            return;
        });
    }
    processTypeSpecificMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyCollection"]();
            if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__["MessageType"].Text) {
                resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);
            }
            let result;
            let processed;
            switch (connectionMessage.path.toLowerCase()) {
                case "speech.phrase":
                    const speechPhrase = _Exports__WEBPACK_IMPORTED_MODULE_6__["SimpleSpeechPhrase"].fromJSON(connectionMessage.textBody);
                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);
                    if (speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__["RecognitionStatus"].TooManyRequests && speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__["RecognitionStatus"].Error) {
                        const args = this.fireEventForResult(speechPhrase, resultProps);
                        this.privLastResult = args.result;
                        if (!!this.privDialogServiceConnector.recognized) {
                            try {
                                this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);
                                /* tslint:disable:no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                    }
                    processed = true;
                    break;
                case "speech.hypothesis":
                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_6__["SpeechHypothesis"].fromJSON(connectionMessage.textBody);
                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionResult"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["ResultReason"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);
                    this.privRequestSession.onHypothesis(offset);
                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionEventArgs"](result, hypothesis.Duration, this.privRequestSession.sessionId);
                    if (!!this.privDialogServiceConnector.recognizing) {
                        try {
                            this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "speech.keyword":
                    const keyword = _Exports__WEBPACK_IMPORTED_MODULE_6__["SpeechKeyword"].fromJSON(connectionMessage.textBody);
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionResult"](this.privRequestSession.requestId, keyword.Status === "Accepted" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["ResultReason"].RecognizedKeyword : _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["ResultReason"].NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);
                    if (keyword.Status !== "Accepted") {
                        this.privLastResult = result;
                    }
                    const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionEventArgs"](result, result.duration, result.resultId);
                    if (!!this.privDialogServiceConnector.recognized) {
                        try {
                            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "audio":
                    {
                        const audioRequestId = connectionMessage.requestId.toUpperCase();
                        const turn = this.privTurnStateManager.GetTurn(audioRequestId);
                        try {
                            // Empty binary message signals end of stream.
                            if (!connectionMessage.binaryBody) {
                                turn.endAudioStream();
                            }
                            else {
                                turn.audioStream.write(connectionMessage.binaryBody);
                            }
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "response":
                    {
                        this.handleResponseMessage(connectionMessage);
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        return __awaiter(this, void 0, void 0, function* () {
            this.terminateMessageLoop = true;
            if (!!this.privRequestSession.isRecognizing) {
                yield this.privRequestSession.onStopRecognizing();
            }
            if (!!this.privDialogServiceConnector.canceled) {
                const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyCollection"]();
                properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationErrorCode"][errorCode]);
                const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionCanceledEventArgs"](cancellationReason, error, errorCode, undefined, sessionId);
                try {
                    this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);
                    /* tslint:disable:no-empty */
                }
                catch (_a) { }
                if (!!this.privSuccessCallback) {
                    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionResult"](undefined, // ResultId
                    _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["ResultReason"].Canceled, undefined, // Text
                    undefined, // Duration
                    undefined, // Offset
                    undefined, // Language
                    undefined, // Language Detection Confidence
                    undefined, // Speaker Id
                    error, undefined, // Json
                    properties);
                    try {
                        this.privSuccessCallback(result);
                        this.privSuccessCallback = undefined;
                        /* tslint:disable:no-empty */
                    }
                    catch (_b) { }
                }
            }
        });
    }
    listenOnce(recoMode, successCallback, errorCallback) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privRecognizerConfig.recognitionMode = recoMode;
            this.privSuccessCallback = successCallback;
            this.privErrorCallback = errorCallback;
            this.privRequestSession.startNewRecognition();
            this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);
            this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].Speech_SessionId, this.privRequestSession.sessionId);
            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
            const conPromise = this.connectImpl();
            const preAudioPromise = this.sendPreAudioMessages();
            const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);
            const format = yield this.privDialogAudioSource.format;
            const deviceInfo = yield this.privDialogAudioSource.deviceInfo;
            const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ReplayableAudioNode"](node, format.avgBytesPerSec);
            yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
            this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
            try {
                yield conPromise;
                yield preAudioPromise;
            }
            catch (error) {
                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationErrorCode"].ConnectionFailure, error);
                return Promise.resolve();
            }
            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SessionEventArgs"](this.privRequestSession.sessionId);
            if (!!this.privRecognizer.sessionStarted) {
                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
            }
            const audioSendPromise = this.sendAudio(audioNode);
            // /* tslint:disable:no-empty */
            audioSendPromise.then(() => { }, (error) => __awaiter(this, void 0, void 0, function* () {
                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationErrorCode"].RuntimeError, error);
            }));
        });
    }
    // Establishes a websocket connection to the end point.
    dialogConnectImpl(connection) {
        this.privConnectionLoop = this.startMessageLoop();
        return connection;
    }
    receiveDialogMessageOverride() {
        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
        const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["Deferred"]();
        const loop = () => __awaiter(this, void 0, void 0, function* () {
            try {
                const isDisposed = this.isDisposed();
                const terminateMessageLoop = (!this.isDisposed() && this.terminateMessageLoop);
                if (isDisposed || terminateMessageLoop) {
                    // We're done.
                    communicationCustodian.resolve(undefined);
                    return;
                }
                const connection = yield this.fetchConnection();
                const message = yield connection.read();
                if (!message) {
                    return loop();
                }
                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__["SpeechConnectionMessage"].fromConnectionMessage(message);
                switch (connectionMessage.path.toLowerCase()) {
                    case "turn.start":
                        {
                            const turnRequestId = connectionMessage.requestId.toUpperCase();
                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
                            // turn started by the service
                            if (turnRequestId !== audioSessionReqId) {
                                this.privTurnStateManager.StartTurn(turnRequestId);
                            }
                            else {
                                this.privRequestSession.onServiceTurnStartResponse();
                            }
                        }
                        break;
                    case "speech.startdetected":
                        const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_6__["SpeechDetected"].fromJSON(connectionMessage.textBody);
                        const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["RecognitionEventArgs"](speechStartDetected.Offset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechStartDetected) {
                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
                        }
                        break;
                    case "speech.enddetected":
                        let json;
                        if (connectionMessage.textBody.length > 0) {
                            json = connectionMessage.textBody;
                        }
                        else {
                            // If the request was empty, the JSON returned is empty.
                            json = "{ Offset: 0 }";
                        }
                        const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_6__["SpeechDetected"].fromJSON(json);
                        this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);
                        const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["RecognitionEventArgs"](speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechEndDetected) {
                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
                        }
                        break;
                    case "turn.end":
                        {
                            const turnEndRequestId = connectionMessage.requestId.toUpperCase();
                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
                            // turn started by the service
                            if (turnEndRequestId !== audioSessionReqId) {
                                this.privTurnStateManager.CompleteTurn(turnEndRequestId);
                            }
                            else {
                                // Audio session turn
                                const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SessionEventArgs"](this.privRequestSession.sessionId);
                                yield this.privRequestSession.onServiceTurnEndResponse(false);
                                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                                    if (!!this.privRecognizer.sessionStopped) {
                                        this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                                    }
                                }
                                // report result to promise.
                                if (!!this.privSuccessCallback && this.privLastResult) {
                                    try {
                                        this.privSuccessCallback(this.privLastResult);
                                        this.privLastResult = null;
                                    }
                                    catch (e) {
                                        if (!!this.privErrorCallback) {
                                            this.privErrorCallback(e);
                                        }
                                    }
                                    // Only invoke the call back once.
                                    // and if it's successful don't invoke the
                                    // error after that.
                                    this.privSuccessCallback = undefined;
                                    this.privErrorCallback = undefined;
                                }
                            }
                        }
                        break;
                    default:
                        if (!this.processTypeSpecificMessages(connectionMessage)) {
                            if (!!this.serviceEvents) {
                                this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceEvent"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                            }
                        }
                }
                const ret = loop();
                return ret;
            }
            catch (error) {
                this.terminateMessageLoop = true;
                communicationCustodian.resolve();
            }
        });
        loop().catch((reason) => {
            _common_Exports__WEBPACK_IMPORTED_MODULE_2__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["BackgroundEvent"](reason));
        });
        return communicationCustodian.promise;
    }
    startMessageLoop() {
        return __awaiter(this, void 0, void 0, function* () {
            this.terminateMessageLoop = false;
            try {
                yield this.receiveDialogMessageOverride();
            }
            catch (error) {
                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["CancellationErrorCode"].RuntimeError, error);
            }
            return Promise.resolve();
        });
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    configConnection(connection) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.terminateMessageLoop) {
                this.terminateMessageLoop = false;
                return Promise.reject(`Connection to service terminated.`);
            }
            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
            yield this.sendAgentConfig(connection);
            return connection;
        });
    }
    sendPreAudioMessages() {
        return __awaiter(this, void 0, void 0, function* () {
            const connection = yield this.fetchConnection();
            this.addKeywordContextData();
            yield this.sendSpeechContext(connection);
            yield this.sendAgentContext(connection);
            yield this.sendWaveHeader(connection);
        });
    }
    fireEventForResult(serviceResult, properties) {
        const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_6__["EnumTranslation"].implTranslateRecognitionResult(serviceResult.RecognitionStatus);
        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionResult"](this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);
        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__["SpeechRecognitionEventArgs"](result, offset, this.privRequestSession.sessionId);
        return ev;
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        _common_Exports__WEBPACK_IMPORTED_MODULE_2__["Events"].instance.onEvent(event);
    }
    addKeywordContextData() {
        const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect");
        if (keywordPropertyValue === undefined) {
            return;
        }
        const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters
            .getProperty("SPEECH-KeywordsToDetect-Offsets");
        const keywordDurationPropertyValue = this.privRecognizerConfig.parameters
            .getProperty("SPEECH-KeywordsToDetect-Durations");
        const keywords = keywordPropertyValue.split(";");
        const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(";");
        const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(";");
        const keywordDefinitionArray = [];
        for (let i = 0; i < keywords.length; i++) {
            const definition = {};
            definition.text = keywords[i];
            if (i < keywordOffsets.length) {
                definition.offset = Number(keywordOffsets[i]);
            }
            if (i < keywordDurations.length) {
                definition.duration = Number(keywordDurations[i]);
            }
            keywordDefinitionArray.push(definition);
        }
        this.speechContext.setSection("invocationSource", "VoiceActivationWithKeyword");
        this.speechContext.setSection("keywordDetection", [{
                clientDetectedKeywords: keywordDefinitionArray,
                onReject: { action: "EndOfTurn" },
                type: "startTrigger"
            }]);
    }
}

//# sourceMappingURL=DialogServiceAdapter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js ***!
  \************************************************************************************************************************/
/*! exports provided: DialogServiceTurnState */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceTurnState", function() { return DialogServiceTurnState; });
/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class DialogServiceTurnState {
    constructor(manager, requestId) {
        this.privRequestId = requestId;
        this.privIsCompleted = false;
        this.privAudioStream = null;
        this.privTurnManager = manager;
        this.resetTurnEndTimeout();
        // tslint:disable-next-line:no-console
        // console.info("DialogServiceTurnState debugturn start:" + this.privRequestId);
    }
    get audioStream() {
        // Called when is needed to stream.
        this.resetTurnEndTimeout();
        return this.privAudioStream;
    }
    processActivityPayload(payload, audioFormat) {
        if (payload.messageDataStreamType === _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_2__["MessageDataStreamType"].TextToSpeechAudio) {
            this.privAudioStream = _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__["AudioOutputStream"].createPullStream();
            this.privAudioStream.format = (audioFormat !== undefined) ? audioFormat : _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_0__["AudioOutputFormatImpl"].getDefaultOutputFormat();
            // tslint:disable-next-line:no-console
            // console.info("Audio start debugturn:" + this.privRequestId);
        }
        return this.privAudioStream;
    }
    endAudioStream() {
        if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {
            this.privAudioStream.close();
        }
    }
    complete() {
        if (this.privTimeoutToken !== undefined) {
            clearTimeout(this.privTimeoutToken);
        }
        this.endAudioStream();
    }
    resetTurnEndTimeout() {
        if (this.privTimeoutToken !== undefined) {
            clearTimeout(this.privTimeoutToken);
        }
        // tslint:disable-next-line:no-console
        // console.info("Timeout reset debugturn:" + this.privRequestId);
        this.privTimeoutToken = setTimeout(() => {
            // tslint:disable-next-line:no-console
            // console.info("Timeout complete debugturn:" + this.privRequestId);
            this.privTurnManager.CompleteTurn(this.privRequestId);
            return;
        }, 2000);
    }
}

//# sourceMappingURL=DialogServiceTurnState.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: DialogServiceTurnStateManager */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceTurnStateManager", function() { return DialogServiceTurnStateManager; });
/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceTurnState */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class DialogServiceTurnStateManager {
    constructor() {
        this.privTurnMap = new Map();
        return;
    }
    StartTurn(id) {
        if (this.privTurnMap.has(id)) {
            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Service error: There is already a turn with id:" + id);
        }
        const turnState = new _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__["DialogServiceTurnState"](this, id);
        this.privTurnMap.set(id, turnState);
        return this.privTurnMap.get(id);
    }
    GetTurn(id) {
        return this.privTurnMap.get(id);
    }
    CompleteTurn(id) {
        if (!this.privTurnMap.has(id)) {
            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Service error: Received turn end for an unknown turn id:" + id);
        }
        const turnState = this.privTurnMap.get(id);
        turnState.complete();
        this.privTurnMap.delete(id);
        return turnState;
    }
}

//# sourceMappingURL=DialogServiceTurnStateManager.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js ***!
  \***********************************************************************************************************************/
/*! exports provided: DynamicGrammarBuilder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DynamicGrammarBuilder", function() { return DynamicGrammarBuilder; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Responsible for building the object to be sent to the speech service to support dynamic grammars.
 * @class DynamicGrammarBuilder
 */
class DynamicGrammarBuilder {
    // Adds one more reference phrases to the dynamic grammar to send.
    // All added phrases are generic phrases.
    addPhrase(phrase) {
        if (!this.privPhrases) {
            this.privPhrases = [];
        }
        if (phrase instanceof Array) {
            this.privPhrases = this.privPhrases.concat(phrase);
        }
        else {
            this.privPhrases.push(phrase);
        }
    }
    // Clears all phrases stored in the current object.
    clearPhrases() {
        this.privPhrases = undefined;
    }
    // Adds one or more reference grammars to the current grammar.
    addReferenceGrammar(grammar) {
        if (!this.privGrammars) {
            this.privGrammars = [];
        }
        if (grammar instanceof Array) {
            this.privGrammars = this.privGrammars.concat(grammar);
        }
        else {
            this.privGrammars.push(grammar);
        }
    }
    // clears all grammars stored on the recognizer.
    clearGrammars() {
        this.privGrammars = undefined;
    }
    // Generates an object that represents the dynamic grammar used by the Speech Service.
    // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance
    // of a DynamicGrammarBuilder
    generateGrammarObject() {
        if (this.privGrammars === undefined && this.privPhrases === undefined) {
            return undefined;
        }
        const retObj = {};
        retObj.ReferenceGrammars = this.privGrammars;
        if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {
            const retPhrases = [];
            this.privPhrases.forEach((value, index, array) => {
                retPhrases.push({
                    Text: value,
                });
            });
            retObj.Groups = [{ Type: "Generic", Items: retPhrases }];
        }
        return retObj;
    }
}

//# sourceMappingURL=DynamicGrammarBuilder.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js ***!
  \**************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=DynamicGrammarInterfaces.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js ***!
  \*****************************************************************************************************************/
/*! exports provided: EnumTranslation */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "EnumTranslation", function() { return EnumTranslation; });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class EnumTranslation {
    static implTranslateRecognitionResult(recognitionStatus) {
        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].Canceled;
        switch (recognitionStatus) {
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Success:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].RecognizedSpeech;
                break;
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].NoMatch:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].InitialSilenceTimeout:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].BabbleTimeout:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].EndOfDictation:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].NoMatch;
                break;
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Error:
            default:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].Canceled;
                break;
        }
        return reason;
    }
    static implTranslateCancelResult(recognitionStatus) {
        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationReason"].EndOfStream;
        switch (recognitionStatus) {
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Success:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].EndOfDictation:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].NoMatch:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationReason"].EndOfStream;
                break;
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].InitialSilenceTimeout:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].BabbleTimeout:
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Error:
            default:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationReason"].Error;
                break;
        }
        return reason;
    }
    static implTranslateCancelErrorCode(recognitionStatus) {
        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCode"].NoError;
        switch (recognitionStatus) {
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Error:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCode"].ServiceError;
                break;
            case _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].TooManyRequests:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCode"].TooManyRequests;
                break;
            default:
                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCode"].NoError;
                break;
        }
        return reason;
    }
}

//# sourceMappingURL=EnumTranslation.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js ***!
  \*********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OutputFormatPropertyName", function() { return OutputFormatPropertyName; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationErrorCodePropertyName", function() { return CancellationErrorCodePropertyName; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServicePropertiesPropertyName", function() { return ServicePropertiesPropertyName; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ForceDictationPropertyName", function() { return ForceDictationPropertyName; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguagesOpenRangeOptionName", function() { return AutoDetectSourceLanguagesOpenRangeOptionName; });
/* harmony import */ var _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CognitiveSubscriptionKeyAuthentication", function() { return _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__["CognitiveSubscriptionKeyAuthentication"]; });

/* harmony import */ var _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CognitiveTokenAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CognitiveTokenAuthentication", function() { return _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__["CognitiveTokenAuthentication"]; });

/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AuthInfo", function() { return _IAuthentication__WEBPACK_IMPORTED_MODULE_2__["AuthInfo"]; });

/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./IConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js");
/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ISynthesisConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js");
/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./IntentConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentConnectionFactory", function() { return _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__["IntentConnectionFactory"]; });

/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["SpeechRecognitionEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionTriggeredEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["RecognitionTriggeredEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ListeningStartedEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["ListeningStartedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectingToServiceEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["ConnectingToServiceEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionStartedEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["RecognitionStartedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionCompletionStatus", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["RecognitionCompletionStatus"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionEndedEvent", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__["RecognitionEndedEvent"]; });

/* harmony import */ var _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceRecognizerBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServiceRecognizerBase", function() { return _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__["ServiceRecognizerBase"]; });

/* harmony import */ var _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./RecognizerConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionMode", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["RecognitionMode"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechResultFormat", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["SpeechResultFormat"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognizerConfig", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["RecognizerConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechServiceConfig", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["SpeechServiceConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Context", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["Context"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "System", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["System"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OS", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["OS"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Device", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["Device"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "connectivity", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["connectivity"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "type", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__["type"]; });

/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SpeechServiceInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js");
/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo","IntentConnectionFactory","SpeechRecognitionEvent","RecognitionTriggeredEvent","ListeningStartedEvent","ConnectingToServiceEvent","RecognitionStartedEvent","RecognitionCompletionStatus","RecognitionEndedEvent","ServiceRecognizerBase","RecognitionMode","SpeechResultFormat","RecognizerConfig","SpeechServiceConfig","Context","System","OS","Device","connectivity","type"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./WebsocketMessageFormatter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "WebsocketMessageFormatter", function() { return _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__["WebsocketMessageFormatter"]; });

/* harmony import */ var _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./SpeechConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechConnectionFactory", function() { return _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__["SpeechConnectionFactory"]; });

/* harmony import */ var _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./TranscriberConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranscriberConnectionFactory", function() { return _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__["TranscriberConnectionFactory"]; });

/* harmony import */ var _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./TranslationConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationConnectionFactory", function() { return _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__["TranslationConnectionFactory"]; });

/* harmony import */ var _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechSynthesisConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisConnectionFactory", function() { return _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__["SpeechSynthesisConnectionFactory"]; });

/* harmony import */ var _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./EnumTranslation */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "EnumTranslation", function() { return _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__["EnumTranslation"]; });

/* harmony import */ var _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./ServiceMessages/Enums */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisStatus", function() { return _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__["SynthesisStatus"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionStatus", function() { return _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__["RecognitionStatus"]; });

/* harmony import */ var _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisEnd", function() { return _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__["TranslationSynthesisEnd"]; });

/* harmony import */ var _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./ServiceMessages/TranslationHypothesis */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationHypothesis", function() { return _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__["TranslationHypothesis"]; });

/* harmony import */ var _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./ServiceMessages/TranslationPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationPhrase", function() { return _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__["TranslationPhrase"]; });

/* harmony import */ var _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationServiceRecognizer", function() { return _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__["TranslationServiceRecognizer"]; });

/* harmony import */ var _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./ServiceMessages/SpeechDetected */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechDetected", function() { return _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__["SpeechDetected"]; });

/* harmony import */ var _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ServiceMessages/SpeechHypothesis */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechHypothesis", function() { return _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__["SpeechHypothesis"]; });

/* harmony import */ var _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./ServiceMessages/SpeechKeyword */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechKeyword", function() { return _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__["SpeechKeyword"]; });

/* harmony import */ var _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechServiceRecognizer", function() { return _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__["SpeechServiceRecognizer"]; });

/* harmony import */ var _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./TranscriptionServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranscriptionServiceRecognizer", function() { return _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__["TranscriptionServiceRecognizer"]; });

/* harmony import */ var _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DetailedSpeechPhrase", function() { return _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__["DetailedSpeechPhrase"]; });

/* harmony import */ var _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SimpleSpeechPhrase", function() { return _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__["SimpleSpeechPhrase"]; });

/* harmony import */ var _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./AddedLmIntent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AddedLmIntent", function() { return _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__["AddedLmIntent"]; });

/* harmony import */ var _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentServiceRecognizer", function() { return _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__["IntentServiceRecognizer"]; });

/* harmony import */ var _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/IntentResponse */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentResponse", function() { return _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__["IntentResponse"]; });

/* harmony import */ var _RequestSession__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./RequestSession */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RequestSession", function() { return _RequestSession__WEBPACK_IMPORTED_MODULE_31__["RequestSession"]; });

/* harmony import */ var _SpeechContext__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./SpeechContext */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechContext", function() { return _SpeechContext__WEBPACK_IMPORTED_MODULE_32__["SpeechContext"]; });

/* harmony import */ var _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./DynamicGrammarBuilder */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DynamicGrammarBuilder", function() { return _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__["DynamicGrammarBuilder"]; });

/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./DynamicGrammarInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js");
/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34___default = /*#__PURE__*/__webpack_require__.n(_DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo","IntentConnectionFactory","SpeechRecognitionEvent","RecognitionTriggeredEvent","ListeningStartedEvent","ConnectingToServiceEvent","RecognitionStartedEvent","RecognitionCompletionStatus","RecognitionEndedEvent","ServiceRecognizerBase","RecognitionMode","SpeechResultFormat","RecognizerConfig","SpeechServiceConfig","Context","System","OS","Device","connectivity","type","WebsocketMessageFormatter","SpeechConnectionFactory","TranscriberConnectionFactory","TranslationConnectionFactory","SpeechSynthesisConnectionFactory","EnumTranslation","SynthesisStatus","RecognitionStatus","TranslationSynthesisEnd","TranslationHypothesis","TranslationPhrase","TranslationServiceRecognizer","SpeechDetected","SpeechHypothesis","SpeechKeyword","SpeechServiceRecognizer","TranscriptionServiceRecognizer","DetailedSpeechPhrase","SimpleSpeechPhrase","AddedLmIntent","IntentServiceRecognizer","IntentResponse","RequestSession","SpeechContext","DynamicGrammarBuilder"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./DialogServiceAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogServiceAdapter", function() { return _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__["DialogServiceAdapter"]; });

/* harmony import */ var _AgentConfig__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./AgentConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AgentConfig", function() { return _AgentConfig__WEBPACK_IMPORTED_MODULE_36__["AgentConfig"]; });

/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationManager", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationManager"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationConnectionConfig", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationConnectionConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationRecognizerFactory", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationRecognizerFactory"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranscriberRecognizer", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["TranscriberRecognizer"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationReceivedTranslationEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationReceivedTranslationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "LockRoomEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["LockRoomEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MuteAllEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["MuteAllEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantAttributeEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ParticipantAttributeEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ParticipantEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantsListEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ParticipantsListEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorCommandTypes", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationTranslatorCommandTypes"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorMessageTypes", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["ConversationTranslatorMessageTypes"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "InternalParticipants", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__["InternalParticipants"]; });

/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MetadataType", function() { return _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__["MetadataType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisAudioMetadata", function() { return _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__["SynthesisAudioMetadata"]; });

/* harmony import */ var _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./SynthesisTurn */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisTurn", function() { return _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__["SynthesisTurn"]; });

/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./SynthesisAdapterBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisAdapterBase", function() { return _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__["SynthesisAdapterBase"]; });

/* harmony import */ var _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./SynthesizerConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisServiceType", function() { return _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_41__["SynthesisServiceType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesizerConfig", function() { return _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_41__["SynthesizerConfig"]; });

/* harmony import */ var _SynthesisContext__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./SynthesisContext */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SynthesisContext", function() { return _SynthesisContext__WEBPACK_IMPORTED_MODULE_42__["SynthesisContext"]; });

/* harmony import */ var _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./SpeakerRecognitionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionConfig", function() { return _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_43__["SpeakerRecognitionConfig"]; });

/* harmony import */ var _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./SpeakerIdMessageAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerIdMessageAdapter", function() { return _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_44__["SpeakerIdMessageAdapter"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Make sure not to export internal modules.
//













































const OutputFormatPropertyName = "OutputFormat";
const CancellationErrorCodePropertyName = "CancellationErrorCode";
const ServicePropertiesPropertyName = "ServiceProperties";
const ForceDictationPropertyName = "ForceDictation";
const AutoDetectSourceLanguagesOpenRangeOptionName = "OpenRange";

//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js ***!
  \*************************************************************************************************************/
/*! exports provided: HeaderNames */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "HeaderNames", function() { return HeaderNames; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class HeaderNames {
}
HeaderNames.AuthKey = "Ocp-Apim-Subscription-Key";
HeaderNames.ConnectionId = "X-ConnectionId";
HeaderNames.ContentType = "Content-Type";
HeaderNames.CustomCommandsAppId = "X-CommandsAppId";
HeaderNames.Path = "Path";
HeaderNames.RequestId = "X-RequestId";
HeaderNames.RequestStreamId = "X-StreamId";
HeaderNames.RequestTimestamp = "X-Timestamp";

//# sourceMappingURL=HeaderNames.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js ***!
  \*****************************************************************************************************************/
/*! exports provided: AuthInfo */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AuthInfo", function() { return AuthInfo; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class AuthInfo {
    constructor(headerName, token) {
        this.privHeaderName = headerName;
        this.privToken = token;
    }
    get headerName() {
        return this.privHeaderName;
    }
    get token() {
        return this.privToken;
    }
}

//# sourceMappingURL=IAuthentication.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js ***!
  \********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=ISynthesisConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js ***!
  \*************************************************************************************************************************/
/*! exports provided: IntentConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentConnectionFactory", function() { return IntentConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.





class IntentConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__["ConnectionFactoryBase"] {
    constructor() {
        super(...arguments);
        this.create = (config, authInfo, connectionId) => {
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint);
            if (!endpoint) {
                const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_IntentRegion);
                const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
                const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Host, "wss://" + region + ".sr.speech" + hostSuffix);
                endpoint = host + "/speech/recognition/interactive/cognitiveservices/v1";
            }
            const queryParams = {
                format: "simple",
                language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_RecoLanguage),
            };
            this.setCommonUrlParams(config, queryParams, endpoint);
            const headers = {};
            if (authInfo.token !== undefined && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].ConnectionId] = connectionId;
            config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Url, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
        };
    }
    getSpeechRegionFromIntentRegion(intentRegion) {
        switch (intentRegion) {
            case "West US":
            case "US West":
            case "westus":
                return "uswest";
            case "West US 2":
            case "US West 2":
            case "westus2":
                return "uswest2";
            case "South Central US":
            case "US South Central":
            case "southcentralus":
                return "ussouthcentral";
            case "West Central US":
            case "US West Central":
            case "westcentralus":
                return "uswestcentral";
            case "East US":
            case "US East":
            case "eastus":
                return "useast";
            case "East US 2":
            case "US East 2":
            case "eastus2":
                return "useast2";
            case "West Europe":
            case "Europe West":
            case "westeurope":
                return "europewest";
            case "North Europe":
            case "Europe North":
            case "northeurope":
                return "europenorth";
            case "Brazil South":
            case "South Brazil":
            case "southbrazil":
                return "brazilsouth";
            case "Australia East":
            case "East Australia":
            case "eastaustralia":
                return "australiaeast";
            case "Southeast Asia":
            case "Asia Southeast":
            case "southeastasia":
                return "asiasoutheast";
            case "East Asia":
            case "Asia East":
            case "eastasia":
                return "asiaeast";
            default:
                return intentRegion;
        }
    }
}

//# sourceMappingURL=IntentConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/*! exports provided: IntentServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentServiceRecognizer", function() { return IntentServiceRecognizer; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



// tslint:disable-next-line:max-classes-per-file
class IntentServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
        this.privIntentRecognizer = recognizer;
        this.privIntentDataSent = false;
    }
    setIntents(addedIntents, umbrellaIntent) {
        this.privAddedLmIntents = addedIntents;
        this.privUmbrellaIntent = umbrellaIntent;
        this.privIntentDataSent = true;
    }
    processTypeSpecificMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            let result;
            let ev;
            let processed = false;
            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
            if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);
            }
            switch (connectionMessage.path.toLowerCase()) {
                case "speech.hypothesis":
                    const speechHypothesis = _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechHypothesis"].fromJSON(connectionMessage.textBody);
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionResult"](undefined, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);
                    this.privRequestSession.onHypothesis(result.offset);
                    ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionEventArgs"](result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
                    if (!!this.privIntentRecognizer.recognizing) {
                        try {
                            this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "speech.phrase":
                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_2__["SimpleSpeechPhrase"].fromJSON(connectionMessage.textBody);
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionResult"](undefined, this.privRequestSession.requestId, _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);
                    ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionEventArgs"](result, result.offset, this.privRequestSession.sessionId);
                    const sendEvent = () => {
                        if (!!this.privIntentRecognizer.recognized) {
                            try {
                                this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
                                /* tslint:disable:no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                        // report result to promise.
                        if (!!this.privSuccessCallback) {
                            try {
                                this.privSuccessCallback(result);
                            }
                            catch (e) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(e);
                                }
                            }
                            // Only invoke the call back once.
                            // and if it's successful don't invoke the
                            // error after that.
                            this.privSuccessCallback = undefined;
                            this.privErrorCallback = undefined;
                        }
                    };
                    // If intent data was sent, the terminal result for this recognizer is an intent being found.
                    // If no intent data was sent, the terminal event is speech recognition being successful.
                    if (false === this.privIntentDataSent || _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].NoMatch === ev.result.reason) {
                        // Advance the buffers.
                        this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
                        sendEvent();
                    }
                    else {
                        // Squirrel away the args, when the response event arrives it will build upon them
                        // and then return
                        this.privPendingIntentArgs = ev;
                    }
                    processed = true;
                    break;
                case "response":
                    // Response from LUIS
                    ev = this.privPendingIntentArgs;
                    this.privPendingIntentArgs = undefined;
                    if (undefined === ev) {
                        if ("" === connectionMessage.textBody) {
                            // This condition happens if there is nothing but silence in the
                            // audio sent to the service.
                            return;
                        }
                        // Odd... Not sure this can happen
                        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionEventArgs"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionResult"](), 0 /*TODO*/, this.privRequestSession.sessionId);
                    }
                    const intentResponse = _Exports__WEBPACK_IMPORTED_MODULE_2__["IntentResponse"].fromJSON(connectionMessage.textBody);
                    // If LUIS didn't return anything, send the existing event, else
                    // modify it to show the match.
                    // See if the intent found is in the list of intents asked for.
                    let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];
                    if (this.privUmbrellaIntent !== undefined) {
                        addedIntent = this.privUmbrellaIntent;
                    }
                    if (null !== intentResponse && addedIntent !== undefined) {
                        const intentId = addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;
                        let reason = ev.result.reason;
                        if (undefined !== intentId) {
                            reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].RecognizedIntent;
                        }
                        // make sure, properties is set.
                        const properties = (undefined !== ev.result.properties) ?
                            ev.result.properties : new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
                        properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);
                        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionEventArgs"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionResult"](intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);
                    }
                    this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
                    if (!!this.privIntentRecognizer.recognized) {
                        try {
                            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    // report result to promise.
                    if (!!this.privSuccessCallback) {
                        try {
                            this.privSuccessCallback(ev.result);
                        }
                        catch (e) {
                            if (!!this.privErrorCallback) {
                                this.privErrorCallback(e);
                            }
                        }
                        // Only invoke the call back once.
                        // and if it's successful don't invoke the
                        // error after that.
                        this.privSuccessCallback = undefined;
                        this.privErrorCallback = undefined;
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][errorCode]);
        if (!!this.privIntentRecognizer.canceled) {
            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionCanceledEventArgs"](cancellationReason, error, errorCode, undefined, undefined, sessionId);
            try {
                this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);
                /* tslint:disable:no-empty */
            }
            catch (_a) { }
        }
        if (!!this.privSuccessCallback) {
            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["IntentRecognitionResult"](undefined, // Intent Id
            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled, undefined, // Text
            undefined, // Duration
            undefined, // Offset
            undefined, // Language
            undefined, // LanguageDetectionConfidence
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                this.privSuccessCallback = undefined;
                /* tslint:disable:no-empty */
            }
            catch (_b) { }
        }
    }
}

//# sourceMappingURL=IntentServiceRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js ***!
  \*********************************************************************************************************************/
/*! exports provided: QueryParameterNames */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "QueryParameterNames", function() { return QueryParameterNames; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class QueryParameterNames {
}
QueryParameterNames.BotId = "botid";
QueryParameterNames.CustomSpeechDeploymentId = "cid";
QueryParameterNames.CustomVoiceDeploymentId = "deploymentId";
QueryParameterNames.EnableAudioLogging = "storeAudio";
QueryParameterNames.EnableLanguageId = "lidEnabled";
QueryParameterNames.EnableWordLevelTimestamps = "wordLevelTimestamps";
QueryParameterNames.EndSilenceTimeoutMs = "endSilenceTimeoutMs";
QueryParameterNames.Format = "format";
QueryParameterNames.InitialSilenceTimeoutMs = "initialSilenceTimeoutMs";
QueryParameterNames.Language = "language";
QueryParameterNames.Profanity = "profanity";
QueryParameterNames.RequestBotStatusMessages = "enableBotMessageStatus";
QueryParameterNames.StableIntermediateThreshold = "stableIntermediateThreshold";
QueryParameterNames.StableTranslation = "stableTranslation";
QueryParameterNames.TestHooks = "testhooks";

//# sourceMappingURL=QueryParameterNames.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SpeechRecognitionEvent, RecognitionTriggeredEvent, ListeningStartedEvent, ConnectingToServiceEvent, RecognitionStartedEvent, RecognitionCompletionStatus, RecognitionEndedEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionEvent", function() { return SpeechRecognitionEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionTriggeredEvent", function() { return RecognitionTriggeredEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ListeningStartedEvent", function() { return ListeningStartedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectingToServiceEvent", function() { return ConnectingToServiceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionStartedEvent", function() { return RecognitionStartedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionCompletionStatus", function() { return RecognitionCompletionStatus; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionEndedEvent", function() { return RecognitionEndedEvent; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file

class SpeechRecognitionEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, requestId, sessionId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
        this.privRequestId = requestId;
        this.privSessionId = sessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get sessionId() {
        return this.privSessionId;
    }
}
class RecognitionTriggeredEvent extends SpeechRecognitionEvent {
    constructor(requestId, sessionId, audioSourceId, audioNodeId) {
        super("RecognitionTriggeredEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
class ListeningStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId, sessionId, audioSourceId, audioNodeId) {
        super("ListeningStartedEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
class ConnectingToServiceEvent extends SpeechRecognitionEvent {
    constructor(requestId, authFetchEventid, sessionId) {
        super("ConnectingToServiceEvent", requestId, sessionId);
        this.privAuthFetchEventid = authFetchEventid;
    }
    get authFetchEventid() {
        return this.privAuthFetchEventid;
    }
}
class RecognitionStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {
        super("RecognitionStartedEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privAuthFetchEventId = authFetchEventId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}
var RecognitionCompletionStatus;
(function (RecognitionCompletionStatus) {
    RecognitionCompletionStatus[RecognitionCompletionStatus["Success"] = 0] = "Success";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceError"] = 1] = "AudioSourceError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceTimeout"] = 2] = "AudioSourceTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchError"] = 3] = "AuthTokenFetchError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchTimeout"] = 4] = "AuthTokenFetchTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["UnAuthorized"] = 5] = "UnAuthorized";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectTimeout"] = 6] = "ConnectTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectError"] = 7] = "ConnectError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ClientRecognitionActivityTimeout"] = 8] = "ClientRecognitionActivityTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["UnknownError"] = 9] = "UnknownError";
})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));
class RecognitionEndedEvent extends SpeechRecognitionEvent {
    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {
        super("RecognitionEndedEvent", requestId, sessionId, status === RecognitionCompletionStatus.Success ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info : _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Error);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privAuthFetchEventId = authFetchEventId;
        this.privStatus = status;
        this.privError = error;
        this.privServiceTag = serviceTag;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
    get serviceTag() {
        return this.privServiceTag;
    }
    get status() {
        return this.privStatus;
    }
    get error() {
        return this.privError;
    }
}

//# sourceMappingURL=RecognitionEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js ***!
  \******************************************************************************************************************/
/*! exports provided: RecognitionMode, SpeechResultFormat, RecognizerConfig, SpeechServiceConfig, Context, System, OS, Device, connectivity, type */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionMode", function() { return RecognitionMode; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechResultFormat", function() { return SpeechResultFormat; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognizerConfig", function() { return RecognizerConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechServiceConfig", function() { return SpeechServiceConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Context", function() { return Context; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "System", function() { return System; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OS", function() { return OS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Device", function() { return Device; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "connectivity", function() { return connectivity; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "type", function() { return type; });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file

var RecognitionMode;
(function (RecognitionMode) {
    RecognitionMode[RecognitionMode["Interactive"] = 0] = "Interactive";
    RecognitionMode[RecognitionMode["Conversation"] = 1] = "Conversation";
    RecognitionMode[RecognitionMode["Dictation"] = 2] = "Dictation";
})(RecognitionMode || (RecognitionMode = {}));
var SpeechResultFormat;
(function (SpeechResultFormat) {
    SpeechResultFormat[SpeechResultFormat["Simple"] = 0] = "Simple";
    SpeechResultFormat[SpeechResultFormat["Detailed"] = 1] = "Detailed";
})(SpeechResultFormat || (SpeechResultFormat = {}));
class RecognizerConfig {
    constructor(speechServiceConfig, parameters) {
        this.privRecognitionMode = RecognitionMode.Interactive;
        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));
        this.privParameters = parameters;
        this.privMaxRetryCount = parseInt(parameters.getProperty("SPEECH-Error-MaxRetryCount", "4"), 10);
    }
    get parameters() {
        return this.privParameters;
    }
    get recognitionMode() {
        return this.privRecognitionMode;
    }
    set recognitionMode(value) {
        this.privRecognitionMode = value;
        this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;
        this.privSpeechServiceConfig.Recognition = RecognitionMode[value];
    }
    get SpeechServiceConfig() {
        return this.privSpeechServiceConfig;
    }
    get recognitionActivityTimeout() {
        return this.privRecognitionActivityTimeout;
    }
    get isContinuousRecognition() {
        return this.privRecognitionMode !== RecognitionMode.Interactive;
    }
    get autoDetectSourceLanguages() {
        return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages, undefined);
    }
    get maxRetryCount() {
        return this.privMaxRetryCount;
    }
}
// The config is serialized and sent as the Speech.Config
class SpeechServiceConfig {
    constructor(context) {
        this.serialize = () => {
            return JSON.stringify(this, (key, value) => {
                if (value && typeof value === "object") {
                    const replacement = {};
                    for (const k in value) {
                        if (Object.hasOwnProperty.call(value, k)) {
                            replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];
                        }
                    }
                    return replacement;
                }
                return value;
            });
        };
        this.context = context;
    }
    get Context() {
        return this.context;
    }
    get Recognition() {
        return this.recognition;
    }
    set Recognition(value) {
        this.recognition = value.toLowerCase();
    }
}
class Context {
    constructor(os) {
        this.system = new System();
        this.os = os;
    }
}
class System {
    constructor() {
        // Note: below will be patched for official builds.
        const SPEECHSDK_CLIENTSDK_VERSION = "1.18.1";
        this.name = "SpeechSDK";
        this.version = SPEECHSDK_CLIENTSDK_VERSION;
        this.build = "JavaScript";
        this.lang = "JavaScript";
    }
}
class OS {
    constructor(platform, name, version) {
        this.platform = platform;
        this.name = name;
        this.version = version;
    }
}
class Device {
    constructor(manufacturer, model, version) {
        this.manufacturer = manufacturer;
        this.model = model;
        this.version = version;
    }
}
var connectivity;
(function (connectivity) {
    connectivity["Bluetooth"] = "Bluetooth";
    connectivity["Wired"] = "Wired";
    connectivity["WiFi"] = "WiFi";
    connectivity["Cellular"] = "Cellular";
    connectivity["InBuilt"] = "InBuilt";
    connectivity["Unknown"] = "Unknown";
})(connectivity || (connectivity = {}));
var type;
(function (type) {
    type["Phone"] = "Phone";
    type["Speaker"] = "Speaker";
    type["Car"] = "Car";
    type["Headset"] = "Headset";
    type["Thermostat"] = "Thermostat";
    type["Microphones"] = "Microphones";
    type["Deskphone"] = "Deskphone";
    type["RemoteControl"] = "RemoteControl";
    type["Unknown"] = "Unknown";
    type["File"] = "File";
    type["Stream"] = "Stream";
})(type || (type = {}));

//# sourceMappingURL=RecognizerConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js ***!
  \****************************************************************************************************************/
/*! exports provided: RequestSession */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RequestSession", function() { return RequestSession; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
/* harmony import */ var _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceTelemetryListener.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



class RequestSession {
    constructor(audioSourceId) {
        this.privIsDisposed = false;
        this.privDetachables = new Array();
        this.privIsAudioNodeDetached = false;
        this.privIsRecognizing = false;
        this.privIsSpeechEnded = false;
        this.privTurnStartAudioOffset = 0;
        this.privLastRecoOffset = 0;
        this.privHypothesisReceived = false;
        this.privBytesSent = 0;
        this.privRecogNumber = 0;
        this.privInTurn = false;
        this.privConnectionAttempts = 0;
        this.onPreConnectionStart = (authFetchEventId, connectionId) => {
            this.privAuthFetchEventId = authFetchEventId;
            this.privSessionId = connectionId;
            this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectingToServiceEvent"](this.privRequestId, this.privAuthFetchEventId, this.privSessionId));
        };
        this.onServiceTurnStartResponse = () => {
            if (!!this.privTurnDeferral && !!this.privInTurn) {
                // What? How are we starting a turn with another not done?
                this.privTurnDeferral.reject("Another turn started before current completed.");
                // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
                /* tslint:disable:no-empty */
                this.privTurnDeferral.promise.then().catch(() => { });
            }
            this.privInTurn = true;
            this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
        };
        this.getTelemetry = () => {
            if (this.privServiceTelemetryListener.hasTelemetry) {
                return this.privServiceTelemetryListener.getTelemetry();
            }
            else {
                return null;
            }
        };
        this.onEvent = (event) => {
            if (!!this.privServiceTelemetryListener) {
                this.privServiceTelemetryListener.onEvent(event);
            }
            _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Events"].instance.onEvent(event);
        };
        this.privAudioSourceId = audioSourceId;
        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privAudioNodeId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
        // We're not in a turn, so resolve.
        this.privTurnDeferral.resolve();
    }
    get sessionId() {
        return this.privSessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get turnCompletionPromise() {
        return this.privTurnDeferral.promise;
    }
    get isSpeechEnded() {
        return this.privIsSpeechEnded;
    }
    get isRecognizing() {
        return this.privIsRecognizing;
    }
    get currentTurnAudioOffset() {
        return this.privTurnStartAudioOffset;
    }
    get recogNumber() {
        return this.privRecogNumber;
    }
    get numConnectionAttempts() {
        return this.privConnectionAttempts;
    }
    // The number of bytes sent for the current connection.
    // Counter is reset to 0 each time a connection is established.
    get bytesSent() {
        return this.privBytesSent;
    }
    listenForServiceTelemetry(eventSource) {
        if (!!this.privServiceTelemetryListener) {
            this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));
        }
    }
    startNewRecognition() {
        this.privIsSpeechEnded = false;
        this.privIsRecognizing = true;
        this.privTurnStartAudioOffset = 0;
        this.privLastRecoOffset = 0;
        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privRecogNumber++;
        this.privServiceTelemetryListener = new _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__["ServiceTelemetryListener"](this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);
        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["RecognitionTriggeredEvent"](this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
    }
    onAudioSourceAttachCompleted(audioNode, isError, error) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privAudioNode = audioNode;
            this.privIsAudioNodeDetached = false;
            if (isError) {
                yield this.onComplete();
            }
            else {
                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["ListeningStartedEvent"](this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
            }
        });
    }
    onAuthCompleted(isError, error) {
        return __awaiter(this, void 0, void 0, function* () {
            if (isError) {
                yield this.onComplete();
            }
        });
    }
    onConnectionEstablishCompleted(statusCode, reason) {
        return __awaiter(this, void 0, void 0, function* () {
            if (statusCode === 200) {
                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["RecognitionStartedEvent"](this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));
                if (!!this.privAudioNode) {
                    this.privAudioNode.replay();
                }
                this.privTurnStartAudioOffset = this.privLastRecoOffset;
                this.privBytesSent = 0;
                return;
            }
            else if (statusCode === 403) {
                yield this.onComplete();
            }
        });
    }
    onServiceTurnEndResponse(continuousRecognition) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privTurnDeferral.resolve();
            if (!continuousRecognition || this.isSpeechEnded) {
                yield this.onComplete();
                this.privInTurn = false;
            }
            else {
                // Start a new request set.
                this.privTurnStartAudioOffset = this.privLastRecoOffset;
                this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
                this.privAudioNode.replay();
            }
        });
    }
    onHypothesis(offset) {
        if (!this.privHypothesisReceived) {
            this.privHypothesisReceived = true;
            this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));
        }
    }
    onPhraseRecognized(offset) {
        this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));
        this.onServiceRecognized(offset);
    }
    onServiceRecognized(offset) {
        this.privLastRecoOffset = offset;
        this.privHypothesisReceived = false;
        this.privAudioNode.shrinkBuffers(offset);
        this.privConnectionAttempts = 0;
    }
    onAudioSent(bytesSent) {
        this.privBytesSent += bytesSent;
    }
    onRetryConnection() {
        this.privConnectionAttempts++;
    }
    dispose(error) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privIsDisposed) {
                // we should have completed by now. If we did not its an unknown error.
                this.privIsDisposed = true;
                for (const detachable of this.privDetachables) {
                    yield detachable.detach();
                }
                (_a = this.privServiceTelemetryListener) === null || _a === void 0 ? void 0 : _a.dispose();
                this.privIsRecognizing = false;
            }
        });
    }
    onStopRecognizing() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.onComplete();
        });
    }
    // Should be called with the audioNode for this session has indicated that it is out of speech.
    onSpeechEnded() {
        this.privIsSpeechEnded = true;
    }
    onComplete() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privIsRecognizing) {
                this.privIsRecognizing = false;
                yield this.detachAudioNode();
            }
        });
    }
    detachAudioNode() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privIsAudioNodeDetached) {
                this.privIsAudioNodeDetached = true;
                if (this.privAudioNode) {
                    yield this.privAudioNode.detach();
                }
            }
        });
    }
}

//# sourceMappingURL=RequestSession.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \*****************************************************************************************************************************************/
/*! exports provided: ActivityPayloadResponse, MessageDataStreamType */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ActivityPayloadResponse", function() { return ActivityPayloadResponse; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MessageDataStreamType", function() { return MessageDataStreamType; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// response
class ActivityPayloadResponse {
    constructor(json) {
        this.privActivityResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new ActivityPayloadResponse(json);
    }
    get conversationId() {
        return this.privActivityResponse.conversationId;
    }
    get messageDataStreamType() {
        return this.privActivityResponse.messageDataStreamType;
    }
    get messagePayload() {
        return this.privActivityResponse.messagePayload;
    }
    get version() {
        return this.privActivityResponse.version;
    }
}
var MessageDataStreamType;
(function (MessageDataStreamType) {
    MessageDataStreamType[MessageDataStreamType["None"] = 0] = "None";
    MessageDataStreamType[MessageDataStreamType["TextToSpeechAudio"] = 1] = "TextToSpeechAudio";
})(MessageDataStreamType || (MessageDataStreamType = {}));

//# sourceMappingURL=ActivityResponsePayload.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \**************************************************************************************************************************************/
/*! exports provided: DetailedSpeechPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DetailedSpeechPhrase", function() { return DetailedSpeechPhrase; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class DetailedSpeechPhrase {
    constructor(json) {
        this.privDetailedSpeechPhrase = JSON.parse(json);
        this.privDetailedSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionStatus"][this.privDetailedSpeechPhrase.RecognitionStatus];
    }
    static fromJSON(json) {
        return new DetailedSpeechPhrase(json);
    }
    getJsonWithCorrectedOffsets(baseOffset) {
        if (!!this.privDetailedSpeechPhrase.NBest && !!this.privDetailedSpeechPhrase.NBest[0].Words) {
            const firstWordOffset = this.privDetailedSpeechPhrase.NBest[0].Words[0].Offset;
            if (firstWordOffset && firstWordOffset < baseOffset) {
                const offset = baseOffset - firstWordOffset;
                for (const details of this.privDetailedSpeechPhrase.NBest) {
                    for (const word of details.Words) {
                        word.Offset += offset;
                    }
                }
            }
        }
        return JSON.stringify(this.privDetailedSpeechPhrase);
    }
    get RecognitionStatus() {
        return this.privDetailedSpeechPhrase.RecognitionStatus;
    }
    get NBest() {
        return this.privDetailedSpeechPhrase.NBest;
    }
    get Duration() {
        return this.privDetailedSpeechPhrase.Duration;
    }
    get Offset() {
        return this.privDetailedSpeechPhrase.Offset;
    }
    get Language() {
        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;
    }
}

//# sourceMappingURL=DetailedSpeechPhrase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js ***!
  \***********************************************************************************************************************/
/*! exports provided: SynthesisStatus, RecognitionStatus */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisStatus", function() { return SynthesisStatus; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionStatus", function() { return RecognitionStatus; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class SynthesisStatus
 * @private
 */
var SynthesisStatus;
(function (SynthesisStatus) {
    /**
     * The response contains valid audio data.
     * @member SynthesisStatus.Success
     */
    SynthesisStatus[SynthesisStatus["Success"] = 0] = "Success";
    /**
     * Indicates the end of audio data. No valid audio data is included in the message.
     * @member SynthesisStatus.SynthesisEnd
     */
    SynthesisStatus[SynthesisStatus["SynthesisEnd"] = 1] = "SynthesisEnd";
    /**
     * Indicates an error occurred during synthesis data processing.
     * @member SynthesisStatus.Error
     */
    SynthesisStatus[SynthesisStatus["Error"] = 2] = "Error";
})(SynthesisStatus || (SynthesisStatus = {}));
var RecognitionStatus;
(function (RecognitionStatus) {
    RecognitionStatus[RecognitionStatus["Success"] = 0] = "Success";
    RecognitionStatus[RecognitionStatus["NoMatch"] = 1] = "NoMatch";
    RecognitionStatus[RecognitionStatus["InitialSilenceTimeout"] = 2] = "InitialSilenceTimeout";
    RecognitionStatus[RecognitionStatus["BabbleTimeout"] = 3] = "BabbleTimeout";
    RecognitionStatus[RecognitionStatus["Error"] = 4] = "Error";
    RecognitionStatus[RecognitionStatus["EndOfDictation"] = 5] = "EndOfDictation";
    RecognitionStatus[RecognitionStatus["TooManyRequests"] = 6] = "TooManyRequests";
})(RecognitionStatus || (RecognitionStatus = {}));

//# sourceMappingURL=Enums.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js ***!
  \********************************************************************************************************************************/
/*! exports provided: IntentResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentResponse", function() { return IntentResponse; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// response
class IntentResponse {
    constructor(json) {
        this.privIntentResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new IntentResponse(json);
    }
    get query() {
        return this.privIntentResponse.query;
    }
    get topScoringIntent() {
        return this.privIntentResponse.topScoringIntent;
    }
    get entities() {
        return this.privIntentResponse.entities;
    }
}

//# sourceMappingURL=IntentResponse.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \************************************************************************************************************************************/
/*! exports provided: SimpleSpeechPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SimpleSpeechPhrase", function() { return SimpleSpeechPhrase; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SimpleSpeechPhrase {
    constructor(json) {
        this.privSimpleSpeechPhrase = JSON.parse(json);
        this.privSimpleSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionStatus"][this.privSimpleSpeechPhrase.RecognitionStatus];
    }
    static fromJSON(json) {
        return new SimpleSpeechPhrase(json);
    }
    get RecognitionStatus() {
        return this.privSimpleSpeechPhrase.RecognitionStatus;
    }
    get DisplayText() {
        return this.privSimpleSpeechPhrase.DisplayText;
    }
    get Offset() {
        return this.privSimpleSpeechPhrase.Offset;
    }
    get Duration() {
        return this.privSimpleSpeechPhrase.Duration;
    }
    get Language() {
        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;
    }
    get SpeakerId() {
        return this.privSimpleSpeechPhrase.SpeakerId;
    }
}

//# sourceMappingURL=SimpleSpeechPhrase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \********************************************************************************************************************************/
/*! exports provided: SpeechDetected */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechDetected", function() { return SpeechDetected; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechDetected {
    constructor(json) {
        this.privSpeechStartDetected = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SpeechDetected(json);
    }
    get Offset() {
        return this.privSpeechStartDetected.Offset;
    }
}

//# sourceMappingURL=SpeechDetected.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechHypothesis */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechHypothesis", function() { return SpeechHypothesis; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechHypothesis {
    constructor(json) {
        this.privSpeechHypothesis = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SpeechHypothesis(json);
    }
    get Text() {
        return this.privSpeechHypothesis.Text;
    }
    get Offset() {
        return this.privSpeechHypothesis.Offset;
    }
    get Duration() {
        return this.privSpeechHypothesis.Duration;
    }
    get Language() {
        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;
    }
    get SpeakerId() {
        return this.privSpeechHypothesis.SpeakerId;
    }
}

//# sourceMappingURL=SpeechHypothesis.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: SpeechKeyword */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechKeyword", function() { return SpeechKeyword; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechKeyword {
    constructor(json) {
        this.privSpeechKeyword = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SpeechKeyword(json);
    }
    get Status() {
        return this.privSpeechKeyword.Status;
    }
    get Text() {
        return this.privSpeechKeyword.Text;
    }
    get Offset() {
        return this.privSpeechKeyword.Offset;
    }
    get Duration() {
        return this.privSpeechKeyword.Duration;
    }
}

//# sourceMappingURL=SpeechKeyword.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \****************************************************************************************************************************************/
/*! exports provided: MetadataType, SynthesisAudioMetadata */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MetadataType", function() { return MetadataType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisAudioMetadata", function() { return SynthesisAudioMetadata; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var MetadataType;
(function (MetadataType) {
    MetadataType["WordBoundary"] = "WordBoundary";
    MetadataType["Bookmark"] = "Bookmark";
    MetadataType["Viseme"] = "Viseme";
})(MetadataType || (MetadataType = {}));
class SynthesisAudioMetadata {
    constructor(json) {
        this.privSynthesisAudioMetadata = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SynthesisAudioMetadata(json);
    }
    get Metadata() {
        return this.privSynthesisAudioMetadata.Metadata;
    }
}

//# sourceMappingURL=SynthesisAudioMetadata.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \***************************************************************************************************************************************/
/*! exports provided: TranslationHypothesis */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationHypothesis", function() { return TranslationHypothesis; });
/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationStatus */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class TranslationHypothesis {
    constructor(json) {
        this.privTranslationHypothesis = JSON.parse(json);
        this.privTranslationHypothesis.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__["TranslationStatus"][this.privTranslationHypothesis.Translation.TranslationStatus];
    }
    static fromJSON(json) {
        return new TranslationHypothesis(json);
    }
    get Duration() {
        return this.privTranslationHypothesis.Duration;
    }
    get Offset() {
        return this.privTranslationHypothesis.Offset;
    }
    get Text() {
        return this.privTranslationHypothesis.Text;
    }
    get Translation() {
        return this.privTranslationHypothesis.Translation;
    }
}

//# sourceMappingURL=TranslationHypothesis.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: TranslationPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationPhrase", function() { return TranslationPhrase; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../TranslationStatus */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class TranslationPhrase {
    constructor(json) {
        this.privTranslationPhrase = JSON.parse(json);
        this.privTranslationPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionStatus"][this.privTranslationPhrase.RecognitionStatus];
        if (this.privTranslationPhrase.Translation !== undefined) {
            this.privTranslationPhrase.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__["TranslationStatus"][this.privTranslationPhrase.Translation.TranslationStatus];
        }
    }
    static fromJSON(json) {
        return new TranslationPhrase(json);
    }
    get RecognitionStatus() {
        return this.privTranslationPhrase.RecognitionStatus;
    }
    get Offset() {
        return this.privTranslationPhrase.Offset;
    }
    get Duration() {
        return this.privTranslationPhrase.Duration;
    }
    get Text() {
        return this.privTranslationPhrase.Text;
    }
    get Translation() {
        return this.privTranslationPhrase.Translation;
    }
}

//# sourceMappingURL=TranslationPhrase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \*****************************************************************************************************************************************/
/*! exports provided: TranslationSynthesisEnd */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisEnd", function() { return TranslationSynthesisEnd; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class TranslationSynthesisEnd {
    constructor(json) {
        this.privSynthesisEnd = JSON.parse(json);
        this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesisStatus"][this.privSynthesisEnd.SynthesisStatus];
    }
    static fromJSON(json) {
        return new TranslationSynthesisEnd(json);
    }
    get SynthesisStatus() {
        return this.privSynthesisEnd.SynthesisStatus;
    }
    get FailureReason() {
        return this.privSynthesisEnd.FailureReason;
    }
}

//# sourceMappingURL=TranslationSynthesisEnd.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: TurnStatusResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TurnStatusResponsePayload", function() { return TurnStatusResponsePayload; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class TurnStatusResponsePayload {
    constructor(json) {
        this.privMessageStatusResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new TurnStatusResponsePayload(json);
    }
    get interactionId() {
        return this.privMessageStatusResponse.interactionId;
    }
    get conversationId() {
        return this.privMessageStatusResponse.conversationId;
    }
    get statusCode() {
        // Payloads may contain a limited set of textual representations or a numeric status
        // code. The textual values are here converted into numeric ones.
        switch (this.privMessageStatusResponse.statusCode) {
            case "Success":
                return 200;
            case "Failed":
                return 400;
            case "TimedOut":
                return 429;
            default:
                return this.privMessageStatusResponse.statusCode;
        }
    }
}

//# sourceMappingURL=TurnStatusPayload.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ServiceRecognizerBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServiceRecognizerBase", function() { return ServiceRecognizerBase; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};





class ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
        this.privSetTimeout = setTimeout;
        this.privIsLiveAudio = false;
        this.recognizeOverride = undefined;
        this.disconnectOverride = undefined;
        this.receiveMessageOverride = undefined;
        this.sendSpeechContext = (connection) => {
            const speechContextJson = this.speechContext.toJSON();
            if (speechContextJson) {
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text, "speech.context", this.privRequestSession.requestId, "application/json", speechContextJson));
            }
            return;
        };
        this.sendPrePayloadJSONOverride = undefined;
        this.postConnectImplOverride = undefined;
        this.configConnectionOverride = undefined;
        this.sendSpeechServiceConfig = (connection, requestSession, SpeechServiceConfigJson) => {
            // filter out anything that is not required for the service to work.
            if (ServiceRecognizerBase.telemetryDataEnabled !== true) {
                const withTelemetry = JSON.parse(SpeechServiceConfigJson);
                const replacement = {
                    context: {
                        system: withTelemetry.context.system,
                    },
                };
                SpeechServiceConfigJson = JSON.stringify(replacement);
            }
            if (this.privRecognizerConfig.parameters.getProperty("TranscriptionService_SingleChannel", "false").toLowerCase() === "true") {
                const json = JSON.parse(SpeechServiceConfigJson);
                json.context.DisableReferenceChannel = "True";
                json.context.MicSpec = "1_0_0";
                SpeechServiceConfigJson = JSON.stringify(json);
            }
            if (SpeechServiceConfigJson) {
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text, "speech.config", requestSession.requestId, "application/json", SpeechServiceConfigJson));
            }
            return;
        };
        if (!authentication) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("authentication");
        }
        if (!connectionFactory) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("connectionFactory");
        }
        if (!audioSource) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("audioSource");
        }
        if (!recognizerConfig) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("recognizerConfig");
        }
        this.privMustReportEndOfStream = false;
        this.privAuthentication = authentication;
        this.privConnectionFactory = connectionFactory;
        this.privAudioSource = audioSource;
        this.privRecognizerConfig = recognizerConfig;
        this.privIsDisposed = false;
        this.privRecognizer = recognizer;
        this.privRequestSession = new _Exports__WEBPACK_IMPORTED_MODULE_3__["RequestSession"](this.privAudioSource.id());
        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privDynamicGrammar = new _Exports__WEBPACK_IMPORTED_MODULE_3__["DynamicGrammarBuilder"]();
        this.privSpeechContext = new _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeechContext"](this.privDynamicGrammar);
        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_3__["AgentConfig"]();
        if (typeof (Blob) !== "undefined" && typeof (Worker) !== "undefined") {
            this.privSetTimeout = _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Timeout"].setTimeout;
        }
        this.connectionEvents.attach((connectionEvent) => __awaiter(this, void 0, void 0, function* () {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                const connectionClosedEvent = connectionEvent;
                if (connectionClosedEvent.statusCode === 1003 ||
                    connectionClosedEvent.statusCode === 1007 ||
                    connectionClosedEvent.statusCode === 1002 ||
                    connectionClosedEvent.statusCode === 4000 ||
                    this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {
                    yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].ConnectionFailure, connectionClosedEvent.reason + " websocket error code: " + connectionClosedEvent.statusCode);
                }
            }
        }));
    }
    get audioSource() {
        return this.privAudioSource;
    }
    get speechContext() {
        return this.privSpeechContext;
    }
    get dynamicGrammar() {
        return this.privDynamicGrammar;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
    set conversationTranslatorToken(token) {
        this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_Token, token);
    }
    set authentication(auth) {
        this.privAuthentication = this.authentication;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose(reason) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privIsDisposed = true;
            if (this.privConnectionConfigurationPromise) {
                try {
                    const connection = yield this.privConnectionConfigurationPromise;
                    yield connection.dispose(reason);
                }
                catch (error) {
                    // The connection is in a bad state. But we're trying to kill it, so...
                    return;
                }
            }
        });
    }
    get connectionEvents() {
        return this.privConnectionEvents;
    }
    get serviceEvents() {
        return this.privServiceEvents;
    }
    get recognitionMode() {
        return this.privRecognizerConfig.recognitionMode;
    }
    recognize(recoMode, successCallback, errorCallBack) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.recognizeOverride !== undefined) {
                return this.recognizeOverride(recoMode, successCallback, errorCallBack);
            }
            // Clear the existing configuration promise to force a re-transmission of config and context.
            this.privConnectionConfigurationPromise = null;
            this.privRecognizerConfig.recognitionMode = recoMode;
            this.privSuccessCallback = successCallback;
            this.privErrorCallback = errorCallBack;
            this.privRequestSession.startNewRecognition();
            this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);
            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
            const conPromise = this.connectImpl();
            let audioNode;
            try {
                const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);
                const format = yield this.audioSource.format;
                const deviceInfo = yield this.audioSource.deviceInfo;
                this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === _Exports__WEBPACK_IMPORTED_MODULE_3__["type"].Microphones;
                audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ReplayableAudioNode"](audioStreamNode, format.avgBytesPerSec);
                yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
                this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
            }
            catch (error) {
                yield this.privRequestSession.onStopRecognizing();
                throw error;
            }
            try {
                yield conPromise;
            }
            catch (error) {
                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].ConnectionFailure, error);
                return;
            }
            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SessionEventArgs"](this.privRequestSession.sessionId);
            if (!!this.privRecognizer.sessionStarted) {
                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
            }
            const messageRetrievalPromise = this.receiveMessage();
            const audioSendPromise = this.sendAudio(audioNode);
            audioSendPromise.catch((error) => __awaiter(this, void 0, void 0, function* () {
                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].RuntimeError, error);
            }));
            return;
        });
    }
    stopRecognizing() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privRequestSession.isRecognizing) {
                try {
                    yield this.audioSource.turnOff();
                    yield this.sendFinalAudio();
                    yield this.privRequestSession.onStopRecognizing();
                    yield this.privRequestSession.turnCompletionPromise;
                }
                finally {
                    yield this.privRequestSession.dispose();
                }
            }
            return;
        });
    }
    connect() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.connectImpl();
            return Promise.resolve();
        });
    }
    connectAsync(cb, err) {
        this.connectImpl().then((connection) => {
            try {
                if (!!cb) {
                    cb();
                }
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
        }, (reason) => {
            try {
                if (!!err) {
                    err(reason);
                }
                /* tslint:disable:no-empty */
            }
            catch (error) {
            }
        });
    }
    disconnect() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError, "Disconnecting");
            if (this.disconnectOverride !== undefined) {
                yield this.disconnectOverride();
            }
            try {
                yield (yield this.privConnectionPromise).dispose();
            }
            catch (error) {
            }
            this.privConnectionPromise = null;
        });
    }
    sendMessage(message) { }
    sendNetworkMessage(path, payload) {
        return __awaiter(this, void 0, void 0, function* () {
            const type = typeof payload === "string" ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text : _common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary;
            const contentType = typeof payload === "string" ? "application/json" : "";
            const connection = yield this.fetchConnection();
            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](type, path, this.privRequestSession.requestId, contentType, payload));
        });
    }
    set activityTemplate(messagePayload) { this.privActivityTemplate = messagePayload; }
    get activityTemplate() { return this.privActivityTemplate; }
    sendTelemetryData() {
        return __awaiter(this, void 0, void 0, function* () {
            const telemetryData = this.privRequestSession.getTelemetry();
            if (ServiceRecognizerBase.telemetryDataEnabled !== true ||
                this.privIsDisposed ||
                null === telemetryData) {
                return;
            }
            if (!!ServiceRecognizerBase.telemetryData) {
                try {
                    ServiceRecognizerBase.telemetryData(telemetryData);
                    /* tslint:disable:no-empty */
                }
                catch (_a) { }
            }
            const connection = yield this.fetchConnection();
            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text, "telemetry", this.privRequestSession.requestId, "application/json", telemetryData));
        });
    }
    // Cancels recognition.
    cancelRecognitionLocal(cancellationReason, errorCode, error) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privRequestSession.isRecognizing) {
                yield this.privRequestSession.onStopRecognizing();
                this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);
            }
        });
    }
    receiveMessage() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                if (this.privIsDisposed) {
                    // We're done.
                    return;
                }
                let connection = yield this.fetchConnection();
                const message = yield connection.read();
                if (this.receiveMessageOverride !== undefined) {
                    return this.receiveMessageOverride();
                }
                // indicates we are draining the queue and it came with no message;
                if (!message) {
                    if (!this.privRequestSession.isRecognizing) {
                        return;
                    }
                    else {
                        return this.receiveMessage();
                    }
                }
                this.privServiceHasSentMessage = true;
                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"].fromConnectionMessage(message);
                if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {
                    switch (connectionMessage.path.toLowerCase()) {
                        case "turn.start":
                            this.privMustReportEndOfStream = true;
                            this.privRequestSession.onServiceTurnStartResponse();
                            break;
                        case "speech.startdetected":
                            const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeechDetected"].fromJSON(connectionMessage.textBody);
                            const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionEventArgs"](speechStartDetected.Offset, this.privRequestSession.sessionId);
                            if (!!this.privRecognizer.speechStartDetected) {
                                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
                            }
                            break;
                        case "speech.enddetected":
                            let json;
                            if (connectionMessage.textBody.length > 0) {
                                json = connectionMessage.textBody;
                            }
                            else {
                                // If the request was empty, the JSON returned is empty.
                                json = "{ Offset: 0 }";
                            }
                            const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeechDetected"].fromJSON(json);
                            // Only shrink the buffers for continuous recognition.
                            // For single shot, the speech.phrase message will come after the speech.end and it should own buffer shrink.
                            if (this.privRecognizerConfig.isContinuousRecognition) {
                                this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);
                            }
                            const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionEventArgs"](speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
                            if (!!this.privRecognizer.speechEndDetected) {
                                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
                            }
                            break;
                        case "turn.end":
                            yield this.sendTelemetryData();
                            if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {
                                this.privMustReportEndOfStream = false;
                                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].EndOfStream, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError, undefined);
                            }
                            const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["SessionEventArgs"](this.privRequestSession.sessionId);
                            yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);
                            if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                                if (!!this.privRecognizer.sessionStopped) {
                                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                                }
                                return;
                            }
                            else {
                                connection = yield this.fetchConnection();
                                yield this.sendPrePayloadJSON(connection);
                            }
                            break;
                        default:
                            if (!(yield this.processTypeSpecificMessages(connectionMessage))) {
                                // here are some messages that the derived class has not processed, dispatch them to connect class
                                if (!!this.privServiceEvents) {
                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ServiceEvent"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                                }
                            }
                    }
                }
                return this.receiveMessage();
            }
            catch (error) {
                return null;
            }
        });
    }
    // Encapsulated for derived service recognizers that need to send additional JSON
    sendPrePayloadJSON(connection) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.sendPrePayloadJSONOverride !== undefined) {
                return this.sendPrePayloadJSONOverride(connection);
            }
            yield this.sendSpeechContext(connection);
            yield this.sendWaveHeader(connection);
            return;
        });
    }
    sendWaveHeader(connection) {
        return __awaiter(this, void 0, void 0, function* () {
            const format = yield this.audioSource.format;
            // this.writeBufferToConsole(format.header);
            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary, "audio", this.privRequestSession.requestId, "audio/x-wav", format.header));
        });
    }
    // Establishes a websocket connection to the end point.
    connectImpl() {
        if (this.privConnectionPromise) {
            return this.privConnectionPromise.then((connection) => {
                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionPromise = null;
                    this.privServiceHasSentMessage = false;
                    return this.connectImpl();
                }
                return this.privConnectionPromise;
            }, (error) => {
                this.privConnectionId = null;
                this.privConnectionPromise = null;
                this.privServiceHasSentMessage = false;
                return this.connectImpl();
            });
        }
        this.privConnectionPromise = this.retryableConnect();
        // Attach an empty handler to allow the promise to run in the background while
        // other startup events happen. It'll eventually be awaited on.
        this.privConnectionPromise.catch(() => { });
        if (this.postConnectImplOverride !== undefined) {
            return this.postConnectImplOverride(this.privConnectionPromise);
        }
        return this.privConnectionPromise;
    }
    fetchConnection() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privConnectionConfigurationPromise) {
                return this.privConnectionConfigurationPromise.then((connection) => {
                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ConnectionState"].Disconnected) {
                        this.privConnectionId = null;
                        this.privConnectionConfigurationPromise = null;
                        this.privServiceHasSentMessage = false;
                        return this.fetchConnection();
                    }
                    return this.privConnectionConfigurationPromise;
                }, (error) => {
                    this.privConnectionId = null;
                    this.privConnectionConfigurationPromise = null;
                    this.privServiceHasSentMessage = false;
                    return this.fetchConnection();
                });
            }
            this.privConnectionConfigurationPromise = this.configureConnection();
            return yield this.privConnectionConfigurationPromise;
        });
    }
    sendAudio(audioStreamNode) {
        return __awaiter(this, void 0, void 0, function* () {
            const audioFormat = yield this.audioSource.format;
            // The time we last sent data to the service.
            let nextSendTime = Date.now();
            // Max amount to send before we start to throttle
            const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty("SPEECH-TransmitLengthBeforThrottleMs", "5000");
            const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);
            const startRecogNumber = this.privRequestSession.recogNumber;
            const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {
                // If speech is done, stop sending audio.
                if (!this.privIsDisposed &&
                    !this.privRequestSession.isSpeechEnded &&
                    this.privRequestSession.isRecognizing &&
                    this.privRequestSession.recogNumber === startRecogNumber) {
                    const connection = yield this.fetchConnection();
                    const audioStreamChunk = yield audioStreamNode.read();
                    // we have a new audio chunk to upload.
                    if (this.privRequestSession.isSpeechEnded) {
                        // If service already recognized audio end then don't send any more audio
                        return;
                    }
                    let payload;
                    let sendDelay;
                    if (!audioStreamChunk || audioStreamChunk.isEnd) {
                        payload = null;
                        sendDelay = 0;
                    }
                    else {
                        payload = audioStreamChunk.buffer;
                        this.privRequestSession.onAudioSent(payload.byteLength);
                        if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {
                            sendDelay = 0;
                        }
                        else {
                            sendDelay = Math.max(0, nextSendTime - Date.now());
                        }
                    }
                    if (0 !== sendDelay) {
                        yield this.delay(sendDelay);
                    }
                    if (payload !== null) {
                        nextSendTime = Date.now() + (payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2));
                    }
                    // Are we still alive?
                    if (!this.privIsDisposed &&
                        !this.privRequestSession.isSpeechEnded &&
                        this.privRequestSession.isRecognizing &&
                        this.privRequestSession.recogNumber === startRecogNumber) {
                        connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary, "audio", this.privRequestSession.requestId, null, payload)).catch(() => {
                            this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => { });
                        });
                        if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {
                            // this.writeBufferToConsole(payload);
                            // Regardless of success or failure, schedule the next upload.
                            // If the underlying connection was broken, the next cycle will
                            // get a new connection and re-transmit missing audio automatically.
                            return readAndUploadCycle();
                        }
                        else {
                            // the audio stream has been closed, no need to schedule next
                            // read-upload cycle.
                            if (!this.privIsLiveAudio) {
                                this.privRequestSession.onSpeechEnded();
                            }
                        }
                    }
                }
            });
            return readAndUploadCycle();
        });
    }
    retryableConnect() {
        return __awaiter(this, void 0, void 0, function* () {
            let isUnAuthorized = false;
            this.privAuthFetchEventId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
            const sessionId = this.privRequestSession.sessionId;
            this.privConnectionId = (sessionId !== undefined) ? sessionId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
            this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);
            let lastStatusCode = 0;
            let lastReason = "";
            while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {
                // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer
                // facing event when a connection fails to let them try and provide new auth information.
                const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
                const auth = yield authPromise;
                yield this.privRequestSession.onAuthCompleted(false);
                // Create the connection
                const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);
                // Attach the telemetry handlers.
                this.privRequestSession.listenForServiceTelemetry(connection.events);
                // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
                // it'll stop sending events.
                connection.events.attach((event) => {
                    this.connectionEvents.onEvent(event);
                });
                const response = yield connection.open();
                // 200 == everything is fine.
                if (response.statusCode === 200) {
                    yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);
                    return Promise.resolve(connection);
                }
                else if (response.statusCode === 1006) {
                    isUnAuthorized = true;
                }
                lastStatusCode = response.statusCode;
                lastReason = response.reason;
                this.privRequestSession.onRetryConnection();
            }
            yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);
            return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);
        });
    }
    delay(delayMs) {
        return new Promise((resolve, reject) => {
            this.privSetTimeout(resolve, delayMs);
        });
    }
    writeBufferToConsole(buffer) {
        let out = "Buffer Size: ";
        if (null === buffer) {
            out += "null";
        }
        else {
            const readView = new Uint8Array(buffer);
            out += buffer.byteLength + "\r\n";
            for (let i = 0; i < buffer.byteLength; i++) {
                out += readView[i].toString(16).padStart(2, "0") + " ";
            }
        }
        // tslint:disable-next-line:no-console
        console.info(out);
    }
    sendFinalAudio() {
        return __awaiter(this, void 0, void 0, function* () {
            const connection = yield this.fetchConnection();
            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary, "audio", this.privRequestSession.requestId, null, null));
            return;
        });
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    configureConnection() {
        return __awaiter(this, void 0, void 0, function* () {
            const connection = yield this.connectImpl();
            if (this.configConnectionOverride !== undefined) {
                return this.configConnectionOverride(connection);
            }
            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
            yield this.sendPrePayloadJSON(connection);
            return connection;
        });
    }
}
ServiceRecognizerBase.telemetryDataEnabled = true;

//# sourceMappingURL=ServiceRecognizerBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ServiceTelemetryListener */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServiceTelemetryListener", function() { return ServiceTelemetryListener; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file


class ServiceTelemetryListener {
    constructor(requestId, audioSourceId, audioNodeId) {
        this.privIsDisposed = false;
        this.privListeningTriggerMetric = null;
        this.privMicMetric = null;
        this.privConnectionEstablishMetric = null;
        this.onEvent = (e) => {
            if (this.privIsDisposed) {
                return;
            }
            if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["RecognitionTriggeredEvent"] && e.requestId === this.privRequestId) {
                this.privListeningTriggerMetric = {
                    End: e.eventTime,
                    Name: "ListeningTrigger",
                    Start: e.eventTime,
                };
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeAttachingEvent"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
                this.privMicStartTime = e.eventTime;
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeAttachedEvent"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
                this.privMicStartTime = e.eventTime;
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["AudioSourceErrorEvent"] && e.audioSourceId === this.privAudioSourceId) {
                if (!this.privMicMetric) {
                    this.privMicMetric = {
                        End: e.eventTime,
                        Error: e.error,
                        Name: "Microphone",
                        Start: this.privMicStartTime,
                    };
                }
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeErrorEvent"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
                if (!this.privMicMetric) {
                    this.privMicMetric = {
                        End: e.eventTime,
                        Error: e.error,
                        Name: "Microphone",
                        Start: this.privMicStartTime,
                    };
                }
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeDetachedEvent"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
                if (!this.privMicMetric) {
                    this.privMicMetric = {
                        End: e.eventTime,
                        Name: "Microphone",
                        Start: this.privMicStartTime,
                    };
                }
            }
            if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectingToServiceEvent"] && e.requestId === this.privRequestId) {
                this.privConnectionId = e.sessionId;
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionStartEvent"] && e.connectionId === this.privConnectionId) {
                this.privConnectionStartTime = e.eventTime;
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionEstablishedEvent"] && e.connectionId === this.privConnectionId) {
                if (!this.privConnectionEstablishMetric) {
                    this.privConnectionEstablishMetric = {
                        End: e.eventTime,
                        Id: this.privConnectionId,
                        Name: "Connection",
                        Start: this.privConnectionStartTime,
                    };
                }
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionEstablishErrorEvent"] && e.connectionId === this.privConnectionId) {
                if (!this.privConnectionEstablishMetric) {
                    this.privConnectionEstablishMetric = {
                        End: e.eventTime,
                        Error: this.getConnectionError(e.statusCode),
                        Id: this.privConnectionId,
                        Name: "Connection",
                        Start: this.privConnectionStartTime,
                    };
                }
            }
            if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionMessageReceivedEvent"] && e.connectionId === this.privConnectionId) {
                if (e.message && e.message.headers && e.message.headers.path) {
                    if (!this.privReceivedMessages[e.message.headers.path]) {
                        this.privReceivedMessages[e.message.headers.path] = new Array();
                    }
                    const maxMessagesToSend = 50;
                    if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {
                        this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);
                    }
                }
            }
        };
        this.getTelemetry = () => {
            const metrics = new Array();
            if (this.privListeningTriggerMetric) {
                metrics.push(this.privListeningTriggerMetric);
            }
            if (this.privMicMetric) {
                metrics.push(this.privMicMetric);
            }
            if (this.privConnectionEstablishMetric) {
                metrics.push(this.privConnectionEstablishMetric);
            }
            if (this.privPhraseLatencies.length > 0) {
                metrics.push({
                    PhraseLatencyMs: this.privPhraseLatencies,
                });
            }
            if (this.privHypothesisLatencies.length > 0) {
                metrics.push({
                    FirstHypothesisLatencyMs: this.privHypothesisLatencies,
                });
            }
            const telemetry = {
                Metrics: metrics,
                ReceivedMessages: this.privReceivedMessages,
            };
            const json = JSON.stringify(telemetry);
            // We dont want to send the same telemetry again. So clean those out.
            this.privReceivedMessages = {};
            this.privListeningTriggerMetric = null;
            this.privMicMetric = null;
            this.privConnectionEstablishMetric = null;
            this.privPhraseLatencies = [];
            this.privHypothesisLatencies = [];
            return json;
        };
        this.dispose = () => {
            this.privIsDisposed = true;
        };
        this.getConnectionError = (statusCode) => {
            /*
            -- Websocket status codes --
            NormalClosure = 1000,
            EndpointUnavailable = 1001,
            ProtocolError = 1002,
            InvalidMessageType = 1003,
            Empty = 1005,
            InvalidPayloadData = 1007,
            PolicyViolation = 1008,
            MessageTooBig = 1009,
            MandatoryExtension = 1010,
            InternalServerError = 1011
            */
            switch (statusCode) {
                case 400:
                case 1002:
                case 1003:
                case 1005:
                case 1007:
                case 1008:
                case 1009: return "BadRequest";
                case 401: return "Unauthorized";
                case 403: return "Forbidden";
                case 503:
                case 1001: return "ServerUnavailable";
                case 500:
                case 1011: return "ServerError";
                case 408:
                case 504: return "Timeout";
                default: return "statuscode:" + statusCode.toString();
            }
        };
        this.privRequestId = requestId;
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privReceivedMessages = {};
        this.privPhraseLatencies = [];
        this.privHypothesisLatencies = [];
    }
    phraseReceived(audioReceivedTime) {
        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.
            this.privPhraseLatencies.push(Date.now() - audioReceivedTime);
        }
    }
    hypothesisReceived(audioReceivedTime) {
        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.
            this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);
        }
    }
    // Determines if there are any telemetry events to send to the service.
    get hasTelemetry() {
        return (Object.keys(this.privReceivedMessages).length !== 0 ||
            this.privListeningTriggerMetric !== null ||
            this.privMicMetric !== null ||
            this.privConnectionEstablishMetric !== null ||
            this.privPhraseLatencies.length !== 0 ||
            this.privHypothesisLatencies.length !== 0);
    }
}

//# sourceMappingURL=ServiceTelemetryListener.Internal.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeakerIdMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerIdMessageAdapter", function() { return SpeakerIdMessageAdapter; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};


/**
 * Implements methods for speaker recognition classes, sending requests to endpoint
 * and parsing response into expected format
 * @class SpeakerIdMessageAdapter
 */
class SpeakerIdMessageAdapter {
    constructor(config) {
        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint, undefined);
        if (!endpoint) {
            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Region, "westus");
            const version = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeakerRecognition_Api_Version, "2.0");
            const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Host, `https://${region}.api.cognitive${hostSuffix}/speaker/{mode}/v${version}/{dependency}`);
            endpoint = host + "/profiles";
        }
        this.privUri = endpoint;
        const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestConfigBase"].requestOptions;
        options.headers[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestConfigBase"].configParams.subscriptionKey] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Key, undefined);
        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestMessageAdapter"](options);
    }
    /**
     * Sends create profile request to endpoint.
     * @function
     * @param {VoiceProfileType} profileType - type of voice profile to create.
     * @param {string} lang - language/locale of voice profile
     * @public
     * @returns {Promise<IRestResponse>} promised rest response containing id of created profile.
     */
    createProfile(profileType, lang) {
        const uri = this.getOperationUri(profileType);
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Post, uri, {}, { locale: lang });
    }
    /**
     * Sends create enrollment request to endpoint.
     * @function
     * @param {VoiceProfile} profileType - voice profile for which to create new enrollment.
     * @param {IAudioSource} audioSource - audioSource from which to pull data to send
     * @public
     * @returns {Promise<IRestResponse>} rest response to enrollment request.
     */
    createEnrollment(profile, audioSource) {
        const uri = this.getOperationUri(profile.profileType) + "/" + profile.profileId + "/enrollments";
        return audioSource.blob.then((result) => {
            return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].File, uri, { ignoreMinLength: "true" }, null, result);
        });
    }
    /**
     * Sends verification request to endpoint.
     * @function
     * @param {SpeakerVerificationModel} model - voice model to verify against.
     * @param {IAudioSource} audioSource - audioSource from which to pull data to send
     * @public
     * @returns {Promise<IRestResponse>} rest response to enrollment request.
     */
    verifySpeaker(model, audioSource) {
        return __awaiter(this, void 0, void 0, function* () {
            const uri = this.getOperationUri(model.voiceProfile.profileType) + "/" + model.voiceProfile.profileId + "/verify";
            try {
                const result = yield audioSource.blob;
                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].File, uri, { ignoreMinLength: "true" }, null, result);
            }
            catch (e) {
                return Promise.resolve({ data: e });
            }
        });
    }
    /**
     * Sends identification request to endpoint.
     * @function
     * @param {SpeakerIdentificationModel} model - voice profiles against which to identify.
     * @param {IAudioSource} audioSource - audioSource from which to pull data to send
     * @public
     * @returns {Promise<IRestResponse>} rest response to enrollment request.
     */
    identifySpeaker(model, audioSource) {
        return __awaiter(this, void 0, void 0, function* () {
            const uri = this.getOperationUri(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileType"].TextIndependentIdentification) + "/identifySingleSpeaker";
            try {
                const result = yield audioSource.blob;
                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].File, uri, { profileIds: model.voiceProfileIds, ignoreMinLength: "true" }, null, result);
            }
            catch (e) {
                return Promise.resolve({ data: e });
            }
        });
    }
    /**
     * Sends profile status request to endpoint.
     * @function
     * @param {VoiceProfile} profile - voice profile to check.
     * @public
     * @returns {Promise<IRestResponse>} rest response to status request
     */
    getProfileStatus(profile) {
        const uri = `${this.getOperationUri(profile.profileType)}/${profile.profileId}`;
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Get, uri, {});
    }
    /**
     * Sends get all profiles request to endpoint.
     * @function
     * @param {VoiceProfileType} profileType - type of profiles to return list of
     * @public
     * @returns {Promise<IRestResponse>} promised rest response containing all profiles
     */
    getProfiles(profileType) {
        const uri = this.getOperationUri(profileType);
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Get, uri, {});
    }
    /**
     * Sends get activation/auth phrases request to endpoint.
     * @function
     * @param {VoiceProfileType} profileType - type of profiles to return phrases for
     * @param {string} lang - language/locale of voice profile
     * @public
     * @returns {Promise<IRestResponse>} promised rest response containing list of valid phrases
     */
    getPhrases(profileType, lang) {
        const uri = `${this.getOperationUri(profileType)}`.replace(`profiles`, `phrases`) + "/" + lang;
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Get, uri, {});
    }
    /**
     * Sends delete profile request to endpoint.
     * @function
     * @param {VoiceProfile} profile - voice profile to delete.
     * @public
     * @returns {Promise<IRestResponse>} rest response to deletion request
     */
    deleteProfile(profile) {
        const uri = this.getOperationUri(profile.profileType) + "/" + profile.profileId;
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Delete, uri, {});
    }
    /**
     * Sends reset profile request to endpoint.
     * @function
     * @param {VoiceProfile} profile - voice profile to reset enrollments for.
     * @public
     * @returns {Promise<IRestResponse>} rest response to reset request
     */
    resetProfile(profile) {
        const uri = this.getOperationUri(profile.profileType) + "/" + profile.profileId + "/reset";
        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Post, uri, {});
    }
    getOperationUri(profileType) {
        const mode = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileType"].TextIndependentIdentification ? "identification" : "verification";
        const dependency = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileType"].TextDependentVerification ? "text-dependent" : "text-independent";
        return this.privUri.replace("{mode}", mode).replace("{dependency}", dependency);
    }
}

//# sourceMappingURL=SpeakerIdMessageAdapter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js ***!
  \**************************************************************************************************************************/
/*! exports provided: SpeakerRecognitionConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionConfig", function() { return SpeakerRecognitionConfig; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SpeakerRecognitionConfig {
    constructor(context, parameters) {
        this.privContext = context ? context : new _Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](null);
        this.privParameters = parameters;
    }
    get parameters() {
        return this.privParameters;
    }
    get Context() {
        return this.privContext;
    }
}

//# sourceMappingURL=SpeakerRecognitionConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeechConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechConnectionFactory", function() { return SpeechConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







class SpeechConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__["ConnectionFactoryBase"] {
    constructor() {
        super(...arguments);
        this.interactiveRelativeUri = "/speech/recognition/interactive/cognitiveservices/v1";
        this.conversationRelativeUri = "/speech/recognition/conversation/cognitiveservices/v1";
        this.dictationRelativeUri = "/speech/recognition/dictation/cognitiveservices/v1";
        this.create = (config, authInfo, connectionId) => {
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint, undefined);
            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, undefined);
            const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Host, "wss://" + region + ".stt.speech" + hostSuffix);
            const queryParams = {};
            const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId, undefined);
            const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage, undefined);
            if (endpointId) {
                if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].CustomSpeechDeploymentId) === -1) {
                    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].CustomSpeechDeploymentId] = endpointId;
                }
            }
            else if (language) {
                if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Language) === -1) {
                    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Language] = language;
                }
            }
            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Format) === -1) {
                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["OutputFormatPropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"].Simple]).toLowerCase();
            }
            if (config.autoDetectSourceLanguages !== undefined) {
                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].EnableLanguageId] = "true";
            }
            this.setCommonUrlParams(config, queryParams, endpoint);
            if (!endpoint) {
                switch (config.recognitionMode) {
                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionMode"].Conversation:
                        if (config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["ForceDictationPropertyName"], "false") === "true") {
                            endpoint = host + this.dictationRelativeUri;
                        }
                        else {
                            endpoint = host + this.conversationRelativeUri;
                        }
                        break;
                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionMode"].Dictation:
                        endpoint = host + this.dictationRelativeUri;
                        break;
                    default:
                        endpoint = host + this.interactiveRelativeUri; // default is interactive
                        break;
                }
            }
            const headers = {};
            if (authInfo.token !== undefined && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].ConnectionId] = connectionId;
            config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Url, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
        };
    }
}

//# sourceMappingURL=SpeechConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechConnectionMessage", function() { return SpeechConnectionMessage; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class SpeechConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionMessage"] {
    constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {
        if (!path) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("path");
        }
        if (!requestId) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("requestId");
        }
        const headers = {};
        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].Path] = path;
        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestId] = requestId;
        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestTimestamp] = new Date().toISOString();
        if (contentType) {
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].ContentType] = contentType;
        }
        if (streamId) {
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestStreamId] = streamId;
        }
        if (additionalHeaders) {
            for (const headerName in additionalHeaders) {
                if (headerName) {
                    headers[headerName] = additionalHeaders[headerName];
                }
            }
        }
        if (id) {
            super(messageType, body, headers, id);
        }
        else {
            super(messageType, body, headers);
        }
        this.privPath = path;
        this.privRequestId = requestId;
        this.privContentType = contentType;
        this.privStreamId = streamId;
        this.privAdditionalHeaders = additionalHeaders;
    }
    get path() {
        return this.privPath;
    }
    get requestId() {
        return this.privRequestId;
    }
    get contentType() {
        return this.privContentType;
    }
    get streamId() {
        return this.privStreamId;
    }
    get additionalHeaders() {
        return this.privAdditionalHeaders;
    }
}
SpeechConnectionMessage.fromConnectionMessage = (message) => {
    let path = null;
    let requestId = null;
    let contentType = null;
    let requestTimestamp = null;
    let streamId = null;
    const additionalHeaders = {};
    if (message.headers) {
        for (const headerName in message.headers) {
            if (headerName) {
                if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].Path.toLowerCase()) {
                    path = message.headers[headerName];
                }
                else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestId.toLowerCase()) {
                    requestId = message.headers[headerName];
                }
                else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestTimestamp.toLowerCase()) {
                    requestTimestamp = message.headers[headerName];
                }
                else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].ContentType.toLowerCase()) {
                    contentType = message.headers[headerName];
                }
                else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__["HeaderNames"].RequestStreamId.toLowerCase()) {
                    streamId = message.headers[headerName];
                }
                else {
                    additionalHeaders[headerName] = message.headers[headerName];
                }
            }
        }
    }
    return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);
};

//# sourceMappingURL=SpeechConnectionMessage.Internal.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechContext */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechContext", function() { return SpeechContext; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Represents the JSON used in the speech.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SpeechContext {
    constructor(dynamicGrammar) {
        this.privContext = {};
        this.privDynamicGrammar = dynamicGrammar;
    }
    /**
     * Adds a section to the speech.context object.
     * @param sectionName Name of the section to add.
     * @param value JSON serializable object that represents the value.
     */
    setSection(sectionName, value) {
        this.privContext[sectionName] = value;
    }
    /**
     * @Internal
     * This is only used by pronunciation assessment config.
     * Do not use externally, object returned will change without warning or notice.
     */
    setPronunciationAssessmentParams(params) {
        if (this.privContext.phraseDetection === undefined) {
            this.privContext.phraseDetection = {
                enrichment: {
                    pronunciationAssessment: {}
                }
            };
        }
        this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);
        if (this.privContext.phraseOutput === undefined) {
            this.privContext.phraseOutput = {
                detailed: {
                    options: []
                },
                format: {}
            };
        }
        this.privContext.phraseOutput.format = "Detailed";
        this.privContext.phraseOutput.detailed.options.push("PronunciationAssessment");
        if (this.privContext.phraseOutput.detailed.options.indexOf("WordTimings") === -1) {
            this.privContext.phraseOutput.detailed.options.push("WordTimings");
        }
        if (this.privContext.phraseOutput.detailed.options.indexOf("SNR") === -1) {
            this.privContext.phraseOutput.detailed.options.push("SNR");
        }
    }
    toJSON() {
        const dgi = this.privDynamicGrammar.generateGrammarObject();
        this.setSection("dgi", dgi);
        const ret = JSON.stringify(this.privContext);
        return ret;
    }
}

//# sourceMappingURL=SpeechContext.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js ***!
  \*************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=SpeechServiceInterfaces.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeechServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechServiceRecognizer", function() { return SpeechServiceRecognizer; });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};


// tslint:disable-next-line:max-classes-per-file
class SpeechServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_1__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);
        this.privSpeechRecognizer = speechRecognizer;
        if (recognizerConfig.autoDetectSourceLanguages !== undefined) {
            const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(",");
            this.privSpeechContext.setSection("languageId", {
                languages: sourceLanguages,
                onSuccess: { action: "Recognize" },
                onUnknown: { action: "None" }
            });
            this.privSpeechContext.setSection("phraseOutput", {
                interimResults: {
                    resultType: "Auto"
                },
                phraseResults: {
                    resultType: "Always"
                }
            });
        }
    }
    processTypeSpecificMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            let result;
            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyCollection"]();
            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);
            let processed = false;
            switch (connectionMessage.path.toLowerCase()) {
                case "speech.hypothesis":
                case "speech.fragment":
                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechHypothesis"].fromJSON(connectionMessage.textBody);
                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, // Speaker Id
                    undefined, connectionMessage.textBody, resultProps);
                    this.privRequestSession.onHypothesis(offset);
                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionEventArgs"](result, hypothesis.Duration, this.privRequestSession.sessionId);
                    if (!!this.privSpeechRecognizer.recognizing) {
                        try {
                            this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "speech.phrase":
                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_1__["SimpleSpeechPhrase"].fromJSON(connectionMessage.textBody);
                    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_1__["EnumTranslation"].implTranslateRecognitionResult(simple.RecognitionStatus);
                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
                    if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].Canceled === resultReason) {
                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_1__["EnumTranslation"].implTranslateCancelResult(simple.RecognitionStatus);
                        yield this.cancelRecognitionLocal(cancelReason, _Exports__WEBPACK_IMPORTED_MODULE_1__["EnumTranslation"].implTranslateCancelErrorCode(simple.RecognitionStatus), undefined);
                    }
                    else {
                        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].InitialSilenceTimeout)) {
                            if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["OutputFormatPropertyName"]) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormat"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormat"].Simple]) {
                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"](this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, // Speaker Id
                                undefined, connectionMessage.textBody, resultProps);
                            }
                            else {
                                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_1__["DetailedSpeechPhrase"].fromJSON(connectionMessage.textBody);
                                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
                                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"](this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionStatus"].Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, // Speaker Id
                                undefined, offsetCorrectedJson, resultProps);
                            }
                            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionEventArgs"](result, result.offset, this.privRequestSession.sessionId);
                            if (!!this.privSpeechRecognizer.recognized) {
                                try {
                                    this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);
                                    /* tslint:disable:no-empty */
                                }
                                catch (error) {
                                    // Not going to let errors in the event handler
                                    // trip things up.
                                }
                            }
                        }
                        if (!!this.privSuccessCallback) {
                            try {
                                this.privSuccessCallback(result);
                            }
                            catch (e) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(e);
                                }
                            }
                            // Only invoke the call back once.
                            // and if it's successful don't invoke the
                            // error after that.
                            this.privSuccessCallback = undefined;
                            this.privErrorCallback = undefined;
                        }
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyCollection"]();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCode"][errorCode]);
        if (!!this.privSpeechRecognizer.canceled) {
            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionCanceledEventArgs"](cancellationReason, error, errorCode, undefined, sessionId);
            try {
                this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);
                /* tslint:disable:no-empty */
            }
            catch (_a) { }
        }
        if (!!this.privSuccessCallback) {
            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["ResultReason"].Canceled, undefined, // Text
            undefined, // Duration
            undefined, // Offset
            undefined, // Language
            undefined, // Language Detection Confidence
            undefined, // Speaker Id
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                this.privSuccessCallback = undefined;
                /* tslint:disable:no-empty */
            }
            catch (_b) { }
        }
    }
}

//# sourceMappingURL=SpeechServiceRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechSynthesisConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisConnectionFactory", function() { return SpeechSynthesisConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.





class SpeechSynthesisConnectionFactory {
    constructor() {
        this.synthesisUri = "/cognitiveservices/websocket/v1";
        this.create = (config, authInfo, connectionId) => {
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint, undefined);
            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Region, undefined);
            const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
            const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_EndpointId, undefined);
            const hostPrefix = (endpointId === undefined) ? "tts" : "voice";
            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Host, "wss://" + region + "." + hostPrefix + ".speech" + hostSuffix);
            const queryParams = {};
            if (!endpoint) {
                endpoint = host + this.synthesisUri;
            }
            const headers = {};
            if (authInfo.token !== undefined && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_3__["HeaderNames"].ConnectionId] = connectionId;
            if (endpointId !== undefined) {
                headers[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_4__["QueryParameterNames"].CustomVoiceDeploymentId] = endpointId;
            }
            config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Url, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_2__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromParameters(config.parameters), enableCompression, connectionId);
        };
    }
}

//# sourceMappingURL=SpeechSynthesisConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js ***!
  \**********************************************************************************************************************/
/*! exports provided: SynthesisAdapterBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisAdapterBase", function() { return SynthesisAdapterBase; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




class SynthesisAdapterBase {
    constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {
        this.speakOverride = undefined;
        this.receiveMessageOverride = undefined;
        this.connectImplOverride = undefined;
        this.configConnectionOverride = undefined;
        this.sendSynthesisContext = (connection) => {
            const synthesisContextJson = this.synthesisContext.toJSON();
            if (synthesisContextJson) {
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, "synthesis.context", this.privSynthesisTurn.requestId, "application/json", synthesisContextJson));
            }
            return;
        };
        this.sendSpeechServiceConfig = (connection, SpeechServiceConfigJson) => {
            if (SpeechServiceConfigJson) {
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, "speech.config", this.privSynthesisTurn.requestId, "application/json", SpeechServiceConfigJson));
            }
        };
        this.sendSsmlMessage = (connection, ssml, requestId) => {
            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, "ssml", requestId, "application/ssml+xml", ssml));
        };
        if (!authentication) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("authentication");
        }
        if (!connectionFactory) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("connectionFactory");
        }
        if (!synthesizerConfig) {
            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("synthesizerConfig");
        }
        this.privAuthentication = authentication;
        this.privConnectionFactory = connectionFactory;
        this.privSynthesizerConfig = synthesizerConfig;
        this.privIsDisposed = false;
        this.privSpeechSynthesizer = speechSynthesizer;
        this.privSessionAudioDestination = audioDestination;
        this.privSynthesisTurn = new _Exports__WEBPACK_IMPORTED_MODULE_2__["SynthesisTurn"]();
        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventSource"]();
        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventSource"]();
        this.privSynthesisContext = new _Exports__WEBPACK_IMPORTED_MODULE_2__["SynthesisContext"](this.privSpeechSynthesizer);
        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_2__["AgentConfig"]();
        this.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                const connectionClosedEvent = connectionEvent;
                if (connectionClosedEvent.statusCode !== 1000) {
                    this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].ConnectionFailure, connectionClosedEvent.reason + " websocket error code: " + connectionClosedEvent.statusCode);
                }
            }
        });
    }
    get synthesisContext() {
        return this.privSynthesisContext;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
    get connectionEvents() {
        return this.privConnectionEvents;
    }
    get serviceEvents() {
        return this.privServiceEvents;
    }
    set activityTemplate(messagePayload) { this.privActivityTemplate = messagePayload; }
    get activityTemplate() { return this.privActivityTemplate; }
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
        this.privSynthesisTurn.audioOutputFormat = format;
        if (this.privSessionAudioDestination !== undefined) {
            this.privSessionAudioDestination.format = format;
        }
        if (this.synthesisContext !== undefined) {
            this.synthesisContext.audioOutputFormat = format;
        }
    }
    static addHeader(audio, format) {
        if (!format.hasHeader) {
            return audio;
        }
        format.updateHeader(audio.byteLength);
        const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);
        tmp.set(new Uint8Array(format.header), 0);
        tmp.set(new Uint8Array(audio), format.header.byteLength);
        return tmp.buffer;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose(reason) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privIsDisposed = true;
            if (this.privSessionAudioDestination !== undefined) {
                this.privSessionAudioDestination.close();
            }
            if (this.privConnectionConfigurationPromise) {
                const connection = yield this.privConnectionConfigurationPromise;
                yield connection.dispose(reason);
            }
        });
    }
    connect() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.connectImpl();
        });
    }
    sendNetworkMessage(path, payload) {
        return __awaiter(this, void 0, void 0, function* () {
            const type = typeof payload === "string" ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text : _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary;
            const contentType = typeof payload === "string" ? "application/json" : "";
            const connection = yield this.fetchConnection();
            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"](type, path, this.privSynthesisTurn.requestId, contentType, payload));
        });
    }
    Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {
        return __awaiter(this, void 0, void 0, function* () {
            let ssml;
            if (isSSML) {
                ssml = text;
            }
            else {
                ssml = this.privSpeechSynthesizer.buildSsml(text);
            }
            if (this.speakOverride !== undefined) {
                return this.speakOverride(ssml, requestId, successCallback, errorCallBack);
            }
            this.privSuccessCallback = successCallback;
            this.privErrorCallback = errorCallBack;
            this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);
            try {
                yield this.connectImpl();
                const connection = yield this.fetchConnection();
                yield this.sendSynthesisContext(connection);
                yield this.sendSsmlMessage(connection, ssml, requestId);
                const synthesisStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisEventArgs"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisResult"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].SynthesizingAudioStarted));
                if (!!this.privSpeechSynthesizer.synthesisStarted) {
                    this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);
                }
                const messageRetrievalPromise = this.receiveMessage();
            }
            catch (e) {
                this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].ConnectionFailure, e);
                return Promise.reject(e);
            }
        });
    }
    // Cancels synthesis.
    cancelSynthesis(requestId, cancellationReason, errorCode, error) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][errorCode]);
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisResult"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled, undefined, error, properties);
        if (!!this.privSpeechSynthesizer.SynthesisCanceled) {
            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisEventArgs"](result);
            try {
                this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);
                /* tslint:disable:no-empty */
            }
            catch (_a) { }
        }
        if (!!this.privSuccessCallback) {
            try {
                this.privSuccessCallback(result);
                /* tslint:disable:no-empty */
            }
            catch (_b) { }
        }
    }
    // Cancels synthesis.
    cancelSynthesisLocal(cancellationReason, errorCode, error) {
        if (!!this.privSynthesisTurn.isSynthesizing) {
            this.privSynthesisTurn.onStopSynthesizing();
            this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);
        }
    }
    processTypeSpecificMessages(connectionMessage, successCallback, errorCallBack) {
        return true;
    }
    receiveMessage() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const connection = yield this.fetchConnection();
                const message = yield connection.read();
                if (this.receiveMessageOverride !== undefined) {
                    return this.receiveMessageOverride();
                }
                if (this.privIsDisposed) {
                    // We're done.
                    return;
                }
                // indicates we are draining the queue and it came with no message;
                if (!message) {
                    if (!this.privSynthesisTurn.isSynthesizing) {
                        return;
                    }
                    else {
                        return this.receiveMessage();
                    }
                }
                this.privServiceHasSentMessage = true;
                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"].fromConnectionMessage(message);
                if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {
                    switch (connectionMessage.path.toLowerCase()) {
                        case "turn.start":
                            this.privSynthesisTurn.onServiceTurnStartResponse();
                            break;
                        case "response":
                            this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);
                            break;
                        case "audio":
                            if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase()
                                && !!connectionMessage.binaryBody) {
                                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);
                                if (!!this.privSpeechSynthesizer.synthesizing) {
                                    try {
                                        const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);
                                        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisEventArgs"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisResult"](this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].SynthesizingAudio, audioWithHeader));
                                        this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);
                                    }
                                    catch (error) {
                                        // Not going to let errors in the event handler
                                        // trip things up.
                                    }
                                }
                                if (this.privSessionAudioDestination !== undefined) {
                                    this.privSessionAudioDestination.write(connectionMessage.binaryBody);
                                }
                            }
                            break;
                        case "audio.metadata":
                            const metadataList = _Exports__WEBPACK_IMPORTED_MODULE_2__["SynthesisAudioMetadata"].fromJSON(connectionMessage.textBody).Metadata;
                            for (const metadata of metadataList) {
                                switch (metadata.Type) {
                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__["MetadataType"].WordBoundary:
                                        this.privSynthesisTurn.onWordBoundaryEvent(metadata.Data.text.Text);
                                        const wordBoundaryEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisWordBoundaryEventArgs"](metadata.Data.Offset, metadata.Data.text.Text, metadata.Data.text.Length, this.privSynthesisTurn.currentTextOffset);
                                        if (!!this.privSpeechSynthesizer.wordBoundary) {
                                            try {
                                                this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);
                                            }
                                            catch (error) {
                                                // Not going to let errors in the event handler
                                                // trip things up.
                                            }
                                        }
                                        break;
                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__["MetadataType"].Bookmark:
                                        const bookmarkEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisBookmarkEventArgs"](metadata.Data.Offset, metadata.Data.Bookmark);
                                        if (!!this.privSpeechSynthesizer.bookmarkReached) {
                                            try {
                                                this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);
                                            }
                                            catch (error) {
                                                // Not going to let errors in the event handler
                                                // trip things up.
                                            }
                                        }
                                        break;
                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__["MetadataType"].Viseme:
                                        this.privSynthesisTurn.onVisemeMetadataReceived(metadata);
                                        if (metadata.Data.IsLastAnimation) {
                                            const visemeEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisVisemeEventArgs"](metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());
                                            if (!!this.privSpeechSynthesizer.visemeReceived) {
                                                try {
                                                    this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);
                                                }
                                                catch (error) {
                                                    // Not going to let errors in the event handler
                                                    // trip things up.
                                                }
                                            }
                                        }
                                        break;
                                }
                            }
                            break;
                        case "turn.end":
                            this.privSynthesisTurn.onServiceTurnEndResponse();
                            let result;
                            try {
                                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();
                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisResult"](this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].SynthesizingAudioCompleted, audioBuffer);
                                if (!!this.privSuccessCallback) {
                                    this.privSuccessCallback(result);
                                }
                            }
                            catch (error) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(error);
                                }
                            }
                            if (this.privSpeechSynthesizer.synthesisCompleted) {
                                try {
                                    this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechSynthesisEventArgs"](result));
                                }
                                catch (e) {
                                    // Not going to let errors in the event handler
                                    // trip things up.
                                }
                            }
                            break;
                        default:
                            if (!this.processTypeSpecificMessages(connectionMessage)) {
                                // here are some messages that the derived class has not processed, dispatch them to connect class
                                if (!!this.privServiceEvents) {
                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ServiceEvent"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                                }
                            }
                    }
                }
                return this.receiveMessage();
            }
            catch (e) {
                // TODO: What goes here?
            }
        });
    }
    connectImpl(isUnAuthorized = false) {
        if (this.privConnectionPromise) {
            return this.privConnectionPromise.then((connection) => {
                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionState"].Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionPromise = null;
                    this.privServiceHasSentMessage = false;
                    return this.connectImpl();
                }
                return this.privConnectionPromise;
            }, (error) => {
                this.privConnectionId = null;
                this.privConnectionPromise = null;
                this.privServiceHasSentMessage = false;
                return this.connectImpl();
            });
        }
        this.privAuthFetchEventId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privConnectionId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);
        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
        this.privConnectionPromise = authPromise.then((result) => __awaiter(this, void 0, void 0, function* () {
            yield this.privSynthesisTurn.onAuthCompleted(false);
            const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);
            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
            // it'll stop sending events.
            connection.events.attach((event) => {
                this.connectionEvents.onEvent(event);
            });
            const response = yield connection.open();
            if (response.statusCode === 200) {
                yield this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
                return Promise.resolve(connection);
            }
            else if (response.statusCode === 403 && !isUnAuthorized) {
                return this.connectImpl(true);
            }
            else {
                yield this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode, response.reason);
                return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);
            }
        }), (error) => __awaiter(this, void 0, void 0, function* () {
            yield this.privSynthesisTurn.onAuthCompleted(true, error);
            throw new Error(error);
        }));
        // Attach an empty handler to allow the promise to run in the background while
        // other startup events happen. It'll eventually be awaited on.
        this.privConnectionPromise.catch(() => { });
        return this.privConnectionPromise;
    }
    fetchConnection() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privConnectionConfigurationPromise) {
                return this.privConnectionConfigurationPromise.then((connection) => {
                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionState"].Disconnected) {
                        this.privConnectionId = null;
                        this.privConnectionConfigurationPromise = null;
                        this.privServiceHasSentMessage = false;
                        return this.fetchConnection();
                    }
                    return this.privConnectionConfigurationPromise;
                }, (error) => {
                    this.privConnectionId = null;
                    this.privConnectionConfigurationPromise = null;
                    this.privServiceHasSentMessage = false;
                    return this.fetchConnection();
                });
            }
            this.privConnectionConfigurationPromise = this.configureConnection();
            return yield this.privConnectionConfigurationPromise;
        });
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    configureConnection() {
        return __awaiter(this, void 0, void 0, function* () {
            const connection = yield this.connectImpl();
            if (this.configConnectionOverride !== undefined) {
                return this.configConnectionOverride(connection);
            }
            yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());
            return connection;
        });
    }
}
SynthesisAdapterBase.telemetryDataEnabled = true;

//# sourceMappingURL=SynthesisAdapterBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js ***!
  \******************************************************************************************************************/
/*! exports provided: SynthesisContext */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisContext", function() { return SynthesisContext; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Represents the JSON used in the synthesis.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SynthesisContext {
    constructor(speechSynthesizer) {
        this.privContext = {};
        this.privSpeechSynthesizer = speechSynthesizer;
    }
    /**
     * Adds a section to the synthesis.context object.
     * @param sectionName Name of the section to add.
     * @param value JSON serializable object that represents the value.
     */
    setSection(sectionName, value) {
        this.privContext[sectionName] = value;
    }
    /**
     * Sets the audio output format for synthesis context generation.
     * @param format {AudioOutputFormatImpl} the output format
     */
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
    }
    toJSON() {
        const synthesisSection = this.buildSynthesisContext();
        this.setSection("synthesis", synthesisSection);
        return JSON.stringify(this.privContext);
    }
    buildSynthesisContext() {
        return {
            audio: {
                metadataOptions: {
                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),
                    sentenceBoundaryEnabled: false,
                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),
                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),
                },
                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,
            },
            language: {
                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage
            }
        };
    }
}

//# sourceMappingURL=SynthesisContext.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js ***!
  \*****************************************************************************************************************/
/*! exports provided: SpeechSynthesisEvent, SynthesisTriggeredEvent, ConnectingToSynthesisServiceEvent, SynthesisStartedEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisEvent", function() { return SpeechSynthesisEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisTriggeredEvent", function() { return SynthesisTriggeredEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectingToSynthesisServiceEvent", function() { return ConnectingToSynthesisServiceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisStartedEvent", function() { return SynthesisStartedEvent; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file

class SpeechSynthesisEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, requestId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
        this.privRequestId = requestId;
    }
    get requestId() {
        return this.privRequestId;
    }
}
class SynthesisTriggeredEvent extends SpeechSynthesisEvent {
    constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {
        super("SynthesisTriggeredEvent", requestId);
        this.privSessionAudioDestinationId = sessionAudioDestinationId;
        this.privTurnAudioDestinationId = turnAudioDestinationId;
    }
    get audioSessionDestinationId() {
        return this.privSessionAudioDestinationId;
    }
    get audioTurnDestinationId() {
        return this.privTurnAudioDestinationId;
    }
}
class ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {
    constructor(requestId, authFetchEventId) {
        super("ConnectingToSynthesisServiceEvent", requestId);
        this.privAuthFetchEventId = authFetchEventId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}
class SynthesisStartedEvent extends SpeechSynthesisEvent {
    constructor(requestId, authFetchEventId) {
        super("SynthesisStartedEvent", requestId);
        this.privAuthFetchEventId = authFetchEventId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}

//# sourceMappingURL=SynthesisEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js ***!
  \***************************************************************************************************************/
/*! exports provided: SynthesisTurn */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisTurn", function() { return SynthesisTurn; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SynthesisAdapterBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _SynthesisEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SynthesisEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




class SynthesisTurn {
    constructor() {
        this.privIsDisposed = false;
        this.privIsSynthesizing = false;
        this.privIsSynthesisEnded = false;
        this.privBytesReceived = 0;
        this.privInTurn = false;
        this.privTextOffset = 0;
        this.privNextSearchTextIndex = 0;
        this.onPreConnectionStart = (authFetchEventId, connectionId) => {
            this.privAuthFetchEventId = authFetchEventId;
            this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_3__["ConnectingToSynthesisServiceEvent"](this.privRequestId, this.privAuthFetchEventId));
        };
        this.onAuthCompleted = (isError, error) => {
            if (isError) {
                this.onComplete();
            }
        };
        this.onConnectionEstablishCompleted = (statusCode, reason) => {
            if (statusCode === 200) {
                this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_3__["SynthesisStartedEvent"](this.requestId, this.privAuthFetchEventId));
                this.privBytesReceived = 0;
                return;
            }
            else if (statusCode === 403) {
                this.onComplete();
            }
        };
        this.onServiceResponseMessage = (responseJson) => {
            const response = JSON.parse(responseJson);
            this.streamId = response.audio.streamId;
        };
        this.onServiceTurnEndResponse = () => {
            this.privInTurn = false;
            this.privTurnDeferral.resolve();
            this.onComplete();
        };
        this.onServiceTurnStartResponse = () => {
            if (!!this.privTurnDeferral && !!this.privInTurn) {
                // What? How are we starting a turn with another not done?
                this.privTurnDeferral.reject("Another turn started before current completed.");
                // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
                /* tslint:disable:no-empty */
                this.privTurnDeferral.promise.then().catch(() => { });
            }
            this.privInTurn = true;
            this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
        };
        this.dispose = (error) => {
            if (!this.privIsDisposed) {
                // we should have completed by now. If we did not its an unknown error.
                this.privIsDisposed = true;
            }
        };
        this.onEvent = (event) => {
            _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Events"].instance.onEvent(event);
        };
        this.onComplete = () => {
            if (this.privIsSynthesizing) {
                this.privIsSynthesizing = false;
                this.privIsSynthesisEnded = true;
                this.privAudioOutputStream.close();
                this.privInTurn = false;
                if (this.privTurnAudioDestination !== undefined) {
                    this.privTurnAudioDestination.close();
                    this.privTurnAudioDestination = undefined;
                }
            }
        };
        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
        // We're not in a turn, so resolve.
        this.privTurnDeferral.resolve();
    }
    get requestId() {
        return this.privRequestId;
    }
    get streamId() {
        return this.privStreamId;
    }
    set streamId(value) {
        this.privStreamId = value;
    }
    get audioOutputFormat() {
        return this.privAudioOutputFormat;
    }
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
    }
    get turnCompletionPromise() {
        return this.privTurnDeferral.promise;
    }
    get isSynthesisEnded() {
        return this.privIsSynthesisEnded;
    }
    get isSynthesizing() {
        return this.privIsSynthesizing;
    }
    get currentTextOffset() {
        return this.privTextOffset;
    }
    // The number of bytes received for current turn
    get bytesReceived() {
        return this.privBytesReceived;
    }
    getAllReceivedAudio() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privReceivedAudio) {
                return Promise.resolve(this.privReceivedAudio);
            }
            if (!this.privIsSynthesisEnded) {
                return null;
            }
            yield this.readAllAudioFromStream();
            return Promise.resolve(this.privReceivedAudio);
        });
    }
    getAllReceivedAudioWithHeader() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privReceivedAudioWithHeader) {
                return this.privReceivedAudioWithHeader;
            }
            if (!this.privIsSynthesisEnded) {
                return null;
            }
            if (this.audioOutputFormat.hasHeader) {
                const audio = yield this.getAllReceivedAudio();
                this.privReceivedAudioWithHeader = _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__["SynthesisAdapterBase"].addHeader(audio, this.audioOutputFormat);
                return this.privReceivedAudioWithHeader;
            }
            else {
                return this.getAllReceivedAudio();
            }
        });
    }
    startNewSynthesis(requestId, rawText, isSSML, audioDestination) {
        this.privIsSynthesisEnded = false;
        this.privIsSynthesizing = true;
        this.privRequestId = requestId;
        this.privRawText = rawText;
        this.privIsSSML = isSSML;
        this.privAudioOutputStream = new _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__["PullAudioOutputStreamImpl"]();
        this.privAudioOutputStream.format = this.privAudioOutputFormat;
        this.privReceivedAudio = null;
        this.privReceivedAudioWithHeader = null;
        this.privBytesReceived = 0;
        this.privTextOffset = 0;
        this.privNextSearchTextIndex = 0;
        this.privPartialVisemeAnimation = "";
        if (audioDestination !== undefined) {
            this.privTurnAudioDestination = audioDestination;
            this.privTurnAudioDestination.format = this.privAudioOutputFormat;
        }
        this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_3__["SynthesisTriggeredEvent"](this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));
    }
    onAudioChunkReceived(data) {
        if (this.isSynthesizing) {
            this.privAudioOutputStream.write(data);
            this.privBytesReceived += data.byteLength;
            if (this.privTurnAudioDestination !== undefined) {
                this.privTurnAudioDestination.write(data);
            }
        }
    }
    onWordBoundaryEvent(text) {
        this.updateTextOffset(text);
    }
    onVisemeMetadataReceived(metadata) {
        if (metadata.Data.AnimationChunk !== undefined) {
            this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;
        }
    }
    onStopSynthesizing() {
        this.onComplete();
    }
    /**
     * Gets the viseme animation string (merged from animation chunk), and clears the internal
     * partial animation.
     */
    getAndClearVisemeAnimation() {
        const animation = this.privPartialVisemeAnimation;
        this.privPartialVisemeAnimation = "";
        return animation;
    }
    updateTextOffset(text) {
        if (this.privTextOffset >= 0) {
            this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);
            if (this.privTextOffset >= 0) {
                this.privNextSearchTextIndex = this.privTextOffset + text.length;
            }
            if (this.privIsSSML) {
                if (this.privRawText.indexOf("<", this.privTextOffset + 1) > this.privRawText.indexOf(">", this.privTextOffset + 1)) {
                    this.updateTextOffset(text);
                }
            }
        }
    }
    readAllAudioFromStream() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privIsSynthesisEnded) {
                this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);
                try {
                    yield this.privAudioOutputStream.read(this.privReceivedAudio);
                }
                catch (e) {
                    this.privReceivedAudio = new ArrayBuffer(0);
                }
            }
        });
    }
}

//# sourceMappingURL=SynthesisTurn.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SynthesisServiceType, SynthesizerConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisServiceType", function() { return SynthesisServiceType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesizerConfig", function() { return SynthesizerConfig; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

var SynthesisServiceType;
(function (SynthesisServiceType) {
    SynthesisServiceType[SynthesisServiceType["Standard"] = 0] = "Standard";
    SynthesisServiceType[SynthesisServiceType["Custom"] = 1] = "Custom";
})(SynthesisServiceType || (SynthesisServiceType = {}));
class SynthesizerConfig {
    constructor(speechServiceConfig, parameters) {
        this.privSynthesisServiceType = SynthesisServiceType.Standard;
        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new _Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechServiceConfig"](new _Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](null));
        this.privParameters = parameters;
    }
    get parameters() {
        return this.privParameters;
    }
    get synthesisServiceType() {
        return this.privSynthesisServiceType;
    }
    set synthesisServiceType(value) {
        this.privSynthesisServiceType = value;
    }
    get SpeechServiceConfig() {
        return this.privSpeechServiceConfig;
    }
}

//# sourceMappingURL=SynthesizerConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranscriberConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranscriberConnectionFactory", function() { return TranscriberConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






class TranscriberConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__["ConnectionFactoryBase"] {
    constructor() {
        super(...arguments);
        this.multiaudioRelativeUri = "/speech/recognition/multiaudio";
        this.create = (config, authInfo, connectionId) => {
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint, undefined);
            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Region, "centralus");
            const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
            const hostDefault = "wss://transcribe." + region + ".cts.speech" + hostSuffix + this.multiaudioRelativeUri;
            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Host, hostDefault);
            const queryParams = {};
            const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_EndpointId, undefined);
            const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_RecoLanguage, undefined);
            if (endpointId) {
                if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].CustomSpeechDeploymentId) === -1) {
                    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].CustomSpeechDeploymentId] = endpointId;
                }
            }
            else if (language) {
                if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Language) === -1) {
                    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].Language] = language;
                }
            }
            this.setCommonUrlParams(config, queryParams, endpoint);
            if (!endpoint) {
                endpoint = host;
            }
            const headers = {};
            if (authInfo.token !== undefined && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].ConnectionId] = connectionId;
            config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Url, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
        };
    }
}

//# sourceMappingURL=TranscriberConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationConnectionConfig", function() { return ConversationConnectionConfig; });
/* harmony import */ var _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/RestConfigBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ConversationConnectionConfig extends _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__["RestConfigBase"] {
    static get host() {
        return ConversationConnectionConfig.privHost;
    }
    static get apiVersion() {
        return ConversationConnectionConfig.privApiVersion;
    }
    static get clientAppId() {
        return ConversationConnectionConfig.privClientAppId;
    }
    static get defaultLanguageCode() {
        return ConversationConnectionConfig.privDefaultLanguageCode;
    }
    static get restPath() {
        return ConversationConnectionConfig.privRestPath;
    }
    static get webSocketPath() {
        return ConversationConnectionConfig.privWebSocketPath;
    }
    static get speechHost() {
        return ConversationConnectionConfig.privSpeechHost;
    }
    static get speechPath() {
        return ConversationConnectionConfig.privSpeechPath;
    }
    static get transcriptionEventKeys() {
        return ConversationConnectionConfig.privTranscriptionEventKeys;
    }
}
ConversationConnectionConfig.privHost = "dev.microsofttranslator.com";
ConversationConnectionConfig.privRestPath = "/capito/room";
ConversationConnectionConfig.privApiVersion = "2.0";
ConversationConnectionConfig.privDefaultLanguageCode = "en-US";
ConversationConnectionConfig.privClientAppId = "FC539C22-1767-4F1F-84BC-B4D811114F15";
ConversationConnectionConfig.privWebSocketPath = "/capito/translate";
ConversationConnectionConfig.privSpeechHost = "{region}.s2s.speech.microsoft.com";
ConversationConnectionConfig.privSpeechPath = "/speech/translation/cognitiveservices/v1";
ConversationConnectionConfig.privTranscriptionEventKeys = ["iCalUid", "callId", "organizer", "FLAC", "MTUri", "DifferenciateGuestSpeakers", "audiorecording", "Threadid", "OrganizerMri", "OrganizerTenantId", "UserToken"];

//# sourceMappingURL=ConversationConnectionConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \*********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationConnectionFactory", function() { return ConversationConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony import */ var _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







/**
 * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.
 * The conversation must already have been started or joined.
 */
class ConversationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_4__["ConnectionFactoryBase"] {
    create(config, authInfo, connectionId) {
        const endpointHost = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Host, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].host);
        const correlationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_CorrelationId, Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createGuid"])());
        const endpoint = `wss://${endpointHost}${_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].webSocketPath}`;
        const token = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Token, undefined);
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(token, "token");
        const queryParams = {};
        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].configParams.apiVersion] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].apiVersion;
        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].configParams.token] = token;
        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__["ConversationConnectionConfig"].configParams.correlationId] = correlationId;
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, {}, new _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__["ConversationWebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
    }
}

//# sourceMappingURL=ConversationConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \*********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationConnectionMessage", function() { return ConversationConnectionMessage; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ConversationConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionMessage"] {
    constructor(messageType, body, headers, id) {
        super(messageType, body, headers, id);
        const json = JSON.parse(this.textBody);
        if (json.type !== undefined) {
            this.privConversationMessageType = json.type;
        }
    }
    get conversationMessageType() {
        return this.privConversationMessageType;
    }
}

//# sourceMappingURL=ConversationConnectionMessage.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ConversationManager */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationManager", function() { return ConversationManager; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.




class ConversationManager {
    constructor() {
        //
        this.privRequestParams = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].configParams;
        this.privErrors = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].restErrors;
        this.privHost = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].host;
        this.privApiVersion = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].apiVersion;
        this.privRestPath = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].restPath;
        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestMessageAdapter"]({});
    }
    /**
     * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.
     * @param args
     * @param conversationCode
     * @param callback
     * @param errorCallback
     */
    createOrJoin(args, conversationCode, cb, err) {
        try {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(args, "args");
            const languageCode = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].defaultLanguageCode);
            const nickname = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_Name);
            const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_Host, this.privHost);
            const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_CorrelationId);
            const subscriptionKey = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key);
            const subscriptionRegion = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region);
            const authToken = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token);
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(languageCode, "languageCode");
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(nickname, "nickname");
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(endpointHost, "endpointHost");
            const queryParams = {};
            queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
            queryParams[this.privRequestParams.languageCode] = languageCode;
            queryParams[this.privRequestParams.nickname] = nickname;
            const headers = {};
            if (correlationId) {
                headers[this.privRequestParams.correlationId] = correlationId;
            }
            headers[this.privRequestParams.clientAppId] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionConfig"].clientAppId;
            if (conversationCode !== undefined) {
                queryParams[this.privRequestParams.roomId] = conversationCode;
            }
            else {
                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);
                headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;
                if (subscriptionKey) {
                    headers[this.privRequestParams.subscriptionKey] = subscriptionKey;
                }
                else if (authToken) {
                    headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;
                }
                else {
                    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);
                }
            }
            const config = {};
            config.headers = headers;
            this.privRestAdapter.options = config;
            const endpoint = `https://${endpointHost}${this.privRestPath}`;
            // TODO: support a proxy and certificate validation
            this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Post, endpoint, queryParams, null).then((response) => {
                const requestId = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestMessageAdapter"].extractHeaderValue(this.privRequestParams.requestId, response.headers);
                if (!response.ok) {
                    if (!!err) {
                        // get the error
                        let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace("{status}", response.status.toString());
                        let errMessageRaw;
                        try {
                            errMessageRaw = JSON.parse(response.data);
                            errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;
                        }
                        catch (e) {
                            errorMessage += ` [${response.data}]`;
                        }
                        if (requestId) {
                            errorMessage += ` ${requestId}`;
                        }
                        err(errorMessage);
                    }
                    return;
                }
                const conversation = JSON.parse(response.data);
                if (conversation) {
                    conversation.requestId = requestId;
                }
                if (!!cb) {
                    try {
                        cb(conversation);
                    }
                    catch (e) {
                        if (!!err) {
                            err(e);
                        }
                    }
                    cb = undefined;
                }
                /* tslint:disable:no-empty */
            }).catch((e) => { });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
        }
    }
    /**
     * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.
     * @param args
     * @param sessionToken
     * @param callback
     */
    leave(args, sessionToken) {
        return new Promise((resolve, reject) => {
            try {
                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace("{arg}", "config"));
                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace("{arg}", "token"));
                const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_Host, this.privHost);
                const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].ConversationTranslator_CorrelationId);
                const queryParams = {};
                queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
                queryParams[this.privRequestParams.sessionToken] = sessionToken;
                const headers = {};
                if (correlationId) {
                    headers[this.privRequestParams.correlationId] = correlationId;
                }
                const config = {};
                config.headers = headers;
                this.privRestAdapter.options = config;
                const endpoint = `https://${endpointHost}${this.privRestPath}`;
                // TODO: support a proxy and certificate validation
                this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["RestRequestType"].Delete, endpoint, queryParams, null).then((response) => {
                    if (!response.ok) {
                        // ignore errors on delete
                    }
                    resolve();
                    /* tslint:disable:no-empty */
                }).catch((e) => { });
            }
            catch (error) {
                if (error instanceof Error) {
                    const typedError = error;
                    reject(typedError.name + ": " + typedError.message);
                }
                else {
                    reject(error);
                }
            }
        });
    }
}

//# sourceMappingURL=ConversationManager.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \******************************************************************************************************************************************/
/*! exports provided: ConversationRequestSession */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationRequestSession", function() { return ConversationRequestSession; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};

/**
 * Placeholder class for the Conversation Request Session. Based off RequestSession.
 * TODO: define what telemetry is required.
 */
class ConversationRequestSession {
    constructor(sessionId) {
        this.privIsDisposed = false;
        this.privDetachables = new Array();
        this.onPreConnectionStart = (authFetchEventId, connectionId) => {
            this.privSessionId = connectionId;
        };
        this.onAuthCompleted = (isError, error) => {
            if (isError) {
                this.onComplete();
            }
        };
        this.onConnectionEstablishCompleted = (statusCode, reason) => {
            if (statusCode === 200) {
                return;
            }
            else if (statusCode === 403) {
                this.onComplete();
            }
        };
        this.onServiceTurnEndResponse = (continuousRecognition) => {
            if (!continuousRecognition) {
                this.onComplete();
            }
            else {
                this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
            }
        };
        this.onComplete = () => {
            //
        };
        this.privSessionId = sessionId;
        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privRequestCompletionDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
    }
    get sessionId() {
        return this.privSessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get completionPromise() {
        return this.privRequestCompletionDeferral.promise;
    }
    dispose(error) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privIsDisposed) {
                // we should have completed by now. If we did not its an unknown error.
                this.privIsDisposed = true;
                for (const detachable of this.privDetachables) {
                    yield detachable.detach();
                }
            }
        });
    }
}

//# sourceMappingURL=ConversationRequestSession.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \******************************************************************************************************************************************/
/*! exports provided: ConversationServiceAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationServiceAdapter", function() { return ConversationServiceAdapter; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js");
/* harmony import */ var _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationRequestSession */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js");
/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceMessages/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};








/***
 * The service adapter handles sending and receiving messages to the Conversation Translator websocket.
 */
class ConversationServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);
        this.privLastPartialUtteranceId = "";
        this.noOp = () => {
            // operation not supported
        };
        this.privConversationServiceConnector = conversationServiceConnector;
        this.privConversationAuthentication = authentication;
        this.receiveMessageOverride = this.receiveConversationMessageOverride;
        this.recognizeOverride = this.noOp;
        this.postConnectImplOverride = this.conversationConnectImpl;
        this.configConnectionOverride = this.configConnection;
        this.disconnectOverride = this.privDisconnect;
        this.privConversationRequestSession = new _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_4__["ConversationRequestSession"](Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])());
        this.privConversationConnectionFactory = connectionFactory;
        this.privConversationIsDisposed = false;
    }
    isDisposed() {
        return super.isDisposed() || this.privConversationIsDisposed;
    }
    dispose(reason) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            this.privConversationIsDisposed = true;
            if (this.privConnectionConfigPromise) {
                const connection = yield this.privConnectionConfigPromise;
                yield connection.dispose(reason);
            }
            yield _super.dispose.call(this, reason);
        });
    }
    sendMessage(message) {
        return __awaiter(this, void 0, void 0, function* () {
            const connection = yield this.fetchConnection();
            return connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, message));
        });
    }
    sendMessageAsync(message) {
        return __awaiter(this, void 0, void 0, function* () {
            const sink = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            const connection = yield this.fetchConnection();
            yield connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__["ConversationConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, message));
        });
    }
    privDisconnect() {
        if (this.terminateMessageLoop) {
            return;
        }
        this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].NoError, "Disconnecting");
        this.terminateMessageLoop = true;
        return Promise.resolve();
    }
    processTypeSpecificMessages(connectionMessage, successCallback, errorCallBack) {
        return __awaiter(this, void 0, void 0, function* () {
            return true;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        this.terminateMessageLoop = true;
        const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ConversationTranslationCanceledEventArgs"](cancellationReason, error, errorCode, undefined, sessionId);
        try {
            if (!!this.privConversationServiceConnector.canceled) {
                this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);
            }
        }
        catch (_a) {
            // continue on error
        }
    }
    /**
     * Establishes a websocket connection to the end point.
     */
    conversationConnectImpl(connection) {
        return __awaiter(this, void 0, void 0, function* () {
            this.privConnectionLoop = this.startMessageLoop();
            return connection;
        });
    }
    /**
     * Process incoming websocket messages
     */
    receiveConversationMessageOverride() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.isDisposed() || this.terminateMessageLoop) {
                return Promise.resolve();
            }
            // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
            const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            try {
                const connection = yield this.fetchConnection();
                const message = yield connection.read();
                if (this.isDisposed() || this.terminateMessageLoop) {
                    // We're done.
                    communicationCustodian.resolve();
                    return Promise.resolve();
                }
                if (!message) {
                    return this.receiveConversationMessageOverride();
                }
                const sessionId = this.privConversationRequestSession.sessionId;
                let sendFinal = false;
                try {
                    switch (message.conversationMessageType.toLowerCase()) {
                        case "info":
                        case "participant_command":
                        case "command":
                            const commandPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__["CommandResponsePayload"].fromJSON(message.textBody);
                            switch (commandPayload.command.toLowerCase()) {
                                /**
                                 * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.
                                 * The consuming client must wait for this message to arrive
                                 * before starting to send their own data.
                                 */
                                case "participantlist":
                                    const participantsPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__["ParticipantsListPayloadResponse"].fromJSON(message.textBody);
                                    const participantsResult = participantsPayload.participants.map((p) => {
                                        const participant = {
                                            avatar: p.avatar,
                                            displayName: p.nickname,
                                            id: p.participantId,
                                            isHost: p.ishost,
                                            isMuted: p.ismuted,
                                            isUsingTts: p.usetts,
                                            preferredLanguage: p.locale
                                        };
                                        return participant;
                                    });
                                    if (!!this.privConversationServiceConnector.participantsListReceived) {
                                        this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantsListEventArgs"](participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).
                                 * This is sent at the start of the Conversation
                                 */
                                case "settranslatetolanguages":
                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantAttributeEventArgs"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorCommandTypes"].setTranslateToLanguages, commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetProfanityFiltering' lets the client set the level of profanity filtering.
                                 * If sent by the participant the setting will effect only their own profanity level.
                                 * If sent by the host, the setting will effect all participants including the host.
                                 * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'
                                 */
                                case "setprofanityfiltering":
                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantAttributeEventArgs"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorCommandTypes"].setProfanityFiltering, commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetMute' is sent if the participant has been muted by the host.
                                 * Check the 'participantId' to determine if the current user has been muted.
                                 */
                                case "setmute":
                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantAttributeEventArgs"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorCommandTypes"].setMute, commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetMuteAll' is sent if the Conversation has been muted by the host.
                                 */
                                case "setmuteall":
                                    if (!!this.privConversationServiceConnector.muteAllCommandReceived) {
                                        this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["MuteAllEventArgs"](commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.
                                 */
                                case "roomexpirationwarning":
                                    if (!!this.privConversationServiceConnector.conversationExpiration) {
                                        this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ConversationExpirationEventArgs"](commandPayload.value, this.privConversationRequestSession.sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.
                                 */
                                case "setusetts":
                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantAttributeEventArgs"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorCommandTypes"].setUseTTS, commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'SetLockState' is set if the host has locked or unlocked the Conversation.
                                 */
                                case "setlockstate":
                                    if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {
                                        this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["LockRoomEventArgs"](commandPayload.value, sessionId));
                                    }
                                    break;
                                /**
                                 * 'ChangeNickname' is received if a user changes their display name.
                                 * Any cached particpiants list should be updated to reflect the display name.
                                 */
                                case "changenickname":
                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantAttributeEventArgs"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorCommandTypes"].changeNickname, commandPayload.nickname, sessionId));
                                    }
                                    break;
                                /**
                                 * 'JoinSession' is sent when a user joins the Conversation.
                                 */
                                case "joinsession":
                                    const joinParticipantPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__["ParticipantPayloadResponse"].fromJSON(message.textBody);
                                    const joiningParticipant = {
                                        avatar: joinParticipantPayload.avatar,
                                        displayName: joinParticipantPayload.nickname,
                                        id: joinParticipantPayload.participantId,
                                        isHost: joinParticipantPayload.ishost,
                                        isMuted: joinParticipantPayload.ismuted,
                                        isUsingTts: joinParticipantPayload.usetts,
                                        preferredLanguage: joinParticipantPayload.locale,
                                    };
                                    if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {
                                        this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantEventArgs"](joiningParticipant, sessionId));
                                    }
                                    break;
                                /**
                                 * 'LeaveSession' is sent when a user leaves the Conversation'.
                                 */
                                case "leavesession":
                                    const leavingParticipant = {
                                        id: commandPayload.participantId
                                    };
                                    if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {
                                        this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ParticipantEventArgs"](leavingParticipant, sessionId));
                                    }
                                    break;
                                /**
                                 * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).
                                 * Check the 'ParticipantId' to check whether the message is for the current user.
                                 */
                                case "disconnectsession":
                                    const disconnectParticipant = {
                                        id: commandPayload.participantId
                                    };
                                    break;
                                case "token":
                                    const token = new _Exports__WEBPACK_IMPORTED_MODULE_2__["CognitiveTokenAuthentication"]((authFetchEventId) => {
                                        const authorizationToken = commandPayload.token;
                                        return Promise.resolve(authorizationToken);
                                    }, (authFetchEventId) => {
                                        const authorizationToken = commandPayload.token;
                                        return Promise.resolve(authorizationToken);
                                    });
                                    this.authentication = token;
                                    break;
                                /**
                                 * Message not recognized.
                                 */
                                default:
                                    break;
                            }
                            break;
                        /**
                         * 'partial' (or 'hypothesis') represents a unfinalized speech message.
                         */
                        case "partial":
                        /**
                         * 'final' (or 'phrase') represents a finalized speech message.
                         */
                        case "final":
                            const speechPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__["SpeechResponsePayload"].fromJSON(message.textBody);
                            const speechResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ConversationTranslationResult"](speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, undefined, undefined, speechPayload.recognition, undefined, undefined, message.textBody, undefined);
                            if (speechPayload.isFinal) {
                                // check the length, sometimes empty finals are returned
                                if (speechResult.text !== undefined && speechResult.text.length > 0) {
                                    sendFinal = true;
                                }
                                else if (speechPayload.id === this.privLastPartialUtteranceId) {
                                    // send final as normal. We had a non-empty partial for this same utterance
                                    // so sending the empty final is important
                                    sendFinal = true;
                                }
                                else {
                                    // suppress unneeded final
                                }
                                if (sendFinal) {
                                    if (!!this.privConversationServiceConnector.translationReceived) {
                                        this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ConversationReceivedTranslationEventArgs"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorMessageTypes"].final, speechResult, sessionId));
                                    }
                                }
                            }
                            else if (speechResult.text !== undefined) {
                                this.privLastPartialUtteranceId = speechPayload.id;
                                if (!!this.privConversationServiceConnector.translationReceived) {
                                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ConversationReceivedTranslationEventArgs"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorMessageTypes"].partial, speechResult, sessionId));
                                }
                            }
                            break;
                        /**
                         * "translated_message" is a text message or instant message (IM).
                         */
                        case "translated_message":
                            const textPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__["TextResponsePayload"].fromJSON(message.textBody);
                            const textResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ConversationTranslationResult"](textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);
                            if (!!this.privConversationServiceConnector.translationReceived) {
                                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__["ConversationReceivedTranslationEventArgs"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslatorMessageTypes"].instantMessage, textResult, sessionId));
                            }
                            break;
                        default:
                            // ignore any unsupported message types
                            break;
                    }
                }
                catch (e) {
                    // continue
                }
                return this.receiveConversationMessageOverride();
            }
            catch (e) {
                this.terminateMessageLoop = true;
            }
            return communicationCustodian.promise;
        });
    }
    startMessageLoop() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.isDisposed()) {
                return Promise.resolve();
            }
            this.terminateMessageLoop = false;
            const messageRetrievalPromise = this.receiveConversationMessageOverride();
            try {
                const r = yield messageRetrievalPromise;
                return r;
            }
            catch (error) {
                this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : "", this.privRequestSession ? this.privRequestSession.requestId : "", _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].RuntimeError, error);
                return null;
            }
        });
    }
    // Takes an established websocket connection to the endpoint
    configConnection() {
        if (this.isDisposed()) {
            return Promise.resolve(undefined);
        }
        if (this.privConnectionConfigPromise) {
            return this.privConnectionConfigPromise.then((connection) => {
                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionState"].Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionConfigPromise = null;
                    return this.configConnection();
                }
                return this.privConnectionConfigPromise;
            }, (error) => {
                this.privConnectionId = null;
                this.privConnectionConfigPromise = null;
                return this.configConnection();
            });
        }
        if (this.terminateMessageLoop) {
            return Promise.resolve(undefined);
        }
        this.privConnectionConfigPromise = this.connectImpl().then((connection) => {
            return connection;
        });
        return this.privConnectionConfigPromise;
    }
    getTranslations(serviceResultTranslations) {
        let translations;
        if (undefined !== serviceResultTranslations) {
            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["Translations"]();
            for (const translation of serviceResultTranslations) {
                translations.set(translation.lang, translation.translation);
            }
        }
        return translations;
    }
}

//# sourceMappingURL=ConversationServiceAdapter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \***********************************************************************************************************************************************/
/*! exports provided: MuteAllEventArgs, LockRoomEventArgs, ParticipantEventArgs, ParticipantAttributeEventArgs, ParticipantsListEventArgs, ConversationReceivedTranslationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MuteAllEventArgs", function() { return MuteAllEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LockRoomEventArgs", function() { return LockRoomEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantEventArgs", function() { return ParticipantEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantAttributeEventArgs", function() { return ParticipantAttributeEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantsListEventArgs", function() { return ParticipantsListEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationReceivedTranslationEventArgs", function() { return ConversationReceivedTranslationEventArgs; });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class MuteAllEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(isMuted, sessionId) {
        super(sessionId);
        this.privIsMuted = isMuted;
    }
    get isMuted() {
        return this.privIsMuted;
    }
}
// tslint:disable-next-line: max-classes-per-file
class LockRoomEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(isLocked, sessionId) {
        super(sessionId);
        this.privIsLocked = isLocked;
    }
    get isMuted() {
        return this.privIsLocked;
    }
}
// tslint:disable-next-line: max-classes-per-file
class ParticipantEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(participant, sessionId) {
        super(sessionId);
        this.privParticipant = participant;
    }
    get participant() {
        return this.privParticipant;
    }
}
// tslint:disable-next-line: max-classes-per-file
class ParticipantAttributeEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(participantId, key, value, sessionId) {
        super(sessionId);
        this.privKey = key;
        this.privValue = value;
        this.privParticipantId = participantId;
    }
    get value() {
        return this.privValue;
    }
    get key() {
        return this.privKey;
    }
    get id() {
        return this.privParticipantId;
    }
}
// tslint:disable-next-line: max-classes-per-file
class ParticipantsListEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {
        super(sessionId);
        this.privRoomId = conversationId;
        this.privSessionToken = token;
        this.privTranslateTo = translateTo;
        this.privProfanityFilter = profanityFilter;
        this.privRoomProfanityFilter = roomProfanityFilter;
        this.privIsRoomLocked = isRoomLocked;
        this.privIsRoomLocked = isMuteAll;
        this.privParticipants = participants;
    }
    get sessionToken() {
        return this.privSessionToken;
    }
    get conversationId() {
        return this.privRoomId;
    }
    get translateTo() {
        return this.privTranslateTo;
    }
    get profanityFilter() {
        return this.privProfanityFilter;
    }
    get roomProfanityFilter() {
        return this.privRoomProfanityFilter;
    }
    get isRoomLocked() {
        return this.privIsRoomLocked;
    }
    get isMuteAll() {
        return this.privIsMuteAll;
    }
    get participants() {
        return this.privParticipants;
    }
}
// tslint:disable-next-line: max-classes-per-file
class ConversationReceivedTranslationEventArgs {
    constructor(command, payload, sessionId) {
        this.privPayload = payload;
        this.privCommand = command;
        this.privSessionId = sessionId;
    }
    get payload() {
        return this.privPayload;
    }
    get command() {
        return this.privCommand;
    }
    get sessionId() {
        return this.privSessionId;
    }
}

//# sourceMappingURL=ConversationTranslatorEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \************************************************************************************************************************************************/
/*! exports provided: InternalParticipants, ConversationTranslatorMessageTypes, ConversationTranslatorCommandTypes */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "InternalParticipants", function() { return InternalParticipants; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorMessageTypes", function() { return ConversationTranslatorMessageTypes; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorCommandTypes", function() { return ConversationTranslatorCommandTypes; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/** Users participating in the conversation */
class InternalParticipants {
    constructor(participants = [], meId) {
        this.participants = participants;
        this.meId = meId;
    }
    /**
     * Add or update a participant
     * @param value
     */
    addOrUpdateParticipant(value) {
        if (value === undefined) {
            return;
        }
        const exists = this.getParticipantIndex(value.id);
        if (exists > -1) {
            this.participants.splice(exists, 1, value);
        }
        else {
            this.participants.push(value);
        }
        // ensure it was added ok
        return this.getParticipant(value.id);
    }
    /**
     * Find the participant's position in the participants list.
     * @param id
     */
    getParticipantIndex(id) {
        return this.participants.findIndex((p) => p.id === id);
    }
    /**
     * Find the participant by id.
     * @param id
     */
    getParticipant(id) {
        return this.participants.find((p) => p.id === id);
    }
    /***
     * Remove a participant from the participants list.
     */
    deleteParticipant(id) {
        this.participants = this.participants.filter((p) => p.id !== id);
    }
    /***
     * Helper to return the conversation host.
     */
    get host() {
        return this.participants.find((p) => p.isHost === true);
    }
    /**
     * Helper to return the current user.
     */
    get me() {
        return this.getParticipant(this.meId);
    }
}
/**
 * List of command message types
 */
const ConversationTranslatorMessageTypes = {
    command: "command",
    final: "final",
    info: "info",
    instantMessage: "instant_message",
    keepAlive: "keep_alive",
    partial: "partial",
    participantCommand: "participant_command",
    translatedMessage: "translated_message"
};
/**
 * List of command types
 */
const ConversationTranslatorCommandTypes = {
    changeNickname: "ChangeNickname",
    disconnectSession: "DisconnectSession",
    ejectParticipant: "EjectParticipant",
    instant_message: "instant_message",
    joinSession: "JoinSession",
    leaveSession: "LeaveSession",
    participantList: "ParticipantList",
    roomExpirationWarning: "RoomExpirationWarning",
    setLockState: "SetLockState",
    setMute: "SetMute",
    setMuteAll: "SetMuteAll",
    setProfanityFiltering: "SetProfanityFiltering",
    setTranslateToLanguages: "SetTranslateToLanguages",
    setUseTTS: "SetUseTTS"
};

//# sourceMappingURL=ConversationTranslatorInterfaces.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \************************************************************************************************************************************************/
/*! exports provided: ConversationRecognizerFactory, ConversationTranslatorRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationRecognizerFactory", function() { return ConversationRecognizerFactory; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorRecognizer", function() { return ConversationTranslatorRecognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js");
/* harmony import */ var _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationServiceAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};






class ConversationRecognizerFactory {
    static fromConfig(conversation, speechConfig, audioConfig) {
        return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);
    }
}
/**
 * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.
 * Based off the recognizers in the SDK folder.
 */
// tslint:disable-next-line:max-classes-per-file
class ConversationTranslatorRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__["Recognizer"] {
    constructor(conversation, speechConfig, audioConfig) {
        const serviceConfigImpl = speechConfig;
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(serviceConfigImpl, "speechConfig");
        const conversationImpl = conversation;
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(conversationImpl, "conversationImpl");
        super(audioConfig, serviceConfigImpl.properties, new _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_4__["ConversationConnectionFactory"]());
        this.privConversation = conversationImpl;
        this.privIsDisposed = false;
        this.privProperties = serviceConfigImpl.properties.clone();
        this.privConnection = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__["Connection"].fromRecognizer(this);
        this.privSetTimeout = (typeof (Blob) !== "undefined" && typeof (Worker) !== "undefined") ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Timeout"].setTimeout : setTimeout;
        this.privClearTimeout = (typeof (Blob) !== "undefined" && typeof (Worker) !== "undefined") ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Timeout"].clearTimeout : clearTimeout;
    }
    set connected(cb) {
        this.privConnection.connected = cb;
    }
    set disconnected(cb) {
        this.privConnection.disconnected = cb;
    }
    /**
     * Return the speech language used by the recognizer
     */
    get speechRecognitionLanguage() {
        return this.privSpeechRecognitionLanguage;
    }
    /**
     * Return the properties for the recognizer
     */
    get properties() {
        return this.privProperties;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    /**
     * Connect to the recognizer
     * @param token
     */
    connect(token, cb, err) {
        try {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(token, "token");
            this.privReco.conversationTranslatorToken = token;
            this.resetConversationTimeout();
            this.privReco.connectAsync(cb, err);
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
        }
    }
    /**
     * Disconnect from the recognizer
     */
    disconnect(cb, err) {
        try {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            if (this.privTimeoutToken !== undefined) {
                this.privClearTimeout(this.privTimeoutToken);
            }
            this.privReco.disconnect().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the recognizer.
            this.dispose(true).catch((reason) => {
                _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
            });
        }
    }
    /**
     * Send the mute all participants command to the websocket
     * @param conversationId
     * @param participantId
     * @param isMuted
     */
    sendRequest(command, cb, err) {
        try {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            this.sendMessage(command, cb, err);
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the recognizer.
            this.dispose(true).catch((reason) => {
                _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
            });
        }
    }
    /**
     * Close and dispose the recognizer
     */
    close() {
        var _a, _b;
        return __awaiter(this, void 0, void 0, function* () {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            (_a = this.privConnection) === null || _a === void 0 ? void 0 : _a.closeConnection();
            (_b = this.privConnection) === null || _b === void 0 ? void 0 : _b.close();
            this.privConnection = undefined;
            yield this.dispose(true);
        });
    }
    /**
     * Dispose the recognizer
     * @param disposing
     */
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privIsDisposed) {
                return;
            }
            if (disposing) {
                if (this.privTimeoutToken !== undefined) {
                    this.privClearTimeout(this.privTimeoutToken);
                }
                this.privIsDisposed = true;
                if (!!this.privConnection) {
                    this.privConnection.closeConnection();
                    this.privConnection.close();
                    this.privConnection = undefined;
                }
                yield _super.dispose.call(this, disposing);
            }
        });
    }
    /**
     * Create the config for the recognizer
     * @param speechConfig
     */
    createRecognizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognizerConfig"](speechConfig, this.privProperties);
    }
    /**
     * Create the service recognizer.
     * The audio source is redundnant here but is required by the implementation.
     * @param authentication
     * @param connectionFactory
     * @param audioConfig
     * @param recognizerConfig
     */
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const audioSource = audioConfig;
        return new _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_5__["ConversationServiceAdapter"](authentication, connectionFactory, audioSource, recognizerConfig, this);
    }
    sendMessage(msg, cb, err) {
        const withAsync = this.privReco;
        function PromiseToEmptyCallback(promise, cb, err) {
            if (!!promise) {
                promise.then((result) => {
                    try {
                        if (!!cb) {
                            cb();
                        }
                    }
                    catch (e) {
                        if (!!err) {
                            err(`'Unhandled error on promise callback: ${e}'`);
                        }
                    }
                }, (reason) => {
                    try {
                        if (!!err) {
                            err(reason);
                        }
                        /* tslint:disable:no-empty */
                    }
                    catch (error) {
                    }
                });
            }
            else {
                if (!!err) {
                    err("Null promise");
                }
            }
        }
        PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);
        this.resetConversationTimeout();
    }
    resetConversationTimeout() {
        if (this.privTimeoutToken !== undefined) {
            this.privClearTimeout(this.privTimeoutToken);
        }
        this.privTimeoutToken = this.privSetTimeout(() => {
            this.sendRequest(this.privConversation.getKeepAlive());
        }, 60000);
    }
}

//# sourceMappingURL=ConversationTranslatorRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
/*!*****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \*****************************************************************************************************************************************************/
/*! exports provided: ConversationWebsocketMessageFormatter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationWebsocketMessageFormatter", function() { return ConversationWebsocketMessageFormatter; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.
 */
class ConversationWebsocketMessageFormatter {
    constructor() {
        /**
         * Format incoming messages: text (speech partial/final, IM) or binary (tts)
         */
        this.toConnectionMessage = (message) => {
            const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            try {
                if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                    const incomingMessage = new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__["ConversationConnectionMessage"](message.messageType, message.textContent, {}, message.id);
                    deferral.resolve(incomingMessage);
                }
                else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary) {
                    deferral.resolve(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__["ConversationConnectionMessage"](message.messageType, message.binaryContent, undefined, message.id));
                }
            }
            catch (e) {
                deferral.reject(`Error formatting the message. Error: ${e}`);
            }
            return deferral.promise;
        };
        /**
         * Format outgoing messages: text (commands or IM)
         */
        this.fromConnectionMessage = (message) => {
            const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            try {
                if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                    const payload = `${message.textBody ? message.textBody : ""}`;
                    deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["RawWebsocketMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, payload, message.id));
                }
            }
            catch (e) {
                deferral.reject(`Error formatting the message. ${e}`);
            }
            return deferral.promise;
        };
    }
}

//# sourceMappingURL=ConversationWebsocketMessageFormatter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ConversationManager, ConversationConnectionConfig, ConversationRecognizerFactory, TranscriberRecognizer, ConversationReceivedTranslationEventArgs, LockRoomEventArgs, MuteAllEventArgs, ParticipantAttributeEventArgs, ParticipantEventArgs, ParticipantsListEventArgs, ConversationTranslatorCommandTypes, ConversationTranslatorMessageTypes, InternalParticipants */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _ConversationManager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationManager */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationManager", function() { return _ConversationManager__WEBPACK_IMPORTED_MODULE_0__["ConversationManager"]; });

/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationConnectionConfig", function() { return _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__["ConversationConnectionConfig"]; });

/* harmony import */ var _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationTranslatorRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationRecognizerFactory", function() { return _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__["ConversationRecognizerFactory"]; });

/* harmony import */ var _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./TranscriberRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranscriberRecognizer", function() { return _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__["TranscriberRecognizer"]; });

/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationReceivedTranslationEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["ConversationReceivedTranslationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "LockRoomEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["LockRoomEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MuteAllEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["MuteAllEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantAttributeEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["ParticipantAttributeEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["ParticipantEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantsListEventArgs", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__["ParticipantsListEventArgs"]; });

/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorCommandTypes", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__["ConversationTranslatorCommandTypes"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslatorMessageTypes", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__["ConversationTranslatorMessageTypes"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "InternalParticipants", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__["InternalParticipants"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
/*!******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \******************************************************************************************************************************************************/
/*! exports provided: CommandResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CommandResponsePayload", function() { return CommandResponsePayload; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class CommandResponsePayload {
    constructor(json) {
        this.privCommandResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new CommandResponsePayload(json);
    }
    get type() {
        return this.privCommandResponse.type;
    }
    get command() {
        return this.privCommandResponse.command;
    }
    get id() {
        return this.privCommandResponse.id;
    }
    get nickname() {
        return this.privCommandResponse.nickname;
    }
    get participantId() {
        return this.privCommandResponse.participantId;
    }
    get roomid() {
        return this.privCommandResponse.roomid;
    }
    get value() {
        return this.privCommandResponse.value;
    }
    get token() {
        return this.privCommandResponse.token;
    }
}

//# sourceMappingURL=CommandResponsePayload.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js ***!
  \***************************************************************************************************************************************/
/*! exports provided: CommandResponsePayload, ParticipantsListPayloadResponse, ParticipantPayloadResponse, SpeechResponsePayload, TextResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _CommandResponsePayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CommandResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CommandResponsePayload", function() { return _CommandResponsePayload__WEBPACK_IMPORTED_MODULE_0__["CommandResponsePayload"]; });

/* harmony import */ var _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ParticipantResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantsListPayloadResponse", function() { return _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__["ParticipantsListPayloadResponse"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantPayloadResponse", function() { return _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__["ParticipantPayloadResponse"]; });

/* harmony import */ var _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TranslationResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechResponsePayload", function() { return _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__["SpeechResponsePayload"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TextResponsePayload", function() { return _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__["TextResponsePayload"]; });





//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/*! exports provided: ParticipantsListPayloadResponse, ParticipantPayloadResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantsListPayloadResponse", function() { return ParticipantsListPayloadResponse; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantPayloadResponse", function() { return ParticipantPayloadResponse; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ParticipantsListPayloadResponse {
    constructor(json) {
        this.privParticipantsPayloadResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new ParticipantsListPayloadResponse(json);
    }
    get roomid() {
        return this.privParticipantsPayloadResponse.roomid;
    }
    get id() {
        return this.privParticipantsPayloadResponse.id;
    }
    get command() {
        return this.privParticipantsPayloadResponse.command;
    }
    get participants() {
        return this.privParticipantsPayloadResponse.participants;
    }
    get token() {
        return this.privParticipantsPayloadResponse.token;
    }
    get translateTo() {
        return this.privParticipantsPayloadResponse.translateTo;
    }
    get profanityFilter() {
        return this.privParticipantsPayloadResponse.profanityFilter;
    }
    get roomProfanityFilter() {
        return this.privParticipantsPayloadResponse.roomProfanityFilter;
    }
    get roomLocked() {
        return this.privParticipantsPayloadResponse.roomLocked;
    }
    get muteAll() {
        return this.privParticipantsPayloadResponse.muteAll;
    }
    get type() {
        return this.privParticipantsPayloadResponse.type;
    }
}
// tslint:disable-next-line: max-classes-per-file
class ParticipantPayloadResponse {
    constructor(json) {
        this.privParticipantPayloadResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new ParticipantPayloadResponse(json);
    }
    get nickname() {
        return this.privParticipantPayloadResponse.nickname;
    }
    get locale() {
        return this.privParticipantPayloadResponse.locale;
    }
    get usetts() {
        return this.privParticipantPayloadResponse.usetts;
    }
    get ismuted() {
        return this.privParticipantPayloadResponse.ismuted;
    }
    get ishost() {
        return this.privParticipantPayloadResponse.ishost;
    }
    get participantId() {
        return this.privParticipantPayloadResponse.participantId;
    }
    get avatar() {
        return this.privParticipantPayloadResponse.avatar;
    }
}

//# sourceMappingURL=ParticipantResponsePayload.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/*! exports provided: SpeechResponsePayload, TextResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechResponsePayload", function() { return SpeechResponsePayload; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TextResponsePayload", function() { return TextResponsePayload; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechResponsePayload {
    constructor(json) {
        this.privSpeechResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SpeechResponsePayload(json);
    }
    get recognition() {
        return this.privSpeechResponse.recognition;
    }
    get translations() {
        return this.privSpeechResponse.translations;
    }
    get id() {
        return this.privSpeechResponse.id;
    }
    get language() {
        return this.privSpeechResponse.language;
    }
    get nickname() {
        return this.privSpeechResponse.nickname;
    }
    get participantId() {
        return this.privSpeechResponse.participantId;
    }
    get roomid() {
        return this.privSpeechResponse.roomid;
    }
    get timestamp() {
        return this.privSpeechResponse.timestamp;
    }
    get type() {
        return this.privSpeechResponse.type;
    }
    get isFinal() {
        return this.privSpeechResponse.type === "final";
    }
}
// tslint:disable-next-line: max-classes-per-file
class TextResponsePayload {
    constructor(json) {
        this.privTextResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new TextResponsePayload(json);
    }
    get originalText() {
        return this.privTextResponse.originalText;
    }
    get translations() {
        return this.privTextResponse.translations;
    }
    get id() {
        return this.privTextResponse.id;
    }
    get language() {
        return this.privTextResponse.language;
    }
    get nickname() {
        return this.privTextResponse.nickname;
    }
    get participantId() {
        return this.privTextResponse.participantId;
    }
    get roomid() {
        return this.privTextResponse.roomid;
    }
    get timestamp() {
        return this.privTextResponse.timestamp;
    }
    get type() {
        return this.privTextResponse.type;
    }
}

//# sourceMappingURL=TranslationResponsePayload.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \*************************************************************************************************************************************/
/*! exports provided: TranscriberRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranscriberRecognizer", function() { return TranscriberRecognizer; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




class TranscriberRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["Recognizer"] {
    /**
     * TranscriberRecognizer constructor.
     * @constructor
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(speechTranslationConfig, audioConfig) {
        const speechTranslationConfigImpl = speechTranslationConfig;
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(speechTranslationConfigImpl, "speechTranslationConfig");
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
        super(audioConfig, speechTranslationConfigImpl.properties, new _Exports__WEBPACK_IMPORTED_MODULE_3__["TranscriberConnectionFactory"]());
        this.privDisposedRecognizer = false;
    }
    getConversationInfo() {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(this.privConversation, "Conversation");
        return this.privConversation.conversationInfo;
    }
    get authorizationToken() {
        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    set authorizationToken(token) {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    set conversation(c) {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(c, "Conversation");
        this.privConversation = c;
    }
    get speechRecognitionLanguage() {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    get properties() {
        return this.privProperties;
    }
    startContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["marshalPromiseToCallbacks"])(this.startContinuousRecognitionAsyncImpl(_Exports__WEBPACK_IMPORTED_MODULE_3__["RecognitionMode"].Conversation), cb, err);
    }
    stopContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["marshalPromiseToCallbacks"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    close() {
        return __awaiter(this, void 0, void 0, function* () {
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
            yield this.dispose(true);
        });
    }
    // Push async join/leave conversation message via serviceRecognizer
    pushConversationEvent(conversationInfo, command) {
        return __awaiter(this, void 0, void 0, function* () {
            const reco = (this.privReco);
            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(reco, "serviceRecognizer");
            yield reco.sendSpeechEventAsync(conversationInfo, command);
        });
    }
    connectCallbacks(transcriber) {
        this.canceled = (s, e) => {
            if (!!transcriber.canceled) {
                transcriber.canceled(transcriber, e);
            }
        };
        this.recognizing = (s, e) => {
            if (!!transcriber.transcribing) {
                transcriber.transcribing(transcriber, e);
            }
        };
        this.recognized = (s, e) => {
            if (!!transcriber.transcribed) {
                transcriber.transcribed(transcriber, e);
            }
        };
        this.sessionStarted = (s, e) => {
            if (!!transcriber.sessionStarted) {
                transcriber.sessionStarted(transcriber, e);
            }
        };
        this.sessionStopped = (s, e) => {
            if (!!transcriber.sessionStopped) {
                transcriber.sessionStopped(transcriber, e);
            }
        };
    }
    disconnectCallbacks() {
        this.canceled = undefined;
        this.recognizing = undefined;
        this.recognized = undefined;
        this.sessionStarted = undefined;
        this.sessionStopped = undefined;
    }
    /**
     * Disposes any resources held by the object.
     * @member ConversationTranscriber.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposedRecognizer) {
                return;
            }
            if (disposing) {
                this.privDisposedRecognizer = true;
                yield this.implRecognizerStop();
            }
            yield _super.dispose.call(this, disposing);
        });
    }
    createRecognizerConfig(speechConfig) {
        return new _Exports__WEBPACK_IMPORTED_MODULE_3__["RecognizerConfig"](speechConfig, this.properties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new _Exports__WEBPACK_IMPORTED_MODULE_3__["TranscriptionServiceRecognizer"](authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
}

//# sourceMappingURL=TranscriberRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \********************************************************************************************************************************/
/*! exports provided: TranscriptionServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranscriptionServiceRecognizer", function() { return TranscriptionServiceRecognizer; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




// tslint:disable-next-line:max-classes-per-file
class TranscriptionServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);
        this.sendSpeechEvent = (connection, payload) => {
            const speechEventJson = JSON.stringify(payload);
            if (speechEventJson) {
                return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__["SpeechConnectionMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, "speech.event", this.privRequestSession.requestId, "application/json", speechEventJson));
            }
            return;
        };
        this.privTranscriberRecognizer = transcriber;
        this.sendPrePayloadJSONOverride = this.sendTranscriptionStartJSON;
    }
    sendSpeechEventAsync(info, command) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privRequestSession.isRecognizing) {
                const connection = yield this.fetchConnection();
                yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));
            }
        });
    }
    processTypeSpecificMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            let result;
            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);
            let processed = false;
            switch (connectionMessage.path.toLowerCase()) {
                case "speech.hypothesis":
                case "speech.fragment":
                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechHypothesis"].fromJSON(connectionMessage.textBody);
                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionResult"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, connectionMessage.textBody, resultProps);
                    this.privRequestSession.onHypothesis(offset);
                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionEventArgs"](result, hypothesis.Duration, this.privRequestSession.sessionId);
                    if (!!this.privTranscriberRecognizer.recognizing) {
                        try {
                            this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "speech.phrase":
                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_2__["SimpleSpeechPhrase"].fromJSON(connectionMessage.textBody);
                    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateRecognitionResult(simple.RecognitionStatus);
                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
                    if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled === resultReason) {
                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateCancelResult(simple.RecognitionStatus);
                        yield this.cancelRecognitionLocal(cancelReason, _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateCancelErrorCode(simple.RecognitionStatus), undefined);
                    }
                    else {
                        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionStatus"].InitialSilenceTimeout)) {
                            if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormatPropertyName"]) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["OutputFormat"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["OutputFormat"].Simple]) {
                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionResult"](this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, connectionMessage.textBody, resultProps);
                            }
                            else {
                                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_2__["DetailedSpeechPhrase"].fromJSON(connectionMessage.textBody);
                                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
                                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionResult"](this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionStatus"].Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, undefined, offsetCorrectedJson, resultProps);
                            }
                            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionEventArgs"](result, result.offset, this.privRequestSession.sessionId);
                            if (!!this.privTranscriberRecognizer.recognized) {
                                try {
                                    this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);
                                    /* tslint:disable:no-empty */
                                }
                                catch (error) {
                                    // Not going to let errors in the event handler
                                    // trip things up.
                                }
                            }
                        }
                        if (!!this.privSuccessCallback) {
                            try {
                                this.privSuccessCallback(result);
                            }
                            catch (e) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(e);
                                }
                            }
                            // Only invoke the call back once.
                            // and if it's successful don't invoke the
                            // error after that.
                            this.privSuccessCallback = undefined;
                            this.privErrorCallback = undefined;
                        }
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][errorCode]);
        if (!!this.privTranscriberRecognizer.canceled) {
            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ConversationTranscriptionCanceledEventArgs"](cancellationReason, error, errorCode, undefined, sessionId);
            try {
                this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);
                /* tslint:disable:no-empty */
            }
            catch (_a) { }
        }
        if (!!this.privSuccessCallback) {
            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechRecognitionResult"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled, undefined, // Text
            undefined, // Duration
            undefined, // Offset
            undefined, // Language
            undefined, // Language Detection Confidence
            undefined, // Speaker Id
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                this.privSuccessCallback = undefined;
                /* tslint:disable:no-empty */
            }
            catch (_b) { }
        }
    }
    // Encapsulated for derived service recognizers that need to send additional JSON
    sendTranscriptionStartJSON(connection) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.sendSpeechContext(connection);
            const info = this.privTranscriberRecognizer.getConversationInfo();
            const payload = this.createSpeechEventPayload(info, "start");
            yield this.sendSpeechEvent(connection, payload);
            yield this.sendWaveHeader(connection);
            return;
        });
    }
    createSpeechEventPayload(info, command) {
        const meeting = "meeting";
        const eventDict = { id: meeting, name: command, meeting: info.conversationProperties };
        const idString = "id";
        const attendees = "attendees";
        const record = "record";
        eventDict[meeting][idString] = info.id;
        eventDict[meeting][attendees] = info.participants;
        eventDict[meeting][record] = info.conversationProperties.audiorecording === "on" ? "true" : "false";
        return eventDict;
    }
}

//# sourceMappingURL=TranscriptionServiceRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranslationConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationConnectionFactory", function() { return TranslationConnectionFactory; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






class TranslationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__["ConnectionFactoryBase"] {
    constructor() {
        super(...arguments);
        this.create = (config, authInfo, connectionId) => {
            let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Endpoint, undefined);
            if (!endpoint) {
                const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Region, undefined);
                const hostSuffix = (region && region.toLowerCase().startsWith("china")) ? ".azure.cn" : ".microsoft.com";
                const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Host, "wss://" + region + ".s2s.speech" + hostSuffix);
                endpoint = host + "/speech/translation/cognitiveservices/v1";
            }
            const queryParams = {
                from: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_RecoLanguage),
                to: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_TranslationToLanguages),
            };
            this.setCommonUrlParams(config, queryParams, endpoint);
            this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_TranslationRequestStablePartialResult, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__["QueryParameterNames"].StableTranslation, config, queryParams, endpoint);
            const voiceName = "voice";
            const featureName = "features";
            if (config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {
                queryParams[voiceName] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_TranslationVoice);
                queryParams[featureName] = "texttospeech";
            }
            const headers = {};
            if (authInfo.token !== undefined && authInfo.token !== "") {
                headers[authInfo.headerName] = authInfo.token;
            }
            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__["HeaderNames"].ConnectionId] = connectionId;
            config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_Url, endpoint);
            const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
            return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["WebsocketConnection"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__["WebsocketMessageFormatter"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["ProxyInfo"].fromRecognizerConfig(config), enableCompression, connectionId);
        };
    }
}

//# sourceMappingURL=TranslationConnectionFactory.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranslationServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationServiceRecognizer", function() { return TranslationServiceRecognizer; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



// tslint:disable-next-line:max-classes-per-file
class TranslationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__["ServiceRecognizerBase"] {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);
        this.privTranslationRecognizer = translationRecognizer;
        this.connectionEvents.attach((connectionEvent) => __awaiter(this, void 0, void 0, function* () {
            if (connectionEvent.name === "ConnectionEstablishedEvent") {
                this.privTranslationRecognizer.onConnection();
            }
            else if (connectionEvent.name === "ConnectionClosedEvent") {
                yield this.privTranslationRecognizer.onDisconnection();
            }
        }));
    }
    processTypeSpecificMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
            let processed = false;
            if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);
            }
            switch (connectionMessage.path.toLowerCase()) {
                case "translation.hypothesis":
                    const result = this.fireEventForResult(_Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationHypothesis"].fromJSON(connectionMessage.textBody), resultProps);
                    this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);
                    if (!!this.privTranslationRecognizer.recognizing) {
                        try {
                            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);
                            /* tslint:disable:no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    processed = true;
                    break;
                case "translation.phrase":
                    const translatedPhrase = _Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationPhrase"].fromJSON(connectionMessage.textBody);
                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);
                    if (translatedPhrase.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionStatus"].Success) {
                        // OK, the recognition was successful. How'd the translation do?
                        const result = this.fireEventForResult(translatedPhrase, resultProps);
                        if (!!this.privTranslationRecognizer.recognized) {
                            try {
                                this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);
                                /* tslint:disable:no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                        // report result to promise.
                        if (!!this.privSuccessCallback) {
                            try {
                                this.privSuccessCallback(result.result);
                            }
                            catch (e) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(e);
                                }
                            }
                            // Only invoke the call back once.
                            // and if it's successful don't invoke the
                            // error after that.
                            this.privSuccessCallback = undefined;
                            this.privErrorCallback = undefined;
                        }
                        break;
                    }
                    else {
                        const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);
                        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionResult"](undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, undefined, connectionMessage.textBody, resultProps);
                        if (reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled) {
                            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateCancelResult(translatedPhrase.RecognitionStatus);
                            yield this.cancelRecognitionLocal(cancelReason, _Exports__WEBPACK_IMPORTED_MODULE_2__["EnumTranslation"].implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus), undefined);
                        }
                        else {
                            if (!(this.privRequestSession.isSpeechEnded && reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].NoMatch && translatedPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionStatus"].InitialSilenceTimeout)) {
                                const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionEventArgs"](result, result.offset, this.privRequestSession.sessionId);
                                if (!!this.privTranslationRecognizer.recognized) {
                                    try {
                                        this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
                                        /* tslint:disable:no-empty */
                                    }
                                    catch (error) {
                                        // Not going to let errors in the event handler
                                        // trip things up.
                                    }
                                }
                            }
                            // report result to promise.
                            if (!!this.privSuccessCallback) {
                                try {
                                    this.privSuccessCallback(result);
                                }
                                catch (e) {
                                    if (!!this.privErrorCallback) {
                                        this.privErrorCallback(e);
                                    }
                                }
                                // Only invoke the call back once.
                                // and if it's successful don't invoke the
                                // error after that.
                                this.privSuccessCallback = undefined;
                                this.privErrorCallback = undefined;
                            }
                        }
                    }
                    processed = true;
                    break;
                case "translation.synthesis":
                    this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);
                    processed = true;
                    break;
                case "translation.synthesis.end":
                    const synthEnd = _Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationSynthesisEnd"].fromJSON(connectionMessage.textBody);
                    switch (synthEnd.SynthesisStatus) {
                        case _Exports__WEBPACK_IMPORTED_MODULE_2__["SynthesisStatus"].Error:
                            if (!!this.privTranslationRecognizer.synthesizing) {
                                const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationSynthesisResult"](_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled, undefined);
                                const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationSynthesisEventArgs"](result, this.privRequestSession.sessionId);
                                try {
                                    this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                                    /* tslint:disable:no-empty */
                                }
                                catch (error) {
                                    // Not going to let errors in the event handler
                                    // trip things up.
                                }
                            }
                            if (!!this.privTranslationRecognizer.canceled) {
                                // And raise a canceled event to send the rich(er) error message back.
                                const canceledResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionCanceledEventArgs"](this.privRequestSession.sessionId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error, synthEnd.FailureReason, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].ServiceError, null);
                                try {
                                    this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);
                                    /* tslint:disable:no-empty */
                                }
                                catch (error) {
                                    // Not going to let errors in the event handler
                                    // trip things up.
                                }
                            }
                            break;
                        case _Exports__WEBPACK_IMPORTED_MODULE_2__["SynthesisStatus"].Success:
                            this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);
                            break;
                        default:
                            break;
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCodePropertyName"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][errorCode]);
        if (!!this.privTranslationRecognizer.canceled) {
            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionCanceledEventArgs"](sessionId, cancellationReason, error, errorCode, undefined);
            try {
                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);
                /* tslint:disable:no-empty */
            }
            catch (_a) { }
        }
        if (!!this.privSuccessCallback) {
            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionResult"](undefined, // Translations
            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled, undefined, // Text
            undefined, // Druation
            undefined, // Offset
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                /* tslint:disable:no-empty */
                this.privSuccessCallback = undefined;
            }
            catch (_b) { }
        }
    }
    fireEventForResult(serviceResult, properties) {
        let translations;
        if (undefined !== serviceResult.Translation.Translations) {
            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["Translations"]();
            for (const translation of serviceResult.Translation.Translations) {
                translations.set(translation.Language, translation.Text);
            }
        }
        let resultReason;
        if (serviceResult instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["TranslationPhrase"]) {
            if (serviceResult.Translation.TranslationStatus === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["TranslationStatus"].Success) {
                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].TranslatedSpeech;
            }
            else {
                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].RecognizedSpeech;
            }
        }
        else {
            resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].TranslatingSpeech;
        }
        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionResult"](translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);
        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationRecognitionEventArgs"](result, offset, this.privRequestSession.sessionId);
        return ev;
    }
    sendSynthesisAudio(audio, sessionId) {
        const reason = (undefined === audio) ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].SynthesizingAudioCompleted : _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].SynthesizingAudio;
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationSynthesisResult"](reason, audio);
        const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__["TranslationSynthesisEventArgs"](result, sessionId);
        if (!!this.privTranslationRecognizer.synthesizing) {
            try {
                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                /* tslint:disable:no-empty */
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
}

//# sourceMappingURL=TranslationServiceRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js ***!
  \*******************************************************************************************************************/
/*! exports provided: TranslationStatus */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationStatus", function() { return TranslationStatus; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines translation status.
 * @class TranslationStatus
 */
var TranslationStatus;
(function (TranslationStatus) {
    /**
     * @member TranslationStatus.Success
     */
    TranslationStatus[TranslationStatus["Success"] = 0] = "Success";
    /**
     * @member TranslationStatus.Error
     */
    TranslationStatus[TranslationStatus["Error"] = 1] = "Error";
})(TranslationStatus || (TranslationStatus = {}));

//# sourceMappingURL=TranslationStatus.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js ***!
  \***************************************************************************************************************************/
/*! exports provided: WebsocketMessageFormatter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "WebsocketMessageFormatter", function() { return WebsocketMessageFormatter; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

const CRLF = "\r\n";
class WebsocketMessageFormatter {
    constructor() {
        this.toConnectionMessage = (message) => {
            const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            try {
                if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                    const textMessage = message.textContent;
                    let headers = {};
                    let body = null;
                    if (textMessage) {
                        const headerBodySplit = textMessage.split("\r\n\r\n");
                        if (headerBodySplit && headerBodySplit.length > 0) {
                            headers = this.parseHeaders(headerBodySplit[0]);
                            if (headerBodySplit.length > 1) {
                                body = headerBodySplit[1];
                            }
                        }
                    }
                    deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionMessage"](message.messageType, body, headers, message.id));
                }
                else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary) {
                    const binaryMessage = message.binaryContent;
                    let headers = {};
                    let body = null;
                    if (!binaryMessage || binaryMessage.byteLength < 2) {
                        throw new Error("Invalid binary message format. Header length missing.");
                    }
                    const dataView = new DataView(binaryMessage);
                    const headerLength = dataView.getInt16(0);
                    if (binaryMessage.byteLength < headerLength + 2) {
                        throw new Error("Invalid binary message format. Header content missing.");
                    }
                    let headersString = "";
                    for (let i = 0; i < headerLength; i++) {
                        headersString += String.fromCharCode((dataView).getInt8(i + 2));
                    }
                    headers = this.parseHeaders(headersString);
                    if (binaryMessage.byteLength > headerLength + 2) {
                        body = binaryMessage.slice(2 + headerLength);
                    }
                    deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["ConnectionMessage"](message.messageType, body, headers, message.id));
                }
            }
            catch (e) {
                deferral.reject(`Error formatting the message. Error: ${e}`);
            }
            return deferral.promise;
        };
        this.fromConnectionMessage = (message) => {
            const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Deferred"]();
            try {
                if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
                    const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : ""}`;
                    deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["RawWebsocketMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text, payload, message.id));
                }
                else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary) {
                    const headersString = this.makeHeaders(message);
                    const content = message.binaryBody;
                    const headerBuffer = this.stringToArrayBuffer(headersString);
                    const headerInt8Array = new Int8Array(headerBuffer);
                    const headerLength = headerInt8Array.byteLength;
                    const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));
                    payloadInt8Array[0] = ((headerLength >> 8) & 0xff);
                    payloadInt8Array[1] = headerLength & 0xff;
                    payloadInt8Array.set(headerInt8Array, 2);
                    if (content) {
                        const bodyInt8Array = new Int8Array(content);
                        payloadInt8Array.set(bodyInt8Array, 2 + headerLength);
                    }
                    const payload = payloadInt8Array.buffer;
                    deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["RawWebsocketMessage"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary, payload, message.id));
                }
            }
            catch (e) {
                deferral.reject(`Error formatting the message. ${e}`);
            }
            return deferral.promise;
        };
        this.makeHeaders = (message) => {
            let headersString = "";
            if (message.headers) {
                for (const header in message.headers) {
                    if (header) {
                        headersString += `${header}: ${message.headers[header]}${CRLF}`;
                    }
                }
            }
            return headersString;
        };
        this.parseHeaders = (headersString) => {
            const headers = {};
            if (headersString) {
                const headerMatches = headersString.match(/[^\r\n]+/g);
                if (headers) {
                    for (const header of headerMatches) {
                        if (header) {
                            const separatorIndex = header.indexOf(":");
                            const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;
                            const headerValue = separatorIndex > 0 && header.length > (separatorIndex + 1) ?
                                header.substr(separatorIndex + 1).trim() :
                                "";
                            headers[headerName] = headerValue;
                        }
                    }
                }
            }
            return headers;
        };
        this.stringToArrayBuffer = (str) => {
            const buffer = new ArrayBuffer(str.length);
            const view = new DataView(buffer);
            for (let i = 0; i < str.length; i++) {
                view.setUint8(i, str.charCodeAt(i));
            }
            return buffer;
        };
    }
}

//# sourceMappingURL=WebsocketMessageFormatter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js ***!
  \************************************************************************************************************/
/*! exports provided: AudioSourceEvent, AudioSourceInitializingEvent, AudioSourceReadyEvent, AudioSourceOffEvent, AudioSourceErrorEvent, AudioStreamNodeEvent, AudioStreamNodeAttachingEvent, AudioStreamNodeAttachedEvent, AudioStreamNodeDetachedEvent, AudioStreamNodeErrorEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioSourceEvent", function() { return AudioSourceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioSourceInitializingEvent", function() { return AudioSourceInitializingEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioSourceReadyEvent", function() { return AudioSourceReadyEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioSourceOffEvent", function() { return AudioSourceOffEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioSourceErrorEvent", function() { return AudioSourceErrorEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeEvent", function() { return AudioStreamNodeEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeAttachingEvent", function() { return AudioStreamNodeAttachingEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeAttachedEvent", function() { return AudioStreamNodeAttachedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeDetachedEvent", function() { return AudioStreamNodeDetachedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeErrorEvent", function() { return AudioStreamNodeErrorEvent; });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file

class AudioSourceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, audioSourceId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
        this.privAudioSourceId = audioSourceId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
}
class AudioSourceInitializingEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceInitializingEvent", audioSourceId);
    }
}
class AudioSourceReadyEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceReadyEvent", audioSourceId);
    }
}
class AudioSourceOffEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceOffEvent", audioSourceId);
    }
}
class AudioSourceErrorEvent extends AudioSourceEvent {
    constructor(audioSourceId, error) {
        super("AudioSourceErrorEvent", audioSourceId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Error);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}
class AudioStreamNodeEvent extends AudioSourceEvent {
    constructor(eventName, audioSourceId, audioNodeId) {
        super(eventName, audioSourceId);
        this.privAudioNodeId = audioNodeId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
class AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeAttachingEvent", audioSourceId, audioNodeId);
    }
}
class AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeAttachedEvent", audioSourceId, audioNodeId);
    }
}
class AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeDetachedEvent", audioSourceId, audioNodeId);
    }
}
class AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId, error) {
        super("AudioStreamNodeErrorEvent", audioSourceId, audioNodeId);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}

//# sourceMappingURL=AudioSourceEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js ***!
  \**********************************************************************************************************/
/*! exports provided: BackgroundEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BackgroundEvent", function() { return BackgroundEvent; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class BackgroundEvent extends _Exports__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(error) {
        super("BackgroundEvent", _Exports__WEBPACK_IMPORTED_MODULE_0__["EventType"].Error);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}

//# sourceMappingURL=BackgroundError.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js ***!
  \*******************************************************************************************************************/
/*! exports provided: ChunkedArrayBufferStream */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ChunkedArrayBufferStream", function() { return ChunkedArrayBufferStream; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ChunkedArrayBufferStream extends _Exports__WEBPACK_IMPORTED_MODULE_0__["Stream"] {
    constructor(targetChunkSize, streamId) {
        super(streamId);
        this.privTargetChunkSize = targetChunkSize;
        this.privNextBufferReadyBytes = 0;
    }
    writeStreamChunk(chunk) {
        // No pending write, and the buffer is the right size so write it.
        if (chunk.isEnd ||
            (0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize)) {
            super.writeStreamChunk(chunk);
            return;
        }
        let bytesCopiedFromBuffer = 0;
        while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {
            // Fill the next buffer.
            if (undefined === this.privNextBufferToWrite) {
                this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);
                this.privNextBufferStartTime = chunk.timeReceived;
            }
            // Find out how many bytes we can copy into the read buffer.
            const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);
            const targetView = new Uint8Array(this.privNextBufferToWrite);
            const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));
            targetView.set(sourceView, this.privNextBufferReadyBytes);
            this.privNextBufferReadyBytes += bytesToCopy;
            bytesCopiedFromBuffer += bytesToCopy;
            // Are we ready to write?
            if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {
                super.writeStreamChunk({
                    buffer: this.privNextBufferToWrite,
                    isEnd: false,
                    timeReceived: this.privNextBufferStartTime,
                });
                this.privNextBufferReadyBytes = 0;
                this.privNextBufferToWrite = undefined;
            }
        }
    }
    close() {
        // Send whatever is pending, then close the base class.
        if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {
            super.writeStreamChunk({
                buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),
                isEnd: false,
                timeReceived: this.privNextBufferStartTime,
            });
        }
        super.close();
    }
}

//# sourceMappingURL=ChunkedArrayBufferStream.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js ***!
  \***********************************************************************************************************/
/*! exports provided: ServiceEvent, ConnectionEvent, ConnectionStartEvent, ConnectionEstablishedEvent, ConnectionClosedEvent, ConnectionErrorEvent, ConnectionEstablishErrorEvent, ConnectionMessageReceivedEvent, ConnectionMessageSentEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServiceEvent", function() { return ServiceEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionEvent", function() { return ConnectionEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionStartEvent", function() { return ConnectionStartEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionEstablishedEvent", function() { return ConnectionEstablishedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionClosedEvent", function() { return ConnectionClosedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionErrorEvent", function() { return ConnectionErrorEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionEstablishErrorEvent", function() { return ConnectionEstablishErrorEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageReceivedEvent", function() { return ConnectionMessageReceivedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageSentEvent", function() { return ConnectionMessageSentEvent; });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ServiceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, jsonstring, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
        this.privJsonResult = jsonstring;
    }
    get jsonString() {
        return this.privJsonResult;
    }
}
class ConnectionEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, connectionId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
        this.privConnectionId = connectionId;
    }
    get connectionId() {
        return this.privConnectionId;
    }
}
class ConnectionStartEvent extends ConnectionEvent {
    constructor(connectionId, uri, headers) {
        super("ConnectionStartEvent", connectionId);
        this.privUri = uri;
        this.privHeaders = headers;
    }
    get uri() {
        return this.privUri;
    }
    get headers() {
        return this.privHeaders;
    }
}
class ConnectionEstablishedEvent extends ConnectionEvent {
    constructor(connectionId, metadata) {
        super("ConnectionEstablishedEvent", connectionId);
    }
}
class ConnectionClosedEvent extends ConnectionEvent {
    constructor(connectionId, statusCode, reason) {
        super("ConnectionClosedEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug);
        this.privReason = reason;
        this.privStatusCode = statusCode;
    }
    get reason() {
        return this.privReason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
}
class ConnectionErrorEvent extends ConnectionEvent {
    constructor(connectionId, message, type) {
        super("ConnectionErrorEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug);
        this.privMessage = message;
        this.privType = type;
    }
    get message() {
        return this.privMessage;
    }
    get type() {
        return this.privType;
    }
}
class ConnectionEstablishErrorEvent extends ConnectionEvent {
    constructor(connectionId, statuscode, reason) {
        super("ConnectionEstablishErrorEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Error);
        this.privStatusCode = statuscode;
        this.privReason = reason;
    }
    get reason() {
        return this.privReason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
}
class ConnectionMessageReceivedEvent extends ConnectionEvent {
    constructor(connectionId, networkReceivedTimeISO, message) {
        super("ConnectionMessageReceivedEvent", connectionId);
        this.privNetworkReceivedTime = networkReceivedTimeISO;
        this.privMessage = message;
    }
    get networkReceivedTime() {
        return this.privNetworkReceivedTime;
    }
    get message() {
        return this.privMessage;
    }
}
class ConnectionMessageSentEvent extends ConnectionEvent {
    constructor(connectionId, networkSentTimeISO, message) {
        super("ConnectionMessageSentEvent", connectionId);
        this.privNetworkSentTime = networkSentTimeISO;
        this.privMessage = message;
    }
    get networkSentTime() {
        return this.privNetworkSentTime;
    }
    get message() {
        return this.privMessage;
    }
}

//# sourceMappingURL=ConnectionEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js ***!
  \************************************************************************************************************/
/*! exports provided: MessageType, ConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MessageType", function() { return MessageType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessage", function() { return ConnectionMessage; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


var MessageType;
(function (MessageType) {
    MessageType[MessageType["Text"] = 0] = "Text";
    MessageType[MessageType["Binary"] = 1] = "Binary";
})(MessageType || (MessageType = {}));
class ConnectionMessage {
    constructor(messageType, body, headers, id) {
        this.privBody = null;
        if (messageType === MessageType.Text && body && !(typeof (body) === "string")) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Payload must be a string");
        }
        if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Payload must be ArrayBuffer");
        }
        this.privMessageType = messageType;
        this.privBody = body;
        this.privHeaders = headers ? headers : {};
        this.privId = id ? id : Object(_Guid__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
        switch (this.messageType) {
            case MessageType.Binary:
                this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;
                break;
            case MessageType.Text:
                this.privSize = this.textBody.length;
        }
    }
    get messageType() {
        return this.privMessageType;
    }
    get headers() {
        return this.privHeaders;
    }
    get body() {
        return this.privBody;
    }
    get textBody() {
        if (this.privMessageType === MessageType.Binary) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Not supported for binary message");
        }
        return this.privBody;
    }
    get binaryBody() {
        if (this.privMessageType === MessageType.Text) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Not supported for text message");
        }
        return this.privBody;
    }
    get id() {
        return this.privId;
    }
}

//# sourceMappingURL=ConnectionMessage.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js ***!
  \*****************************************************************************************************************/
/*! exports provided: ConnectionOpenResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionOpenResponse", function() { return ConnectionOpenResponse; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ConnectionOpenResponse {
    constructor(statusCode, reason) {
        this.privStatusCode = statusCode;
        this.privReason = reason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
    get reason() {
        return this.privReason;
    }
}

//# sourceMappingURL=ConnectionOpenResponse.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js ***!
  \*******************************************************************************************************/
/*! exports provided: DialogEvent, SendingAgentContextMessageEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogEvent", function() { return DialogEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SendingAgentContextMessageEvent", function() { return SendingAgentContextMessageEvent; });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class DialogEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Info) {
        super(eventName, eventType);
    }
}
class SendingAgentContextMessageEvent extends DialogEvent {
    constructor(agentConfig) {
        super("SendingAgentContextMessageEvent");
        this.privAgentConfig = agentConfig;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
}

//# sourceMappingURL=DialogEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js ***!
  \************************************************************************************************/
/*! exports provided: ArgumentNullError, InvalidOperationError, ObjectDisposedError */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ArgumentNullError", function() { return ArgumentNullError; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "InvalidOperationError", function() { return InvalidOperationError; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ObjectDisposedError", function() { return ObjectDisposedError; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file
/**
 * The error that is thrown when an argument passed in is null.
 *
 * @export
 * @class ArgumentNullError
 * @extends {Error}
 */
class ArgumentNullError extends Error {
    /**
     * Creates an instance of ArgumentNullError.
     *
     * @param {string} argumentName - Name of the argument that is null
     *
     * @memberOf ArgumentNullError
     */
    constructor(argumentName) {
        super(argumentName);
        this.name = "ArgumentNull";
        this.message = argumentName;
    }
}
/**
 * The error that is thrown when an invalid operation is performed in the code.
 *
 * @export
 * @class InvalidOperationError
 * @extends {Error}
 */
class InvalidOperationError extends Error {
    /**
     * Creates an instance of InvalidOperationError.
     *
     * @param {string} error - The error
     *
     * @memberOf InvalidOperationError
     */
    constructor(error) {
        super(error);
        this.name = "InvalidOperation";
        this.message = error;
    }
}
/**
 * The error that is thrown when an object is disposed.
 *
 * @export
 * @class ObjectDisposedError
 * @extends {Error}
 */
// tslint:disable-next-line:max-classes-per-file
class ObjectDisposedError extends Error {
    /**
     * Creates an instance of ObjectDisposedError.
     *
     * @param {string} objectName - The object that is disposed
     * @param {string} error - The error
     *
     * @memberOf ObjectDisposedError
     */
    constructor(objectName, error) {
        super(error);
        this.name = objectName + "ObjectDisposed";
        this.message = error;
    }
}

//# sourceMappingURL=Error.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js ***!
  \******************************************************************************************************/
/*! exports provided: EventSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "EventSource", function() { return EventSource; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class EventSource {
    constructor(metadata) {
        this.privEventListeners = {};
        this.privIsDisposed = false;
        this.onEvent = (event) => {
            if (this.isDisposed()) {
                throw (new _Error__WEBPACK_IMPORTED_MODULE_0__["ObjectDisposedError"]("EventSource"));
            }
            if (this.metadata) {
                for (const paramName in this.metadata) {
                    if (paramName) {
                        if (event.metadata) {
                            if (!event.metadata[paramName]) {
                                event.metadata[paramName] = this.metadata[paramName];
                            }
                        }
                    }
                }
            }
            for (const eventId in this.privEventListeners) {
                if (eventId && this.privEventListeners[eventId]) {
                    this.privEventListeners[eventId](event);
                }
            }
        };
        this.attach = (onEventCallback) => {
            const id = Object(_Guid__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
            this.privEventListeners[id] = onEventCallback;
            return {
                detach: () => {
                    delete this.privEventListeners[id];
                    return Promise.resolve();
                },
            };
        };
        this.attachListener = (listener) => {
            return this.attach(listener.onEvent);
        };
        this.isDisposed = () => {
            return this.privIsDisposed;
        };
        this.dispose = () => {
            this.privEventListeners = null;
            this.privIsDisposed = true;
        };
        this.privMetadata = metadata;
    }
    get metadata() {
        return this.privMetadata;
    }
}

//# sourceMappingURL=EventSource.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js ***!
  \*************************************************************************************************/
/*! exports provided: Events */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Events", function() { return Events; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./EventSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class Events {
    static get instance() {
        return Events.privInstance;
    }
}
Events.privInstance = new _EventSource__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
Events.setEventSource = (eventSource) => {
    if (!eventSource) {
        throw new _Error__WEBPACK_IMPORTED_MODULE_0__["ArgumentNullError"]("eventSource");
    }
    Events.privInstance = eventSource;
};

//# sourceMappingURL=Events.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioSourceEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioSourceEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioSourceEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioSourceInitializingEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioSourceInitializingEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioSourceReadyEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioSourceReadyEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioSourceOffEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioSourceOffEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioSourceErrorEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioSourceErrorEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeAttachingEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeAttachingEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeAttachedEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeAttachedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeDetachedEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeDetachedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamNodeErrorEvent", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__["AudioStreamNodeErrorEvent"]; });

/* harmony import */ var _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServiceEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ServiceEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionStartEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionStartEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionEstablishedEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionEstablishedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionClosedEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionClosedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionErrorEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionErrorEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionEstablishErrorEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionEstablishErrorEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageReceivedEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionMessageReceivedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageSentEvent", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__["ConnectionMessageSentEvent"]; });

/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MessageType", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__["MessageType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessage", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__["ConnectionMessage"]; });

/* harmony import */ var _ConnectionOpenResponse__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionOpenResponse */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionOpenResponse", function() { return _ConnectionOpenResponse__WEBPACK_IMPORTED_MODULE_3__["ConnectionOpenResponse"]; });

/* harmony import */ var _DialogEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./DialogEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogEvent", function() { return _DialogEvents__WEBPACK_IMPORTED_MODULE_4__["DialogEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SendingAgentContextMessageEvent", function() { return _DialogEvents__WEBPACK_IMPORTED_MODULE_4__["SendingAgentContextMessageEvent"]; });

/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ArgumentNullError", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__["ArgumentNullError"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "InvalidOperationError", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__["InvalidOperationError"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ObjectDisposedError", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__["ObjectDisposedError"]; });

/* harmony import */ var _Events__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Events */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Events", function() { return _Events__WEBPACK_IMPORTED_MODULE_6__["Events"]; });

/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./EventSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "EventSource", function() { return _EventSource__WEBPACK_IMPORTED_MODULE_7__["EventSource"]; });

/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "createGuid", function() { return _Guid__WEBPACK_IMPORTED_MODULE_8__["createGuid"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "createNoDashGuid", function() { return _Guid__WEBPACK_IMPORTED_MODULE_8__["createNoDashGuid"]; });

/* harmony import */ var _IAudioSource__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./IAudioSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js");
/* harmony import */ var _IAudioSource__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_IAudioSource__WEBPACK_IMPORTED_MODULE_9__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IAudioSource__WEBPACK_IMPORTED_MODULE_9__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IAudioSource__WEBPACK_IMPORTED_MODULE_9__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IConnection__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./IConnection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionState", function() { return _IConnection__WEBPACK_IMPORTED_MODULE_10__["ConnectionState"]; });

/* harmony import */ var _IDetachable__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IDetachable */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js");
/* harmony import */ var _IDetachable__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_IDetachable__WEBPACK_IMPORTED_MODULE_11__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDetachable__WEBPACK_IMPORTED_MODULE_11__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDetachable__WEBPACK_IMPORTED_MODULE_11__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IDictionary__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./IDictionary */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js");
/* harmony import */ var _IDictionary__WEBPACK_IMPORTED_MODULE_12___default = /*#__PURE__*/__webpack_require__.n(_IDictionary__WEBPACK_IMPORTED_MODULE_12__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDictionary__WEBPACK_IMPORTED_MODULE_12__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDictionary__WEBPACK_IMPORTED_MODULE_12__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IDisposable__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./IDisposable */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js");
/* harmony import */ var _IDisposable__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_IDisposable__WEBPACK_IMPORTED_MODULE_13__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDisposable__WEBPACK_IMPORTED_MODULE_13__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDisposable__WEBPACK_IMPORTED_MODULE_13__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IEventSource__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IEventSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js");
/* harmony import */ var _IEventSource__WEBPACK_IMPORTED_MODULE_14___default = /*#__PURE__*/__webpack_require__.n(_IEventSource__WEBPACK_IMPORTED_MODULE_14__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IEventSource__WEBPACK_IMPORTED_MODULE_14__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IEventSource__WEBPACK_IMPORTED_MODULE_14__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./IErrorMessages */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js");
/* harmony import */ var _IErrorMessages__WEBPACK_IMPORTED_MODULE_15___default = /*#__PURE__*/__webpack_require__.n(_IErrorMessages__WEBPACK_IMPORTED_MODULE_15__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _ITimer__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./ITimer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js");
/* harmony import */ var _ITimer__WEBPACK_IMPORTED_MODULE_16___default = /*#__PURE__*/__webpack_require__.n(_ITimer__WEBPACK_IMPORTED_MODULE_16__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _ITimer__WEBPACK_IMPORTED_MODULE_16__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _ITimer__WEBPACK_IMPORTED_MODULE_16__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./IWebsocketMessageFormatter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js");
/* harmony import */ var _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17___default = /*#__PURE__*/__webpack_require__.n(_IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./List */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "List", function() { return _List__WEBPACK_IMPORTED_MODULE_18__["List"]; });

/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "EventType", function() { return _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__["EventType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PlatformEvent", function() { return _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__["PlatformEvent"]; });

/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./Promise */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PromiseState", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["PromiseState"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PromiseResult", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["PromiseResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PromiseResultEventSource", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["PromiseResultEventSource"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Deferred", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["Deferred"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Sink", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["Sink"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "marshalPromiseToCallbacks", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__["marshalPromiseToCallbacks"]; });

/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./Queue */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Queue", function() { return _Queue__WEBPACK_IMPORTED_MODULE_21__["Queue"]; });

/* harmony import */ var _RawWebsocketMessage__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./RawWebsocketMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RawWebsocketMessage", function() { return _RawWebsocketMessage__WEBPACK_IMPORTED_MODULE_22__["RawWebsocketMessage"]; });

/* harmony import */ var _RiffPcmEncoder__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./RiffPcmEncoder */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RiffPcmEncoder", function() { return _RiffPcmEncoder__WEBPACK_IMPORTED_MODULE_23__["RiffPcmEncoder"]; });

/* harmony import */ var _Stream__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./Stream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Stream", function() { return _Stream__WEBPACK_IMPORTED_MODULE_24__["Stream"]; });

/* harmony import */ var _common_speech_TranslationStatus__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../common.speech/TranslationStatus */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationStatus", function() { return _common_speech_TranslationStatus__WEBPACK_IMPORTED_MODULE_25__["TranslationStatus"]; });

/* harmony import */ var _ChunkedArrayBufferStream__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./ChunkedArrayBufferStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ChunkedArrayBufferStream", function() { return _ChunkedArrayBufferStream__WEBPACK_IMPORTED_MODULE_26__["ChunkedArrayBufferStream"]; });

/* harmony import */ var _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./IAudioDestination */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js");
/* harmony import */ var _IAudioDestination__WEBPACK_IMPORTED_MODULE_27___default = /*#__PURE__*/__webpack_require__.n(_IAudioDestination__WEBPACK_IMPORTED_MODULE_27__);
/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__) if(["default","TranslationStatus","AudioSourceEvent","AudioSourceInitializingEvent","AudioSourceReadyEvent","AudioSourceOffEvent","AudioSourceErrorEvent","AudioStreamNodeEvent","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeDetachedEvent","AudioStreamNodeErrorEvent","ServiceEvent","ConnectionEvent","ConnectionStartEvent","ConnectionEstablishedEvent","ConnectionClosedEvent","ConnectionErrorEvent","ConnectionEstablishErrorEvent","ConnectionMessageReceivedEvent","ConnectionMessageSentEvent","MessageType","ConnectionMessage","ConnectionOpenResponse","DialogEvent","SendingAgentContextMessageEvent","ArgumentNullError","InvalidOperationError","ObjectDisposedError","Events","EventSource","createGuid","createNoDashGuid","ConnectionState","List","EventType","PlatformEvent","PromiseState","PromiseResult","PromiseResultEventSource","Deferred","Sink","marshalPromiseToCallbacks","Queue","RawWebsocketMessage","RiffPcmEncoder","Stream","ChunkedArrayBufferStream"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__[key]; }) }(__WEBPACK_IMPORT_KEY__));
/* harmony import */ var _Timeout__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./Timeout */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Timeout", function() { return _Timeout__WEBPACK_IMPORTED_MODULE_28__["Timeout"]; });

/* harmony import */ var _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./OCSPEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPMemoryCacheHitEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPMemoryCacheHitEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheMissEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheMissEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPDiskCacheHitEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPDiskCacheHitEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdateNeededEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheUpdateNeededEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPMemoryCacheStoreEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPMemoryCacheStoreEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPDiskCacheStoreEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPDiskCacheStoreEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdatehCompleteEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheUpdatehCompleteEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPStapleReceivedEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPStapleReceivedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPWSUpgradeStartedEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPWSUpgradeStartedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheEntryExpiredEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheEntryExpiredEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheEntryNeedsRefreshEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheEntryNeedsRefreshEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheHitEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheHitEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPVerificationFailedEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPVerificationFailedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheFetchErrorEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheFetchErrorEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPResponseRetrievedEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPResponseRetrievedEvent"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdateErrorEvent", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__["OCSPCacheUpdateErrorEvent"]; });

/* harmony import */ var _BackgroundError__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./BackgroundError */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BackgroundEvent", function() { return _BackgroundError__WEBPACK_IMPORTED_MODULE_30__["BackgroundEvent"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
































//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js ***!
  \***********************************************************************************************/
/*! exports provided: createGuid, createNoDashGuid */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createGuid", function() { return createGuid; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "createNoDashGuid", function() { return createNoDashGuid; });
/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/index.js");
/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(uuid__WEBPACK_IMPORTED_MODULE_0__);
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

const createGuid = () => {
    return Object(uuid__WEBPACK_IMPORTED_MODULE_0__["v4"])();
};
const createNoDashGuid = () => {
    return createGuid().replace(new RegExp("-", "g"), "").toUpperCase();
};


//# sourceMappingURL=Guid.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js ***!
  \************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IAudioDestination.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js ***!
  \*******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IAudioSource.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js ***!
  \******************************************************************************************************/
/*! exports provided: ConnectionState */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionState", function() { return ConnectionState; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var ConnectionState;
(function (ConnectionState) {
    ConnectionState[ConnectionState["None"] = 0] = "None";
    ConnectionState[ConnectionState["Connected"] = 1] = "Connected";
    ConnectionState[ConnectionState["Connecting"] = 2] = "Connecting";
    ConnectionState[ConnectionState["Disconnected"] = 3] = "Disconnected";
})(ConnectionState || (ConnectionState = {}));

//# sourceMappingURL=IConnection.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IDetachable.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IDictionary.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IDisposable.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js ***!
  \*********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {



//# sourceMappingURL=IErrorMessages.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js ***!
  \*******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IEventSource.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js ***!
  \*************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=ITimer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js ***!
  \*********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

//# sourceMappingURL=IWebsocketMessageFormatter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js ***!
  \***********************************************************************************************/
/*! exports provided: List */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "List", function() { return List; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class List {
    constructor(list) {
        this.privSubscriptionIdCounter = 0;
        this.privAddSubscriptions = {};
        this.privRemoveSubscriptions = {};
        this.privDisposedSubscriptions = {};
        this.privDisposeReason = null;
        this.get = (itemIndex) => {
            this.throwIfDisposed();
            return this.privList[itemIndex];
        };
        this.first = () => {
            return this.get(0);
        };
        this.last = () => {
            return this.get(this.length() - 1);
        };
        this.add = (item) => {
            this.throwIfDisposed();
            this.insertAt(this.privList.length, item);
        };
        this.insertAt = (index, item) => {
            this.throwIfDisposed();
            if (index === 0) {
                this.privList.unshift(item);
            }
            else if (index === this.privList.length) {
                this.privList.push(item);
            }
            else {
                this.privList.splice(index, 0, item);
            }
            this.triggerSubscriptions(this.privAddSubscriptions);
        };
        this.removeFirst = () => {
            this.throwIfDisposed();
            return this.removeAt(0);
        };
        this.removeLast = () => {
            this.throwIfDisposed();
            return this.removeAt(this.length() - 1);
        };
        this.removeAt = (index) => {
            this.throwIfDisposed();
            return this.remove(index, 1)[0];
        };
        this.remove = (index, count) => {
            this.throwIfDisposed();
            const removedElements = this.privList.splice(index, count);
            this.triggerSubscriptions(this.privRemoveSubscriptions);
            return removedElements;
        };
        this.clear = () => {
            this.throwIfDisposed();
            this.remove(0, this.length());
        };
        this.length = () => {
            this.throwIfDisposed();
            return this.privList.length;
        };
        this.onAdded = (addedCallback) => {
            this.throwIfDisposed();
            const subscriptionId = this.privSubscriptionIdCounter++;
            this.privAddSubscriptions[subscriptionId] = addedCallback;
            return {
                detach: () => {
                    delete this.privAddSubscriptions[subscriptionId];
                    return Promise.resolve();
                },
            };
        };
        this.onRemoved = (removedCallback) => {
            this.throwIfDisposed();
            const subscriptionId = this.privSubscriptionIdCounter++;
            this.privRemoveSubscriptions[subscriptionId] = removedCallback;
            return {
                detach: () => {
                    delete this.privRemoveSubscriptions[subscriptionId];
                    return Promise.resolve();
                },
            };
        };
        this.onDisposed = (disposedCallback) => {
            this.throwIfDisposed();
            const subscriptionId = this.privSubscriptionIdCounter++;
            this.privDisposedSubscriptions[subscriptionId] = disposedCallback;
            return {
                detach: () => {
                    delete this.privDisposedSubscriptions[subscriptionId];
                    return Promise.resolve();
                },
            };
        };
        this.join = (seperator) => {
            this.throwIfDisposed();
            return this.privList.join(seperator);
        };
        this.toArray = () => {
            const cloneCopy = Array();
            this.privList.forEach((val) => {
                cloneCopy.push(val);
            });
            return cloneCopy;
        };
        this.any = (callback) => {
            this.throwIfDisposed();
            if (callback) {
                return this.where(callback).length() > 0;
            }
            else {
                return this.length() > 0;
            }
        };
        this.all = (callback) => {
            this.throwIfDisposed();
            return this.where(callback).length() === this.length();
        };
        this.forEach = (callback) => {
            this.throwIfDisposed();
            for (let i = 0; i < this.length(); i++) {
                callback(this.privList[i], i);
            }
        };
        this.select = (callback) => {
            this.throwIfDisposed();
            const selectList = [];
            for (let i = 0; i < this.privList.length; i++) {
                selectList.push(callback(this.privList[i], i));
            }
            return new List(selectList);
        };
        this.where = (callback) => {
            this.throwIfDisposed();
            const filteredList = new List();
            for (let i = 0; i < this.privList.length; i++) {
                if (callback(this.privList[i], i)) {
                    filteredList.add(this.privList[i]);
                }
            }
            return filteredList;
        };
        this.orderBy = (compareFn) => {
            this.throwIfDisposed();
            const clonedArray = this.toArray();
            const orderedArray = clonedArray.sort(compareFn);
            return new List(orderedArray);
        };
        this.orderByDesc = (compareFn) => {
            this.throwIfDisposed();
            return this.orderBy((a, b) => compareFn(b, a));
        };
        this.clone = () => {
            this.throwIfDisposed();
            return new List(this.toArray());
        };
        this.concat = (list) => {
            this.throwIfDisposed();
            return new List(this.privList.concat(list.toArray()));
        };
        this.concatArray = (array) => {
            this.throwIfDisposed();
            return new List(this.privList.concat(array));
        };
        this.isDisposed = () => {
            return this.privList == null;
        };
        this.dispose = (reason) => {
            if (!this.isDisposed()) {
                this.privDisposeReason = reason;
                this.privList = null;
                this.privAddSubscriptions = null;
                this.privRemoveSubscriptions = null;
                this.triggerSubscriptions(this.privDisposedSubscriptions);
            }
        };
        this.throwIfDisposed = () => {
            if (this.isDisposed()) {
                throw new _Error__WEBPACK_IMPORTED_MODULE_0__["ObjectDisposedError"]("List", this.privDisposeReason);
            }
        };
        this.triggerSubscriptions = (subscriptions) => {
            if (subscriptions) {
                for (const subscriptionId in subscriptions) {
                    if (subscriptionId) {
                        subscriptions[subscriptionId]();
                    }
                }
            }
        };
        this.privList = [];
        // copy the list rather than taking as is.
        if (list) {
            for (const item of list) {
                this.privList.push(item);
            }
        }
    }
}

//# sourceMappingURL=List.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js ***!
  \*****************************************************************************************************/
/*! exports provided: OCSPEvent, OCSPMemoryCacheHitEvent, OCSPCacheMissEvent, OCSPDiskCacheHitEvent, OCSPCacheUpdateNeededEvent, OCSPMemoryCacheStoreEvent, OCSPDiskCacheStoreEvent, OCSPCacheUpdatehCompleteEvent, OCSPStapleReceivedEvent, OCSPWSUpgradeStartedEvent, OCSPCacheEntryExpiredEvent, OCSPCacheEntryNeedsRefreshEvent, OCSPCacheHitEvent, OCSPVerificationFailedEvent, OCSPCacheFetchErrorEvent, OCSPResponseRetrievedEvent, OCSPCacheUpdateErrorEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPEvent", function() { return OCSPEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPMemoryCacheHitEvent", function() { return OCSPMemoryCacheHitEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheMissEvent", function() { return OCSPCacheMissEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPDiskCacheHitEvent", function() { return OCSPDiskCacheHitEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdateNeededEvent", function() { return OCSPCacheUpdateNeededEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPMemoryCacheStoreEvent", function() { return OCSPMemoryCacheStoreEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPDiskCacheStoreEvent", function() { return OCSPDiskCacheStoreEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdatehCompleteEvent", function() { return OCSPCacheUpdatehCompleteEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPStapleReceivedEvent", function() { return OCSPStapleReceivedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPWSUpgradeStartedEvent", function() { return OCSPWSUpgradeStartedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheEntryExpiredEvent", function() { return OCSPCacheEntryExpiredEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheEntryNeedsRefreshEvent", function() { return OCSPCacheEntryNeedsRefreshEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheHitEvent", function() { return OCSPCacheHitEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPVerificationFailedEvent", function() { return OCSPVerificationFailedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheFetchErrorEvent", function() { return OCSPCacheFetchErrorEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPResponseRetrievedEvent", function() { return OCSPResponseRetrievedEvent; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OCSPCacheUpdateErrorEvent", function() { return OCSPCacheUpdateErrorEvent; });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// tslint:disable:max-classes-per-file

class OCSPEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["PlatformEvent"] {
    constructor(eventName, eventType, signature) {
        super(eventName, eventType);
        this.privSignature = signature;
    }
}
class OCSPMemoryCacheHitEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPMemoryCacheHitEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPCacheMissEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheMissEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPDiskCacheHitEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPDiskCacheHitEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPCacheUpdateNeededEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheUpdateNeededEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPMemoryCacheStoreEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPMemoryCacheStoreEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPDiskCacheStoreEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPDiskCacheStoreEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPCacheUpdatehCompleteEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheUpdatehCompleteEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, signature);
    }
}
class OCSPStapleReceivedEvent extends OCSPEvent {
    constructor() {
        super("OCSPStapleReceivedEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, "");
    }
}
class OCSPWSUpgradeStartedEvent extends OCSPEvent {
    constructor(serialNumber) {
        super("OCSPWSUpgradeStartedEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
    }
}
class OCSPCacheEntryExpiredEvent extends OCSPEvent {
    constructor(serialNumber, expireTime) {
        super("OCSPCacheEntryExpiredEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privExpireTime = expireTime;
    }
}
class OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {
    constructor(serialNumber, startTime, expireTime) {
        super("OCSPCacheEntryNeedsRefreshEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privExpireTime = expireTime;
        this.privStartTime = startTime;
    }
}
class OCSPCacheHitEvent extends OCSPEvent {
    constructor(serialNumber, startTime, expireTime) {
        super("OCSPCacheHitEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privExpireTime = expireTime;
        this.privExpireTimeString = new Date(expireTime).toLocaleDateString();
        this.privStartTime = startTime;
        this.privStartTimeString = new Date(startTime).toLocaleTimeString();
    }
}
class OCSPVerificationFailedEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPVerificationFailedEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privError = error;
    }
}
class OCSPCacheFetchErrorEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPCacheFetchErrorEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privError = error;
    }
}
class OCSPResponseRetrievedEvent extends OCSPEvent {
    constructor(serialNumber) {
        super("OCSPResponseRetrievedEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
    }
}
class OCSPCacheUpdateErrorEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPCacheUpdateErrorEvent", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__["EventType"].Debug, serialNumber);
        this.privError = error;
    }
}

//# sourceMappingURL=OCSPEvents.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js ***!
  \********************************************************************************************************/
/*! exports provided: EventType, PlatformEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "EventType", function() { return EventType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PlatformEvent", function() { return PlatformEvent; });
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

var EventType;
(function (EventType) {
    EventType[EventType["Debug"] = 0] = "Debug";
    EventType[EventType["Info"] = 1] = "Info";
    EventType[EventType["Warning"] = 2] = "Warning";
    EventType[EventType["Error"] = 3] = "Error";
})(EventType || (EventType = {}));
class PlatformEvent {
    constructor(eventName, eventType) {
        this.privName = eventName;
        this.privEventId = Object(_Guid__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privEventTime = new Date().toISOString();
        this.privEventType = eventType;
        this.privMetadata = {};
    }
    get name() {
        return this.privName;
    }
    get eventId() {
        return this.privEventId;
    }
    get eventTime() {
        return this.privEventTime;
    }
    get eventType() {
        return this.privEventType;
    }
    get metadata() {
        return this.privMetadata;
    }
}

//# sourceMappingURL=PlatformEvent.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js ***!
  \**************************************************************************************************/
/*! exports provided: PromiseState, PromiseResult, PromiseResultEventSource, Deferred, Sink, marshalPromiseToCallbacks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PromiseState", function() { return PromiseState; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PromiseResult", function() { return PromiseResult; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PromiseResultEventSource", function() { return PromiseResultEventSource; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Deferred", function() { return Deferred; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Sink", function() { return Sink; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "marshalPromiseToCallbacks", function() { return marshalPromiseToCallbacks; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var PromiseState;
(function (PromiseState) {
    PromiseState[PromiseState["None"] = 0] = "None";
    PromiseState[PromiseState["Resolved"] = 1] = "Resolved";
    PromiseState[PromiseState["Rejected"] = 2] = "Rejected";
})(PromiseState || (PromiseState = {}));
class PromiseResult {
    constructor(promiseResultEventSource) {
        this.throwIfError = () => {
            if (this.isError) {
                throw this.error;
            }
        };
        promiseResultEventSource.on((result) => {
            if (!this.privIsCompleted) {
                this.privIsCompleted = true;
                this.privIsError = false;
                this.privResult = result;
            }
        }, (error) => {
            if (!this.privIsCompleted) {
                this.privIsCompleted = true;
                this.privIsError = true;
                this.privError = error;
            }
        });
    }
    get isCompleted() {
        return this.privIsCompleted;
    }
    get isError() {
        return this.privIsError;
    }
    get error() {
        return this.privError;
    }
    get result() {
        return this.privResult;
    }
}
class PromiseResultEventSource {
    constructor() {
        this.setResult = (result) => {
            this.privOnSetResult(result);
        };
        this.setError = (error) => {
            this.privOnSetError(error);
        };
        this.on = (onSetResult, onSetError) => {
            this.privOnSetResult = onSetResult;
            this.privOnSetError = onSetError;
        };
    }
}
class Deferred {
    constructor() {
        this.resolve = (result) => {
            this.privResolve(result);
            return this;
        };
        this.reject = (error) => {
            this.privReject(error);
            return this;
        };
        this.privPromise = new Promise((resolve, reject) => {
            this.privResolve = resolve;
            this.privReject = reject;
        });
    }
    get promise() {
        return this.privPromise;
    }
}
class Sink {
    constructor() {
        this.privState = PromiseState.None;
        this.privPromiseResult = null;
        this.privPromiseResultEvents = null;
        this.privSuccessHandlers = [];
        this.privErrorHandlers = [];
        this.resolve = (result) => {
            if (this.privState !== PromiseState.None) {
                throw new Error("'Cannot resolve a completed promise'");
            }
            this.privState = PromiseState.Resolved;
            this.privPromiseResultEvents.setResult(result);
            for (let i = 0; i < this.privSuccessHandlers.length; i++) {
                this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);
            }
            this.detachHandlers();
        };
        this.reject = (error) => {
            if (this.privState !== PromiseState.None) {
                throw new Error("'Cannot reject a completed promise'");
            }
            this.privState = PromiseState.Rejected;
            this.privPromiseResultEvents.setError(error);
            for (const errorHandler of this.privErrorHandlers) {
                this.executeErrorCallback(error, errorHandler);
            }
            this.detachHandlers();
        };
        this.on = (successCallback, errorCallback) => {
            if (successCallback == null) {
                successCallback = (r) => { return; };
            }
            if (this.privState === PromiseState.None) {
                this.privSuccessHandlers.push(successCallback);
                this.privErrorHandlers.push(errorCallback);
            }
            else {
                if (this.privState === PromiseState.Resolved) {
                    this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);
                }
                else if (this.privState === PromiseState.Rejected) {
                    this.executeErrorCallback(this.privPromiseResult.error, errorCallback);
                }
                this.detachHandlers();
            }
        };
        this.executeSuccessCallback = (result, successCallback, errorCallback) => {
            try {
                successCallback(result);
            }
            catch (e) {
                this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);
            }
        };
        this.executeErrorCallback = (error, errorCallback) => {
            if (errorCallback) {
                try {
                    errorCallback(error);
                }
                catch (e) {
                    throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);
                }
            }
            else {
                throw new Error(`'Unhandled error: ${error}'`);
            }
        };
        this.detachHandlers = () => {
            this.privErrorHandlers = [];
            this.privSuccessHandlers = [];
        };
        this.privPromiseResultEvents = new PromiseResultEventSource();
        this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);
    }
    get state() {
        return this.privState;
    }
    get result() {
        return this.privPromiseResult;
    }
}
function marshalPromiseToCallbacks(promise, cb, err) {
    promise.then((val) => {
        try {
            if (!!cb) {
                cb(val);
            }
        }
        catch (error) {
            if (!!err) {
                try {
                    if (error instanceof Error) {
                        const typedError = error;
                        err(typedError.name + ": " + typedError.message);
                    }
                    else {
                        err(error);
                    }
                    /* tslint:disable:no-empty */
                }
                catch (error) { }
            }
        }
    }, (error) => {
        if (!!err) {
            try {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
                /* tslint:disable:no-empty */
            }
            catch (error) { }
        }
    });
}

//# sourceMappingURL=Promise.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js ***!
  \************************************************************************************************/
/*! exports provided: Queue */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Queue", function() { return Queue; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./List */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js");
/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Promise */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



var SubscriberType;
(function (SubscriberType) {
    SubscriberType[SubscriberType["Dequeue"] = 0] = "Dequeue";
    SubscriberType[SubscriberType["Peek"] = 1] = "Peek";
})(SubscriberType || (SubscriberType = {}));
class Queue {
    constructor(list) {
        this.privPromiseStore = new _List__WEBPACK_IMPORTED_MODULE_1__["List"]();
        this.privIsDrainInProgress = false;
        this.privIsDisposing = false;
        this.privDisposeReason = null;
        this.enqueue = (item) => {
            this.throwIfDispose();
            this.enqueueFromPromise(new Promise((resolve, reject) => { resolve(item); }));
        };
        this.enqueueFromPromise = (promise) => {
            this.throwIfDispose();
            promise.then((val) => {
                this.privList.add(val);
                /* tslint:disable:no-empty */
            }, (error) => { });
        };
        this.dequeue = () => {
            this.throwIfDispose();
            const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_2__["Deferred"]();
            if (this.privSubscribers) {
                this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });
                this.drain();
            }
            return deferredSubscriber.promise;
        };
        this.peek = () => {
            this.throwIfDispose();
            const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_2__["Deferred"]();
            const subs = this.privSubscribers;
            if (subs) {
                this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });
                this.drain();
            }
            return deferredSubscriber.promise;
        };
        this.length = () => {
            this.throwIfDispose();
            return this.privList.length();
        };
        this.isDisposed = () => {
            return this.privSubscribers == null;
        };
        this.drain = () => {
            if (!this.privIsDrainInProgress && !this.privIsDisposing) {
                this.privIsDrainInProgress = true;
                const subs = this.privSubscribers;
                const lists = this.privList;
                if (subs && lists) {
                    while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {
                        const subscriber = subs.removeFirst();
                        if (subscriber.type === SubscriberType.Peek) {
                            subscriber.deferral.resolve(lists.first());
                        }
                        else {
                            const dequeuedItem = lists.removeFirst();
                            subscriber.deferral.resolve(dequeuedItem);
                        }
                    }
                    // note: this block assumes cooperative multitasking, i.e.,
                    // between the if-statement and the assignment there are no
                    // thread switches.
                    // Reason is that between the initial const = this.; and this
                    // point there is the derral.resolve() operation that might have
                    // caused recursive calls to the Queue, especially, calling
                    // Dispose() on the queue alredy (which would reset the var
                    // here to null!).
                    // That should generally hold true for javascript...
                    if (this.privSubscribers === subs) {
                        this.privSubscribers = subs;
                    }
                    // note: this block assumes cooperative multitasking, i.e.,
                    // between the if-statement and the assignment there are no
                    // thread switches.
                    // Reason is that between the initial const = this.; and this
                    // point there is the derral.resolve() operation that might have
                    // caused recursive calls to the Queue, especially, calling
                    // Dispose() on the queue alredy (which would reset the var
                    // here to null!).
                    // That should generally hold true for javascript...
                    if (this.privList === lists) {
                        this.privList = lists;
                    }
                }
                this.privIsDrainInProgress = false;
            }
        };
        this.throwIfDispose = () => {
            if (this.isDisposed()) {
                if (this.privDisposeReason) {
                    throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"](this.privDisposeReason);
                }
                throw new _Error__WEBPACK_IMPORTED_MODULE_0__["ObjectDisposedError"]("Queue");
            }
            else if (this.privIsDisposing) {
                throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Queue disposing");
            }
        };
        this.privList = list ? list : new _List__WEBPACK_IMPORTED_MODULE_1__["List"]();
        this.privDetachables = [];
        this.privSubscribers = new _List__WEBPACK_IMPORTED_MODULE_1__["List"]();
        this.privDetachables.push(this.privList.onAdded(this.drain));
    }
    drainAndDispose(pendingItemProcessor, reason) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.isDisposed() && !this.privIsDisposing) {
                this.privDisposeReason = reason;
                this.privIsDisposing = true;
                const subs = this.privSubscribers;
                if (subs) {
                    while (subs.length() > 0) {
                        const subscriber = subs.removeFirst();
                        // TODO: this needs work (Resolve(null) instead?).
                        subscriber.deferral.resolve(undefined);
                        // subscriber.deferral.reject("Disposed");
                    }
                    // note: this block assumes cooperative multitasking, i.e.,
                    // between the if-statement and the assignment there are no
                    // thread switches.
                    // Reason is that between the initial const = this.; and this
                    // point there is the derral.resolve() operation that might have
                    // caused recursive calls to the Queue, especially, calling
                    // Dispose() on the queue alredy (which would reset the var
                    // here to null!).
                    // That should generally hold true for javascript...
                    if (this.privSubscribers === subs) {
                        this.privSubscribers = subs;
                    }
                }
                for (const detachable of this.privDetachables) {
                    yield detachable.detach();
                }
                if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {
                    const promiseArray = [];
                    this.privPromiseStore.toArray().forEach((wrapper) => {
                        promiseArray.push(wrapper);
                    });
                    return Promise.all(promiseArray).finally(() => {
                        this.privSubscribers = null;
                        this.privList.forEach((item, index) => {
                            pendingItemProcessor(item);
                        });
                        this.privList = null;
                        return;
                    }).then();
                }
                else {
                    this.privSubscribers = null;
                    this.privList = null;
                }
            }
        });
    }
    dispose(reason) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.drainAndDispose(null, reason);
        });
    }
}

//# sourceMappingURL=Queue.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js ***!
  \**************************************************************************************************************/
/*! exports provided: RawWebsocketMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RawWebsocketMessage", function() { return RawWebsocketMessage; });
/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class RawWebsocketMessage {
    constructor(messageType, payload, id) {
        this.privPayload = null;
        if (!payload) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_1__["ArgumentNullError"]("payload");
        }
        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary && payload.__proto__.constructor.name !== "ArrayBuffer") {
            throw new _Error__WEBPACK_IMPORTED_MODULE_1__["InvalidOperationError"]("Payload must be ArrayBuffer");
        }
        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text && !(typeof (payload) === "string")) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_1__["InvalidOperationError"]("Payload must be a string");
        }
        this.privMessageType = messageType;
        this.privPayload = payload;
        this.privId = id ? id : Object(_Guid__WEBPACK_IMPORTED_MODULE_2__["createNoDashGuid"])();
    }
    get messageType() {
        return this.privMessageType;
    }
    get payload() {
        return this.privPayload;
    }
    get textContent() {
        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Binary) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_1__["InvalidOperationError"]("Not supported for binary message");
        }
        return this.privPayload;
    }
    get binaryContent() {
        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__["MessageType"].Text) {
            throw new _Error__WEBPACK_IMPORTED_MODULE_1__["InvalidOperationError"]("Not supported for text message");
        }
        return this.privPayload;
    }
    get id() {
        return this.privId;
    }
}

//# sourceMappingURL=RawWebsocketMessage.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js ***!
  \*********************************************************************************************************/
/*! exports provided: RiffPcmEncoder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RiffPcmEncoder", function() { return RiffPcmEncoder; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class RiffPcmEncoder {
    constructor(actualSampleRate, desiredSampleRate) {
        this.encode = (actualAudioFrame) => {
            const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);
            if (!audioFrame) {
                return null;
            }
            const audioLength = audioFrame.length * 2;
            const buffer = new ArrayBuffer(audioLength);
            const view = new DataView(buffer);
            this.floatTo16BitPCM(view, 0, audioFrame);
            return buffer;
        };
        this.setString = (view, offset, str) => {
            for (let i = 0; i < str.length; i++) {
                view.setUint8(offset + i, str.charCodeAt(i));
            }
        };
        this.floatTo16BitPCM = (view, offset, input) => {
            for (let i = 0; i < input.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, input[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
        };
        this.downSampleAudioFrame = (srcFrame, srcRate, dstRate) => {
            if (!srcFrame) {
                return null;
            }
            if (dstRate === srcRate || dstRate > srcRate) {
                return srcFrame;
            }
            const ratio = srcRate / dstRate;
            const dstLength = Math.round(srcFrame.length / ratio);
            const dstFrame = new Float32Array(dstLength);
            let srcOffset = 0;
            let dstOffset = 0;
            while (dstOffset < dstLength) {
                const nextSrcOffset = Math.round((dstOffset + 1) * ratio);
                let accum = 0;
                let count = 0;
                while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {
                    accum += srcFrame[srcOffset++];
                    count++;
                }
                dstFrame[dstOffset++] = accum / count;
            }
            return dstFrame;
        };
        this.privActualSampleRate = actualSampleRate;
        this.privDesiredSampleRate = desiredSampleRate;
    }
}

//# sourceMappingURL=RiffPcmEncoder.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js ***!
  \*************************************************************************************************/
/*! exports provided: Stream */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Stream", function() { return Stream; });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Queue */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};



class Stream {
    constructor(streamId) {
        this.privIsWriteEnded = false;
        this.privIsReadEnded = false;
        this.read = () => {
            if (this.privIsReadEnded) {
                throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Stream read has already finished");
            }
            return this.privReaderQueue
                .dequeue()
                .then((streamChunk) => __awaiter(this, void 0, void 0, function* () {
                if (streamChunk === undefined || streamChunk.isEnd) {
                    yield this.privReaderQueue.dispose("End of stream reached");
                }
                return streamChunk;
            }));
        };
        this.readEnded = () => {
            if (!this.privIsReadEnded) {
                this.privIsReadEnded = true;
                this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_2__["Queue"]();
            }
        };
        this.throwIfClosed = () => {
            if (this.privIsWriteEnded) {
                throw new _Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Stream closed");
            }
        };
        this.privId = streamId ? streamId : Object(_Guid__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
        this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_2__["Queue"]();
    }
    get isClosed() {
        return this.privIsWriteEnded;
    }
    get isReadEnded() {
        return this.privIsReadEnded;
    }
    get id() {
        return this.privId;
    }
    close() {
        if (!this.privIsWriteEnded) {
            this.writeStreamChunk({
                buffer: null,
                isEnd: true,
                timeReceived: Date.now(),
            });
            this.privIsWriteEnded = true;
        }
    }
    writeStreamChunk(streamChunk) {
        this.throwIfClosed();
        if (!this.privReaderQueue.isDisposed()) {
            try {
                this.privReaderQueue.enqueue(streamChunk);
            }
            catch (e) {
                // Do nothing
            }
        }
    }
}

//# sourceMappingURL=Stream.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js ***!
  \**************************************************************************************************/
/*! exports provided: Timeout */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Timeout", function() { return Timeout; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class Timeout {
}
Timeout.workerTimers = null;
Timeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);
Timeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);
Timeout.load = (url) => {
    // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.
    const scheduledTimeoutFunctions = new Map([[0, () => { }]]); // tslint:disable-line no-empty
    const unhandledRequests = new Map();
    const worker = new Worker(url);
    worker.addEventListener("message", ({ data }) => {
        if (Timeout.isCallNotification(data)) {
            const { params: { timerId } } = data;
            const idOrFunc = scheduledTimeoutFunctions.get(timerId);
            if (typeof idOrFunc === "number") {
                const unhandledTimerId = unhandledRequests.get(idOrFunc);
                if (unhandledTimerId === undefined ||
                    unhandledTimerId !== timerId) {
                    throw new Error("The timer is in an undefined state.");
                }
            }
            else if (typeof idOrFunc !== "undefined") {
                idOrFunc();
                // A timeout can be safely deleted because it is only called once.
                scheduledTimeoutFunctions.delete(timerId);
            }
            else {
                throw new Error("The timer is in an undefined state.");
            }
        }
        else if (Timeout.isClearResponse(data)) {
            const { id } = data;
            const unhandledTimerId = unhandledRequests.get(id);
            if (unhandledTimerId === undefined) {
                throw new Error("The timer is in an undefined state.");
            }
            unhandledRequests.delete(id);
            scheduledTimeoutFunctions.delete(unhandledTimerId);
        }
        else {
            const { error: { message } } = data;
            throw new Error(message);
        }
    });
    const clearTimeout = (timerId) => {
        const id = Math.random();
        unhandledRequests.set(id, timerId);
        scheduledTimeoutFunctions.set(timerId, id);
        worker.postMessage({
            id,
            method: "clear",
            params: { timerId }
        });
    };
    const setTimeout = (func, delay) => {
        const timerId = Math.random();
        scheduledTimeoutFunctions.set(timerId, func);
        worker.postMessage({
            id: null,
            method: "set",
            params: {
                delay,
                now: performance.now(),
                timerId
            }
        });
        return timerId;
    };
    return {
        clearTimeout,
        setTimeout
    };
};
Timeout.loadWorkerTimers = () => {
    const worker = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="",n(n.s=14)}([function(e,t,n){"use strict";n.d(t,"a",(function(){return i})),n.d(t,"b",(function(){return u})),n.d(t,"c",(function(){return a})),n.d(t,"d",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id "'.concat(e,'".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id "'.concat(e,'".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if("performance"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o="performance"in self?performance.now():Date.now();o>n?postMessage({id:null,method:"call",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){"use strict";n.r(t);var r=n(2);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)"default"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)"default"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)"default"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)"default"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)"default"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(11);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(0),o=n(1);for(var i in o)"default"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)"default"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener("message",({data:e})=>{try{if("clear"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if("set"!==e.method)throw new Error('The given method "'.concat(e.method,'" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`; // tslint:disable-line:max-line-length
    return () => {
        if (Timeout.workerTimers !== null) {
            return Timeout.workerTimers;
        }
        const blob = new Blob([worker], { type: "application/javascript; charset=utf-8" });
        const url = URL.createObjectURL(blob);
        Timeout.workerTimers = Timeout.load(url);
        // Edge doesn't like the URL to be revoked directly.
        Timeout.workerTimers.setTimeout(() => URL.revokeObjectURL(url), 0);
        return Timeout.workerTimers;
    };
};
Timeout.timers = Timeout.loadWorkerTimers();
Timeout.isCallNotification = (message) => {
    return message.method !== undefined && message.method === "call";
};
Timeout.isClearResponse = (message) => {
    return message.error === null && typeof message.id === "number";
};

//# sourceMappingURL=Timeout.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js ***!
  \*****************************************************************************************************************/
/*! exports provided: ActivityReceivedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ActivityReceivedEventArgs", function() { return ActivityReceivedEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of received message/events.
 * @class ActivityReceivedEventArgs
 */
class ActivityReceivedEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {any} activity - The activity..
     */
    constructor(activity, audioStream) {
        this.privActivity = activity;
        this.privAudioStream = audioStream;
    }
    /**
     * Gets the received activity
     * @member ActivityReceivedEventArgs.prototype.activity
     * @function
     * @public
     * @returns {any} the received activity.
     */
    get activity() {
        return this.privActivity;
    }
    get audioStream() {
        return this.privAudioStream;
    }
}

//# sourceMappingURL=ActivityReceivedEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js ***!
  \*********************************************************************************************************/
/*! exports provided: AudioConfig, AudioConfigImpl, AudioOutputConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioConfig", function() { return AudioConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioConfigImpl", function() { return AudioConfigImpl; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioOutputConfigImpl", function() { return AudioOutputConfigImpl; });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _AudioFileWriter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioFileWriter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js");
/* harmony import */ var _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioInputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js");
/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






/**
 * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).
 * @class AudioConfig
 * Updated in version 1.11.0
 */
class AudioConfig {
    /**
     * Creates an AudioConfig object representing the default microphone on the system.
     * @member AudioConfig.fromDefaultMicrophoneInput
     * @function
     * @public
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromDefaultMicrophoneInput() {
        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["PcmRecorder"](true);
        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["MicAudioSource"](pcmRecorder));
    }
    /**
     * Creates an AudioConfig object representing a microphone with the specified device ID.
     * @member AudioConfig.fromMicrophoneInput
     * @function
     * @public
     * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.
     *        Default microphone is used the value is omitted.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromMicrophoneInput(deviceId) {
        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["PcmRecorder"](true);
        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["MicAudioSource"](pcmRecorder, deviceId));
    }
    /**
     * Creates an AudioConfig object representing the specified file.
     * @member AudioConfig.fromWavFileInput
     * @function
     * @public
     * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromWavFileInput(file, name = "unnamedBuffer.wav") {
        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["FileAudioSource"](file, name));
    }
    /**
     * Creates an AudioConfig object representing the specified stream.
     * @member AudioConfig.fromStreamInput
     * @function
     * @public
     * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input
     *        stream. Currently, only WAV / PCM is supported.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromStreamInput(audioStream) {
        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["PullAudioInputStreamCallback"]) {
            return new AudioConfigImpl(new _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__["PullAudioInputStreamImpl"](audioStream));
        }
        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["AudioInputStream"]) {
            return new AudioConfigImpl(audioStream);
        }
        if (typeof MediaStream !== "undefined" && audioStream instanceof MediaStream) {
            const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["PcmRecorder"](false);
            return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__["MicAudioSource"](pcmRecorder, null, null, audioStream));
        }
        throw new Error("Not Supported Type");
    }
    /**
     * Creates an AudioConfig object representing the default speaker.
     * @member AudioConfig.fromDefaultSpeakerOutput
     * @function
     * @public
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromDefaultSpeakerOutput() {
        return new AudioOutputConfigImpl(new _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerAudioDestination"]());
    }
    /**
     * Creates an AudioConfig object representing the custom IPlayer object.
     * You can use the IPlayer object to control pause, resume, etc.
     * @member AudioConfig.fromSpeakerOutput
     * @function
     * @public
     * @param {IPlayer} player - the IPlayer object for playback.
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.12.0
     */
    static fromSpeakerOutput(player) {
        if (player === undefined) {
            return AudioConfig.fromDefaultSpeakerOutput();
        }
        if (player instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeakerAudioDestination"]) {
            return new AudioOutputConfigImpl(player);
        }
        throw new Error("Not Supported Type");
    }
    /**
     * Creates an AudioConfig object representing a specified output audio file
     * @member AudioConfig.fromAudioFileOutput
     * @function
     * @public
     * @param {PathLike} filename - the filename of the output audio file
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromAudioFileOutput(filename) {
        return new AudioOutputConfigImpl(new _AudioFileWriter__WEBPACK_IMPORTED_MODULE_3__["AudioFileWriter"](filename));
    }
    /**
     * Creates an AudioConfig object representing a specified audio output stream
     * @member AudioConfig.fromStreamOutput
     * @function
     * @public
     * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output
     *        stream.
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromStreamOutput(audioStream) {
        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["PushAudioOutputStreamCallback"]) {
            return new AudioOutputConfigImpl(new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__["PushAudioOutputStreamImpl"](audioStream));
        }
        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["PushAudioOutputStream"]) {
            return new AudioOutputConfigImpl(audioStream);
        }
        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["PullAudioOutputStream"]) {
            return new AudioOutputConfigImpl(audioStream);
        }
        throw new Error("Not Supported Type");
    }
}
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class AudioConfigImpl
 */
class AudioConfigImpl extends AudioConfig {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {IAudioSource} source - An audio source.
     */
    constructor(source) {
        super();
        this.privSource = source;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return this.privSource.format;
    }
    /**
     * @member AudioConfigImpl.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        this.privSource.turnOff().then(() => {
            if (!!cb) {
                cb();
            }
        }, (error) => {
            if (!!err) {
                err(error);
            }
        });
    }
    /**
     * @member AudioConfigImpl.prototype.id
     * @function
     * @public
     */
    id() {
        return this.privSource.id();
    }
    /**
     * @member AudioConfigImpl.prototype.blob
     * @function
     * @public
     */
    get blob() {
        return this.privSource.blob;
    }
    /**
     * @member AudioConfigImpl.prototype.turnOn
     * @function
     * @public
     * @returns {Promise<void>} A promise.
     */
    turnOn() {
        return this.privSource.turnOn();
    }
    /**
     * @member AudioConfigImpl.prototype.attach
     * @function
     * @public
     * @param {string} audioNodeId - The audio node id.
     * @returns {Promise<IAudioStreamNode>} A promise.
     */
    attach(audioNodeId) {
        return this.privSource.attach(audioNodeId);
    }
    /**
     * @member AudioConfigImpl.prototype.detach
     * @function
     * @public
     * @param {string} audioNodeId - The audio node id.
     */
    detach(audioNodeId) {
        return this.privSource.detach(audioNodeId);
    }
    /**
     * @member AudioConfigImpl.prototype.turnOff
     * @function
     * @public
     * @returns {Promise<void>} A promise.
     */
    turnOff() {
        return this.privSource.turnOff();
    }
    /**
     * @member AudioConfigImpl.prototype.events
     * @function
     * @public
     * @returns {EventSource<AudioSourceEvent>} An event source for audio events.
     */
    get events() {
        return this.privSource.events;
    }
    setProperty(name, value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(value, "value");
        if (undefined !== this.privSource.setProperty) {
            this.privSource.setProperty(name, value);
        }
        else {
            throw new Error("This AudioConfig instance does not support setting properties.");
        }
    }
    getProperty(name, def) {
        if (undefined !== this.privSource.getProperty) {
            return this.privSource.getProperty(name, def);
        }
        else {
            throw new Error("This AudioConfig instance does not support getting properties.");
        }
        return def;
    }
    get deviceInfo() {
        return this.privSource.deviceInfo;
    }
}
class AudioOutputConfigImpl extends AudioConfig {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {IAudioDestination} destination - An audio destination.
     */
    constructor(destination) {
        super();
        this.privDestination = destination;
    }
    set format(format) {
        this.privDestination.format = format;
    }
    write(buffer) {
        this.privDestination.write(buffer);
    }
    close() {
        this.privDestination.close();
    }
    id() {
        return this.privDestination.id();
    }
    setProperty(name, value) {
        throw new Error("This AudioConfig instance does not support setting properties.");
    }
    getProperty(name, def) {
        throw new Error("This AudioConfig instance does not support getting properties.");
    }
}

//# sourceMappingURL=AudioConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js ***!
  \*************************************************************************************************************/
/*! exports provided: AudioFileWriter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioFileWriter", function() { return AudioFileWriter; });
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ 2);
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class AudioFileWriter {
    constructor(filename) {
        this.id = () => {
            return this.privId;
        };
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__["openSync"], "\nFile System access not available, please use Push or PullAudioOutputStream");
        this.privFd = fs__WEBPACK_IMPORTED_MODULE_0__["openSync"](filename, "w");
    }
    set format(format) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNotUndefined(this.privAudioFormat, "format is already set");
        this.privAudioFormat = format;
        let headerOffset = 0;
        if (this.privAudioFormat.hasHeader) {
            headerOffset = this.privAudioFormat.header.byteLength;
        }
        if (this.privFd !== undefined) {
            this.privWriteStream = fs__WEBPACK_IMPORTED_MODULE_0__["createWriteStream"]("", { fd: this.privFd, start: headerOffset, autoClose: false });
        }
    }
    write(buffer) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(this.privAudioFormat, "must set format before writing.");
        if (this.privWriteStream !== undefined) {
            this.privWriteStream.write(new Uint8Array(buffer.slice(0)));
        }
    }
    close() {
        if (this.privFd !== undefined) {
            this.privWriteStream.on("finish", () => {
                if (this.privAudioFormat.hasHeader) {
                    this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);
                    fs__WEBPACK_IMPORTED_MODULE_0__["writeSync"](this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);
                }
                fs__WEBPACK_IMPORTED_MODULE_0__["closeSync"](this.privFd);
                this.privFd = undefined;
            });
            this.privWriteStream.end();
        }
    }
}

//# sourceMappingURL=AudioFileWriter.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js ***!
  \**************************************************************************************************************/
/*! exports provided: AudioInputStream, PushAudioInputStream, PushAudioInputStreamImpl, PullAudioInputStream, PullAudioInputStreamImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* WEBPACK VAR INJECTION */(function(Buffer) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioInputStream", function() { return AudioInputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PushAudioInputStream", function() { return PushAudioInputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PushAudioInputStreamImpl", function() { return PushAudioInputStreamImpl; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStream", function() { return PullAudioInputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStreamImpl", function() { return PullAudioInputStreamImpl; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _common_Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
// tslint:disable:max-classes-per-file





/**
 * Represents audio input stream used for custom audio input configurations.
 * @class AudioInputStream
 */
class AudioInputStream {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() { }
    /**
     * Creates a memory backed PushAudioInputStream with the specified audio format.
     * @member AudioInputStream.createPushStream
     * @function
     * @public
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     *        written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PushAudioInputStream} The audio input stream being created.
     */
    static createPushStream(format) {
        return PushAudioInputStream.create(format);
    }
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for read()
     * and close() methods.
     * @member AudioInputStream.createPullStream
     * @function
     * @public
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from
     *        PullAudioInputStreamCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from
     *        the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PullAudioInputStream} The audio input stream being created.
     */
    static createPullStream(callback, format) {
        return PullAudioInputStream.create(callback, format);
        // throw new Error("Oops");
    }
}
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @class PushAudioInputStream
 */
class PushAudioInputStream extends AudioInputStream {
    /**
     * Creates a memory backed PushAudioInputStream with the specified audio format.
     * @member PushAudioInputStream.create
     * @function
     * @public
     * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
     *        push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PushAudioInputStream} The push audio input stream being created.
     */
    static create(format) {
        return new PushAudioInputStreamImpl(format);
    }
}
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @private
 * @class PushAudioInputStreamImpl
 */
class PushAudioInputStreamImpl extends PushAudioInputStream {
    /**
     * Creates and initalizes an instance with the given values.
     * @constructor
     * @param {AudioStreamFormat} format - The audio stream format.
     */
    constructor(format) {
        super();
        this.onEvent = (event) => {
            this.privEvents.onEvent(event);
            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(event);
        };
        if (format === undefined) {
            this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_4__["AudioStreamFormatImpl"].getDefaultInputFormat();
        }
        else {
            this.privFormat = format;
        }
        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privId = Object(_common_Guid__WEBPACK_IMPORTED_MODULE_2__["createNoDashGuid"])();
        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["ChunkedArrayBufferStream"](this.privFormat.avgBytesPerSec / 10);
    }
    /**
     * Format information for the audio
     */
    get format() {
        return Promise.resolve(this.privFormat);
    }
    /**
     * Writes the audio data specified by making an internal copy of the data.
     * @member PushAudioInputStreamImpl.prototype.write
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
     */
    write(dataBuffer) {
        this.privStream.writeStreamChunk({
            buffer: dataBuffer,
            isEnd: false,
            timeReceived: Date.now()
        });
    }
    /**
     * Closes the stream.
     * @member PushAudioInputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privStream.close();
    }
    id() {
        return this.privId;
    }
    get blob() {
        return this.attach("id").then((audioNode) => {
            const data = [];
            let bufferData = Buffer.from("");
            const readCycle = () => {
                return audioNode.read().then((audioStreamChunk) => {
                    if (!audioStreamChunk || audioStreamChunk.isEnd) {
                        if (typeof (XMLHttpRequest) !== "undefined" && typeof (Blob) !== "undefined") {
                            return Promise.resolve(new Blob(data));
                        }
                        else {
                            return Promise.resolve(Buffer.from(bufferData));
                        }
                    }
                    else {
                        if (typeof (Blob) !== "undefined") {
                            data.push(audioStreamChunk.buffer);
                        }
                        else {
                            bufferData = Buffer.concat([bufferData, this.toBuffer(audioStreamChunk.buffer)]);
                        }
                        return readCycle();
                    }
                });
            };
            return readCycle();
        });
    }
    turnOn() {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceInitializingEvent"](this.privId)); // no stream id
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceReadyEvent"](this.privId));
        return;
    }
    attach(audioNodeId) {
        return __awaiter(this, void 0, void 0, function* () {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachingEvent"](this.privId, audioNodeId));
            yield this.turnOn();
            const stream = this.privStream;
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachedEvent"](this.privId, audioNodeId));
            return {
                detach: () => __awaiter(this, void 0, void 0, function* () {
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
                    return this.turnOff();
                }),
                id: () => {
                    return audioNodeId;
                },
                read: () => {
                    return stream.read();
                },
            };
        });
    }
    detach(audioNodeId) {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
    }
    turnOff() {
        return;
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return Promise.resolve({
            bitspersample: this.privFormat.bitsPerSample,
            channelcount: this.privFormat.channels,
            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["connectivity"].Unknown,
            manufacturer: "Speech SDK",
            model: "PushStream",
            samplerate: this.privFormat.samplesPerSec,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["type"].Stream,
        });
    }
    toBuffer(arrayBuffer) {
        const buf = Buffer.alloc(arrayBuffer.byteLength);
        const view = new Uint8Array(arrayBuffer);
        for (let i = 0; i < buf.length; ++i) {
            buf[i] = view[i];
        }
        return buf;
    }
}
/*
 * Represents audio input stream used for custom audio input configurations.
 * @class PullAudioInputStream
 */
class PullAudioInputStream extends AudioInputStream {
    /**
     * Creates and initializes and instance.
     * @constructor
     */
    constructor() { super(); }
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for
     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
     * @member PullAudioInputStream.create
     * @function
     * @public
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
     *        derived from PullAudioInputStreamCustomCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     *        returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PullAudioInputStream} The push audio input stream being created.
     */
    static create(callback, format) {
        return new PullAudioInputStreamImpl(callback, format);
    }
}
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class PullAudioInputStreamImpl
 */
class PullAudioInputStreamImpl extends PullAudioInputStream {
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for
     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
     * @constructor
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
     *        derived from PullAudioInputStreamCustomCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     *        returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     */
    constructor(callback, format) {
        super();
        this.onEvent = (event) => {
            this.privEvents.onEvent(event);
            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(event);
        };
        if (undefined === format) {
            this.privFormat = _Exports__WEBPACK_IMPORTED_MODULE_3__["AudioStreamFormat"].getDefaultInputFormat();
        }
        else {
            this.privFormat = format;
        }
        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["EventSource"]();
        this.privId = Object(_common_Guid__WEBPACK_IMPORTED_MODULE_2__["createNoDashGuid"])();
        this.privCallback = callback;
        this.privIsClosed = false;
        this.privBufferSize = this.privFormat.avgBytesPerSec / 10;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return Promise.resolve(this.privFormat);
    }
    /**
     * Closes the stream.
     * @member PullAudioInputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privIsClosed = true;
        this.privCallback.close();
    }
    id() {
        return this.privId;
    }
    get blob() {
        return Promise.reject("Not implemented");
    }
    turnOn() {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceInitializingEvent"](this.privId)); // no stream id
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioSourceReadyEvent"](this.privId));
        return;
    }
    attach(audioNodeId) {
        return __awaiter(this, void 0, void 0, function* () {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachingEvent"](this.privId, audioNodeId));
            yield this.turnOn();
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeAttachedEvent"](this.privId, audioNodeId));
            return {
                detach: () => {
                    this.privCallback.close();
                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
                    return this.turnOff();
                },
                id: () => {
                    return audioNodeId;
                },
                read: () => {
                    let totalBytes = 0;
                    let transmitBuff;
                    // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
                    while (totalBytes < this.privBufferSize) {
                        // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much
                        // data back.
                        const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);
                        const pulledBytes = this.privCallback.read(readBuff);
                        // If there is no return buffer yet defined, set the return buffer to the that was just populated.
                        // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the
                        // preferred size allocated.
                        if (undefined === transmitBuff) {
                            transmitBuff = readBuff;
                        }
                        else {
                            // Not the first bite at the apple, so fill the return buffer with the data we got back.
                            const intView = new Int8Array(transmitBuff);
                            intView.set(new Int8Array(readBuff), totalBytes);
                        }
                        // If there are no bytes to read, just break out and be done.
                        if (0 === pulledBytes) {
                            break;
                        }
                        totalBytes += pulledBytes;
                    }
                    return Promise.resolve({
                        buffer: transmitBuff.slice(0, totalBytes),
                        isEnd: this.privIsClosed || totalBytes === 0,
                        timeReceived: Date.now(),
                    });
                },
            };
        });
    }
    detach(audioNodeId) {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["AudioStreamNodeDetachedEvent"](this.privId, audioNodeId));
    }
    turnOff() {
        return;
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return Promise.resolve({
            bitspersample: this.privFormat.bitsPerSample,
            channelcount: this.privFormat.channels,
            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["connectivity"].Unknown,
            manufacturer: "Speech SDK",
            model: "PullStream",
            samplerate: this.privFormat.samplesPerSec,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["type"].Stream,
        });
    }
}

//# sourceMappingURL=AudioInputStream.js.map

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../../../buffer/index.js */ "./node_modules/buffer/index.js").Buffer))

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioOutputFormatImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioOutputFormatImpl", function() { return AudioOutputFormatImpl; });
/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../SpeechSynthesisOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * @private
 * @class AudioOutputFormatImpl
 * Updated in version 1.17.0
 */
// tslint:disable-next-line:max-classes-per-file
class AudioOutputFormatImpl extends _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioStreamFormatImpl"] {
    /**
     * Creates an instance with the given values.
     * @constructor
     * @param formatTag
     * @param {number} channels - Number of channels.
     * @param {number} samplesPerSec - Samples per second.
     * @param {number} avgBytesPerSec - Average bytes per second.
     * @param {number} blockAlign - Block alignment.
     * @param {number} bitsPerSample - Bits per sample.
     * @param {string} audioFormatString - Audio format string
     * @param {string} requestAudioFormatString - Audio format string sent to service.
     * @param {boolean} hasHeader - If the format has header or not.
     */
    constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {
        super(samplesPerSec, bitsPerSample, channels, formatTag);
        this.formatTag = formatTag;
        this.avgBytesPerSec = avgBytesPerSec;
        this.blockAlign = blockAlign;
        this.priAudioFormatString = audioFormatString;
        this.priRequestAudioFormatString = requestAudioFormatString;
        this.priHasHeader = hasHeader;
    }
    static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {
        if (speechSynthesisOutputFormat === undefined) {
            return AudioOutputFormatImpl.getDefaultOutputFormat();
        }
        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);
    }
    static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {
        switch (speechSynthesisOutputFormatString) {
            case "raw-8khz-8bit-mono-mulaw":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-16khz-16kbps-mono-siren":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, "audio-16khz-16kbps-mono-siren", true);
            case "audio-16khz-16kbps-mono-siren":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-32kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-128kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-64kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-48kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-96kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-160kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-16khz-16bit-mono-truesilk":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-8khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", true);
            case "riff-24khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", true);
            case "riff-8khz-8bit-mono-mulaw":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-mulaw", true);
            case "raw-16khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, "raw-16khz-16bit-mono-pcm", false);
            case "raw-24khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", false);
            case "raw-8khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", false);
            case "ogg-16khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "ogg-24khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-48khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", false);
            case "riff-48khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", true);
            case "audio-48khz-96kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-48khz-192kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "ogg-48khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "webm-16khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].WEBM_OPUS, 1, 16000, 8000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "webm-24khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].WEBM_OPUS, 1, 24000, 8000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-24khz-16bit-mono-truesilk":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-8khz-8bit-mono-alaw":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-8khz-8bit-mono-alaw":
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-alaw", true);
            case "riff-16khz-16bit-mono-pcm":
            default:
                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioFormatTag"].PCM, 1, 16000, 32000, 2, 16, "riff-16khz-16bit-mono-pcm", "raw-16khz-16bit-mono-pcm", true);
        }
    }
    static getDefaultOutputFormat() {
        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString((typeof window !== "undefined") ? "audio-24khz-48kbitrate-mono-mp3" : "riff-16khz-16bit-mono-pcm");
    }
    /**
     * Specifies if this audio output format has a header
     * @boolean AudioOutputFormatImpl.prototype.hasHeader
     * @function
     * @public
     */
    get hasHeader() {
        return this.priHasHeader;
    }
    /**
     * Specifies the header of this format
     * @ArrayBuffer AudioOutputFormatImpl.prototype.header
     * @function
     * @public
     */
    get header() {
        if (this.hasHeader) {
            return this.privHeader;
        }
        return undefined;
    }
    /**
     * Updates the header based on the audio length
     * @member AudioOutputFormatImpl.updateHeader
     * @function
     * @public
     * @param {number} audioLength - the audio length
     */
    updateHeader(audioLength) {
        if (this.priHasHeader) {
            const view = new DataView(this.privHeader);
            view.setUint32(40, audioLength, true);
        }
    }
    /**
     * Specifies the audio format string to be sent to the service
     * @string AudioOutputFormatImpl.prototype.requestAudioFormatString
     * @function
     * @public
     */
    get requestAudioFormatString() {
        return this.priRequestAudioFormatString;
    }
}
AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw8Khz8BitMonoMULaw]: "raw-8khz-8bit-mono-mulaw",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff16Khz16KbpsMonoSiren]: "riff-16khz-16kbps-mono-siren",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio16Khz16KbpsMonoSiren]: "audio-16khz-16kbps-mono-siren",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio16Khz32KBitRateMonoMp3]: "audio-16khz-32kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio16Khz128KBitRateMonoMp3]: "audio-16khz-128kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio16Khz64KBitRateMonoMp3]: "audio-16khz-64kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio24Khz48KBitRateMonoMp3]: "audio-24khz-48kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio24Khz96KBitRateMonoMp3]: "audio-24khz-96kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio24Khz160KBitRateMonoMp3]: "audio-24khz-160kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw16Khz16BitMonoTrueSilk]: "raw-16khz-16bit-mono-truesilk",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff16Khz16BitMonoPcm]: "riff-16khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff8Khz16BitMonoPcm]: "riff-8khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff24Khz16BitMonoPcm]: "riff-24khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff8Khz8BitMonoMULaw]: "riff-8khz-8bit-mono-mulaw",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw16Khz16BitMonoPcm]: "raw-16khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw24Khz16BitMonoPcm]: "raw-24khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw8Khz16BitMonoPcm]: "raw-8khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Ogg16Khz16BitMonoOpus]: "ogg-16khz-16bit-mono-opus",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Ogg24Khz16BitMonoOpus]: "ogg-24khz-16bit-mono-opus",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw48Khz16BitMonoPcm]: "raw-48khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff48Khz16BitMonoPcm]: "riff-48khz-16bit-mono-pcm",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio48Khz96KBitRateMonoMp3]: "audio-48khz-96kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Audio48Khz192KBitRateMonoMp3]: "audio-48khz-192kbitrate-mono-mp3",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Ogg48Khz16BitMonoOpus]: "ogg-48khz-16bit-mono-opus",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Webm16Khz16BitMonoOpus]: "webm-16khz-16bit-mono-opus",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Webm24Khz16BitMonoOpus]: "webm-24khz-16bit-mono-opus",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw24Khz16BitMonoTrueSilk]: "raw-24khz-16bit-mono-truesilk",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Raw8Khz8BitMonoALaw]: "raw-8khz-8bit-mono-alaw",
    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisOutputFormat"].Riff8Khz8BitMonoALaw]: "riff-8khz-8bit-mono-alaw",
};

//# sourceMappingURL=AudioOutputFormat.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioOutputStream, PullAudioOutputStream, PullAudioOutputStreamImpl, PushAudioOutputStream, PushAudioOutputStreamImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioOutputStream", function() { return AudioOutputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PullAudioOutputStream", function() { return PullAudioOutputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PullAudioOutputStreamImpl", function() { return PullAudioOutputStreamImpl; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStream", function() { return PushAudioOutputStream; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStreamImpl", function() { return PushAudioOutputStreamImpl; });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
// tslint:disable:max-classes-per-file



/**
 * Represents audio output stream used for custom audio output configurations.
 * @class AudioOutputStream
 */
class AudioOutputStream {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() { }
    /**
     * Creates a memory backed PullAudioOutputStream with the specified audio format.
     * @member AudioOutputStream.createPullStream
     * @function
     * @public
     * @returns {PullAudioOutputStream} The audio output stream being created.
     */
    static createPullStream() {
        return PullAudioOutputStream.create();
    }
}
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @class PullAudioOutputStream
 */
class PullAudioOutputStream extends AudioOutputStream {
    /**
     * Creates a memory backed PullAudioOutputStream with the specified audio format.
     * @member PullAudioOutputStream.create
     * @function
     * @public
     * @returns {PullAudioOutputStream} The push audio output stream being created.
     */
    static create() {
        return new PullAudioOutputStreamImpl();
    }
}
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @private
 * @class PullAudioOutputStreamImpl
 */
class PullAudioOutputStreamImpl extends PullAudioOutputStream {
    /**
     * Creates and initializes an instance with the given values.
     * @constructor
     */
    constructor() {
        super();
        this.privId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__["Stream"]();
    }
    /**
     * Sets the format information to the stream. For internal use only.
     * @param {AudioStreamFormat} format - the format to be set.
     */
    set format(format) {
        if (format === undefined || format === null) {
            this.privFormat = _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__["AudioOutputFormatImpl"].getDefaultOutputFormat();
        }
        this.privFormat = format;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return this.privFormat;
    }
    /**
     * Checks if the stream is closed
     * @member PullAudioOutputStreamImpl.prototype.isClosed
     * @property
     * @public
     */
    get isClosed() {
        return this.privStream.isClosed;
    }
    /**
     * Gets the id of the stream
     * @member PullAudioOutputStreamImpl.prototype.id
     * @property
     * @public
     */
    id() {
        return this.privId;
    }
    /**
     * Reads audio data from the internal buffer.
     * @member PullAudioOutputStreamImpl.prototype.read
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.
     * @returns {Promise<number>} - Audio buffer length has been read.
     */
    read(dataBuffer) {
        return __awaiter(this, void 0, void 0, function* () {
            const intView = new Int8Array(dataBuffer);
            let totalBytes = 0;
            if (this.privLastChunkView !== undefined) {
                if (this.privLastChunkView.length > dataBuffer.byteLength) {
                    intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));
                    this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);
                    return Promise.resolve(dataBuffer.byteLength);
                }
                intView.set(this.privLastChunkView);
                totalBytes = this.privLastChunkView.length;
                this.privLastChunkView = undefined;
            }
            // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
            while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {
                const chunk = yield this.privStream.read();
                if (chunk !== undefined && !chunk.isEnd) {
                    let tmpBuffer;
                    if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {
                        tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);
                        this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));
                    }
                    else {
                        tmpBuffer = chunk.buffer;
                    }
                    intView.set(new Int8Array(tmpBuffer), totalBytes);
                    totalBytes += tmpBuffer.byteLength;
                }
                else {
                    yield this.privStream.readEnded();
                }
            }
            return totalBytes;
        });
    }
    /**
     * Writes the audio data specified by making an internal copy of the data.
     * @member PullAudioOutputStreamImpl.prototype.write
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
     */
    write(dataBuffer) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(this.privStream, "must set format before writing");
        this.privStream.writeStreamChunk({
            buffer: dataBuffer,
            isEnd: false,
            timeReceived: Date.now()
        });
    }
    /**
     * Closes the stream.
     * @member PullAudioOutputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privStream.close();
    }
}
/*
 * Represents audio output stream used for custom audio output configurations.
 * @class PushAudioOutputStream
 */
class PushAudioOutputStream extends AudioOutputStream {
    /**
     * Creates and initializes and instance.
     * @constructor
     */
    constructor() { super(); }
    /**
     * Creates a PushAudioOutputStream that delegates to the specified callback interface for
     * write() and close() methods.
     * @member PushAudioOutputStream.create
     * @function
     * @public
     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
     *        derived from PushAudioOutputStreamCallback
     * @returns {PushAudioOutputStream} The push audio output stream being created.
     */
    static create(callback) {
        return new PushAudioOutputStreamImpl(callback);
    }
}
/**
 * Represents audio output stream used for custom audio output configurations.
 * @private
 * @class PushAudioOutputStreamImpl
 */
class PushAudioOutputStreamImpl extends PushAudioOutputStream {
    /**
     * Creates a PushAudioOutputStream that delegates to the specified callback interface for
     * read() and close() methods.
     * @constructor
     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
     *        derived from PushAudioOutputStreamCallback
     */
    constructor(callback) {
        super();
        this.privId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__["createNoDashGuid"])();
        this.privCallback = callback;
    }
    // tslint:disable-next-line:no-empty
    set format(format) { }
    write(buffer) {
        if (!!this.privCallback.write) {
            this.privCallback.write(buffer);
        }
    }
    close() {
        if (!!this.privCallback.close) {
            this.privCallback.close();
        }
    }
    id() {
        return this.privId;
    }
}

//# sourceMappingURL=AudioOutputStream.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioFormatTag, AudioStreamFormat, AudioStreamFormatImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioFormatTag", function() { return AudioFormatTag; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamFormat", function() { return AudioStreamFormat; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AudioStreamFormatImpl", function() { return AudioStreamFormatImpl; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var AudioFormatTag;
(function (AudioFormatTag) {
    AudioFormatTag[AudioFormatTag["PCM"] = 1] = "PCM";
    AudioFormatTag[AudioFormatTag["MuLaw"] = 2] = "MuLaw";
    AudioFormatTag[AudioFormatTag["Siren"] = 3] = "Siren";
    AudioFormatTag[AudioFormatTag["MP3"] = 4] = "MP3";
    AudioFormatTag[AudioFormatTag["SILKSkype"] = 5] = "SILKSkype";
    AudioFormatTag[AudioFormatTag["OGG_OPUS"] = 6] = "OGG_OPUS";
    AudioFormatTag[AudioFormatTag["WEBM_OPUS"] = 7] = "WEBM_OPUS";
    AudioFormatTag[AudioFormatTag["ALaw"] = 8] = "ALaw";
})(AudioFormatTag || (AudioFormatTag = {}));
/**
 * Represents audio stream format used for custom audio input configurations.
 * @class AudioStreamFormat
 */
class AudioStreamFormat {
    /**
     * Creates an audio stream format object representing the default audio stream
     * format (16KHz 16bit mono PCM).
     * @member AudioStreamFormat.getDefaultInputFormat
     * @function
     * @public
     * @returns {AudioStreamFormat} The audio stream format being created.
     */
    static getDefaultInputFormat() {
        return AudioStreamFormatImpl.getDefaultInputFormat();
    }
    /**
     * Creates an audio stream format object with the specified pcm waveformat characteristics.
     * @member AudioStreamFormat.getWaveFormatPCM
     * @function
     * @public
     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
     * @param {number} bitsPerSample - Bits per sample, typically 16.
     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
     *        uses one channel and stereo data uses two channels.
     * @returns {AudioStreamFormat} The audio stream format being created.
     */
    static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {
        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);
    }
}
/**
 * @private
 * @class AudioStreamFormatImpl
 */
// tslint:disable-next-line:max-classes-per-file
class AudioStreamFormatImpl extends AudioStreamFormat {
    /**
     * Creates an instance with the given values.
     * @constructor
     * @param {number} samplesPerSec - Samples per second.
     * @param {number} bitsPerSample - Bits per sample.
     * @param {number} channels - Number of channels.
     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
     */
    constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {
        super();
        this.setString = (view, offset, str) => {
            for (let i = 0; i < str.length; i++) {
                view.setUint8(offset + i, str.charCodeAt(i));
            }
        };
        /* 1 for PCM; 6 for alaw; 7 for mulaw */
        switch (format) {
            case AudioFormatTag.PCM:
                this.formatTag = 1;
                break;
            case AudioFormatTag.ALaw:
                this.formatTag = 6;
                break;
            case AudioFormatTag.MuLaw:
                this.formatTag = 7;
                break;
            default:
        }
        this.bitsPerSample = bitsPerSample;
        this.samplesPerSec = samplesPerSec;
        this.channels = channels;
        this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);
        this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);
        this.privHeader = new ArrayBuffer(44);
        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView
        const view = new DataView(this.privHeader);
        /* RIFF identifier */
        this.setString(view, 0, "RIFF");
        /* file length */
        view.setUint32(4, 0, true);
        /* RIFF type & Format */
        this.setString(view, 8, "WAVEfmt ");
        /* format chunk length */
        view.setUint32(16, 16, true);
        /* audio format */
        view.setUint16(20, this.formatTag, true);
        /* channel count */
        view.setUint16(22, this.channels, true);
        /* sample rate */
        view.setUint32(24, this.samplesPerSec, true);
        /* byte rate (sample rate * block align) */
        view.setUint32(28, this.avgBytesPerSec, true);
        /* block align (channel count * bytes per sample) */
        view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);
        /* bits per sample */
        view.setUint16(34, this.bitsPerSample, true);
        /* data chunk identifier */
        this.setString(view, 36, "data");
        /* data chunk length */
        view.setUint32(40, 0, true);
    }
    /**
     * Retrieves the default input format.
     * @member AudioStreamFormatImpl.getDefaultInputFormat
     * @function
     * @public
     * @returns {AudioStreamFormatImpl} The default input format.
     */
    static getDefaultInputFormat() {
        return new AudioStreamFormatImpl();
    }
    /**
     * Creates an audio context appropriate to current browser
     * @member AudioStreamFormatImpl.getAudioContext
     * @function
     * @public
     * @returns {AudioContext} An audio context instance
     */
    static getAudioContext(sampleRate) {
        // Workaround for Speech SDK bug in Safari.
        const AudioContext = window.AudioContext // our preferred impl
            || window.webkitAudioContext // fallback, mostly when on Safari
            || false; // could not find.
        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
        if (!!AudioContext) {
            if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {
                return new AudioContext({ sampleRate });
            }
            else {
                return new AudioContext();
            }
        }
        else {
            throw new Error("Browser does not support Web Audio API (AudioContext is not available).");
        }
    }
    /**
     * Closes the configuration object.
     * @member AudioStreamFormatImpl.prototype.close
     * @function
     * @public
     */
    close() { return; }
    get header() {
        return this.privHeader;
    }
}

//# sourceMappingURL=AudioStreamFormat.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js ***!
  \*************************************************************************************************************/
/*! exports provided: BaseAudioPlayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BaseAudioPlayer", function() { return BaseAudioPlayer; });
/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Promise */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Base audio player class
 * TODO: Plays only PCM for now.
 * @class
 */
class BaseAudioPlayer {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.
     */
    constructor(audioFormat) {
        this.audioContext = null;
        this.gainNode = null;
        this.autoUpdateBufferTimer = 0;
        if (audioFormat === undefined) {
            audioFormat = _Exports__WEBPACK_IMPORTED_MODULE_2__["AudioStreamFormat"].getDefaultInputFormat();
        }
        this.init(audioFormat);
    }
    /**
     * play Audio sample
     * @param newAudioData audio data to be played.
     */
    playAudioSample(newAudioData, cb, err) {
        Object(_common_Promise__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            this.ensureInitializedContext();
            const audioData = this.formatAudioData(newAudioData);
            const newSamplesData = new Float32Array(this.samples.length + audioData.length);
            newSamplesData.set(this.samples, 0);
            newSamplesData.set(audioData, this.samples.length);
            this.samples = newSamplesData;
        }))(), cb, err);
    }
    /**
     * stops audio and clears the buffers
     */
    stopAudio(cb, err) {
        if (this.audioContext !== null) {
            this.samples = new Float32Array();
            clearInterval(this.autoUpdateBufferTimer);
            this.audioContext.close().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
            this.audioContext = null;
        }
    }
    init(audioFormat) {
        this.audioFormat = audioFormat;
        this.samples = new Float32Array();
    }
    ensureInitializedContext() {
        if (this.audioContext === null) {
            this.createAudioContext();
            const timerPeriod = 200;
            this.autoUpdateBufferTimer = setInterval(() => {
                this.updateAudioBuffer();
            }, timerPeriod);
        }
    }
    createAudioContext() {
        // new ((window as any).AudioContext || (window as any).webkitAudioContext)();
        this.audioContext = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioStreamFormatImpl"].getAudioContext();
        // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan
        // to control the volume, not likely
        this.gainNode = this.audioContext.createGain();
        this.gainNode.gain.value = 1;
        this.gainNode.connect(this.audioContext.destination);
        this.startTime = this.audioContext.currentTime;
    }
    formatAudioData(audioData) {
        switch (this.audioFormat.bitsPerSample) {
            case 8:
                return this.formatArrayBuffer(new Int8Array(audioData), 128);
            case 16:
                return this.formatArrayBuffer(new Int16Array(audioData), 32768);
            case 32:
                return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);
            default:
                throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__["InvalidOperationError"]("Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time");
        }
    }
    formatArrayBuffer(audioData, maxValue) {
        const float32Data = new Float32Array(audioData.length);
        for (let i = 0; i < audioData.length; i++) {
            float32Data[i] = audioData[i] / maxValue;
        }
        return float32Data;
    }
    updateAudioBuffer() {
        if (this.samples.length === 0) {
            return;
        }
        const channelCount = this.audioFormat.channels;
        const bufferSource = this.audioContext.createBufferSource();
        const frameCount = this.samples.length / channelCount;
        const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);
        // TODO: Should we do the conversion in the pushAudioSample instead?
        for (let channel = 0; channel < channelCount; channel++) {
            // Fill in individual channel data
            let channelOffset = channel;
            const audioData = audioBuffer.getChannelData(channel);
            for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {
                audioData[i] = this.samples[channelOffset];
            }
        }
        if (this.startTime < this.audioContext.currentTime) {
            this.startTime = this.audioContext.currentTime;
        }
        bufferSource.buffer = audioBuffer;
        bufferSource.connect(this.gainNode);
        bufferSource.start(this.startTime);
        // Make sure we play the next sample after the current one.
        this.startTime += audioBuffer.duration;
        // Clear the samples for the next pushed data.
        this.samples = new Float32Array();
    }
    playAudio(audioData) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.audioContext === null) {
                this.createAudioContext();
            }
            const source = this.audioContext.createBufferSource();
            const destination = this.audioContext.destination;
            yield this.audioContext.decodeAudioData(audioData, (newBuffer) => {
                source.buffer = newBuffer;
                source.connect(destination);
                source.start(0);
            });
        });
    }
}

//# sourceMappingURL=BaseAudioPlayer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \**************************************************************************************************************************/
/*! exports provided: PullAudioInputStreamCallback */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStreamCallback", function() { return PullAudioInputStreamCallback; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (read() and close()) for
 * custom audio input streams).
 * @class PullAudioInputStreamCallback
 */
class PullAudioInputStreamCallback {
}

//# sourceMappingURL=PullAudioInputStreamCallback.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \***************************************************************************************************************************/
/*! exports provided: PushAudioOutputStreamCallback */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStreamCallback", function() { return PushAudioOutputStreamCallback; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (write() and close()) for
 * custom audio output streams).
 * @class PushAudioOutputStreamCallback
 */
class PushAudioOutputStreamCallback {
}

//# sourceMappingURL=PushAudioOutputStreamCallback.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \*********************************************************************************************************************/
/*! exports provided: SpeakerAudioDestination */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerAudioDestination", function() { return SpeakerAudioDestination; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




const MediaDurationPlaceholderSeconds = 60 * 30;
const AudioFormatToMimeType = {
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].PCM]: "audio/wav",
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].MuLaw]: "audio/x-wav",
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].MP3]: "audio/mpeg",
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].OGG_OPUS]: "audio/ogg",
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].WEBM_OPUS]: "audio/webm; codecs=opus",
    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].ALaw]: "audio/x-wav",
};
/**
 * Represents the speaker playback audio destination, which only works in browser.
 * Note: the SDK will try to use <a href="https://www.w3.org/TR/media-source/">Media Source Extensions</a> to play audio.
 * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.
 * @class SpeakerAudioDestination
 * Updated in version 1.17.0
 */
class SpeakerAudioDestination {
    constructor(audioDestinationId) {
        this.privPlaybackStarted = false;
        this.privAppendingToBuffer = false;
        this.privMediaSourceOpened = false;
        this.privBytesReceived = 0;
        this.privId = audioDestinationId ? audioDestinationId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
        this.privIsPaused = false;
        this.privIsClosed = false;
    }
    id() {
        return this.privId;
    }
    write(buffer, cb, err) {
        if (this.privAudioBuffer !== undefined) {
            this.privAudioBuffer.push(buffer);
            this.updateSourceBuffer().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        else if (this.privAudioOutputStream !== undefined) {
            this.privAudioOutputStream.write(buffer);
            this.privBytesReceived += buffer.byteLength;
        }
    }
    close(cb, err) {
        this.privIsClosed = true;
        if (this.privSourceBuffer !== undefined) {
            this.handleSourceBufferUpdateEnd().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        else if (this.privAudioOutputStream !== undefined) {
            if ((this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].PCM || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].MuLaw
                || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"].ALaw) && this.privFormat.hasHeader === false) {
                // tslint:disable-next-line:no-console
                console.warn(`Play back is not supported for raw PCM, mulaw or alaw format without header.`);
                if (!!this.onAudioEnd) {
                    this.onAudioEnd(this);
                }
            }
            else {
                let receivedAudio = new ArrayBuffer(this.privBytesReceived);
                this.privAudioOutputStream.read(receivedAudio).then((_) => {
                    receivedAudio = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesisAdapterBase"].addHeader(receivedAudio, this.privFormat);
                    const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });
                    this.privAudio.src = window.URL.createObjectURL(audioBlob);
                    this.notifyPlayback().then(() => {
                        if (!!cb) {
                            cb();
                        }
                    }, (error) => {
                        if (!!err) {
                            err(error);
                        }
                    });
                }, (error) => {
                    if (!!err) {
                        err(error);
                    }
                });
            }
        }
        else {
            // unsupported format, call onAudioEnd directly.
            if (!!this.onAudioEnd) {
                this.onAudioEnd(this);
            }
        }
    }
    set format(format) {
        if (typeof (AudioContext) !== "undefined" || typeof (window.webkitAudioContext) !== "undefined") {
            this.privFormat = format;
            const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];
            if (mimeType === undefined) {
                // tslint:disable-next-line:no-console
                console.warn(`Unknown mimeType for format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"][this.privFormat.formatTag]}; playback is not supported.`);
            }
            else if (typeof (MediaSource) !== "undefined" && MediaSource.isTypeSupported(mimeType)) {
                this.privAudio = new Audio();
                this.privAudioBuffer = [];
                this.privMediaSource = new MediaSource();
                this.privAudio.src = URL.createObjectURL(this.privMediaSource);
                this.privAudio.load();
                this.privMediaSource.onsourceopen = (event) => {
                    this.privMediaSourceOpened = true;
                    this.privMediaSource.duration = MediaDurationPlaceholderSeconds;
                    this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);
                    this.privSourceBuffer.onupdate = (_) => {
                        this.updateSourceBuffer().catch((reason) => {
                            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
                        });
                    };
                    this.privSourceBuffer.onupdateend = (_) => {
                        this.handleSourceBufferUpdateEnd().catch((reason) => {
                            _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
                        });
                    };
                    this.privSourceBuffer.onupdatestart = (_) => {
                        this.privAppendingToBuffer = false;
                    };
                };
                this.updateSourceBuffer().catch((reason) => {
                    _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Events"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["BackgroundEvent"](reason));
                });
            }
            else {
                // tslint:disable-next-line:no-console
                console.warn(`Format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__["AudioFormatTag"][this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);
                this.privAudioOutputStream = new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_2__["PullAudioOutputStreamImpl"]();
                this.privAudioOutputStream.format = this.privFormat;
                this.privAudio = new Audio();
            }
        }
    }
    get isClosed() {
        return this.privIsClosed;
    }
    get currentTime() {
        if (this.privAudio !== undefined) {
            return this.privAudio.currentTime;
        }
        return -1;
    }
    pause() {
        if (!this.privIsPaused && this.privAudio !== undefined) {
            this.privAudio.pause();
            this.privIsPaused = true;
        }
    }
    resume(cb, err) {
        if (this.privIsPaused && this.privAudio !== undefined) {
            this.privAudio.play().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
            this.privIsPaused = false;
        }
    }
    get internalAudio() {
        return this.privAudio;
    }
    updateSourceBuffer() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privAudioBuffer !== undefined && (this.privAudioBuffer.length > 0) && this.sourceBufferAvailable()) {
                this.privAppendingToBuffer = true;
                const binary = this.privAudioBuffer.shift();
                try {
                    this.privSourceBuffer.appendBuffer(binary);
                }
                catch (error) {
                    this.privAudioBuffer.unshift(binary);
                    // tslint:disable-next-line:no-console
                    console.log("buffer filled, pausing addition of binaries until space is made");
                    return;
                }
                yield this.notifyPlayback();
            }
            else if (this.canEndStream()) {
                yield this.handleSourceBufferUpdateEnd();
            }
        });
    }
    handleSourceBufferUpdateEnd() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.canEndStream() && this.sourceBufferAvailable()) {
                this.privMediaSource.endOfStream();
                yield this.notifyPlayback();
            }
        });
    }
    notifyPlayback() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privPlaybackStarted && this.privAudio !== undefined) {
                this.privPlaybackStarted = true;
                if (!!this.onAudioStart) {
                    this.onAudioStart(this);
                }
                this.privAudio.onended = () => {
                    if (!!this.onAudioEnd) {
                        this.onAudioEnd(this);
                    }
                };
                if (!this.privIsPaused) {
                    yield this.privAudio.play();
                }
            }
        });
    }
    canEndStream() {
        return (this.isClosed && this.privSourceBuffer !== undefined && (this.privAudioBuffer.length === 0)
            && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === "open");
    }
    sourceBufferAvailable() {
        return (this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating);
    }
}

//# sourceMappingURL=SpeakerAudioDestination.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AutoDetectSourceLanguageConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageConfig", function() { return AutoDetectSourceLanguageConfig; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Language auto detect configuration.
 * @class AutoDetectSourceLanguageConfig
 * Added in version 1.13.0.
 */
class AutoDetectSourceLanguageConfig {
    constructor() {
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromOpenRange
     * @function
     * @public
     * Only [[SpeechSynthesizer]] supports source language auto detection from open range,
     * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.
     */
    static fromOpenRange() {
        const config = new AutoDetectSourceLanguageConfig();
        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["AutoDetectSourceLanguagesOpenRangeOptionName"]);
        return config;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromLanguages
     * @function
     * @public
     * @param {string[]} languages Comma-separated string of languages (eg. "en-US,fr-FR") to populate properties of config.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.
     */
    static fromLanguages(languages) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfArrayEmptyOrWhitespace(languages, "languages");
        const config = new AutoDetectSourceLanguageConfig();
        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());
        return config;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs
     * @function
     * @public
     * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.
     */
    static fromSourceLanguageConfigs(configs) {
        if (configs.length < 1) {
            throw new Error("Expected non-empty SourceLanguageConfig array.");
        }
        const autoConfig = new AutoDetectSourceLanguageConfig();
        const langs = [];
        configs.forEach((config) => {
            langs.push(config.language);
            if (config.endpointId !== undefined && config.endpointId !== "") {
                const customProperty = config.language + _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId.toString();
                autoConfig.properties.setProperty(customProperty, config.endpointId);
            }
        });
        autoConfig.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());
        return autoConfig;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.prototype.properties
     * @function
     * @public
     * @return {PropertyCollection} Properties of the config.
     * @summary Gets an auto detected language config properties
     */
    get properties() {
        return this.privProperties;
    }
}

//# sourceMappingURL=AutoDetectSourceLanguageConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AutoDetectSourceLanguageResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageResult", function() { return AutoDetectSourceLanguageResult; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Output format
 * @class AutoDetectSourceLanguageResult
 */
class AutoDetectSourceLanguageResult {
    constructor(language, languageDetectionConfidence) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(language, "language");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(languageDetectionConfidence, "languageDetectionConfidence");
        this.privLanguage = language;
        this.privLanguageDetectionConfidence = languageDetectionConfidence;
    }
    /**
     * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.
     * @member AutoDetectSourceLanguageResult.fromResult
     * @function
     * @public
     * @param {SpeechRecognitionResult} result - The recognition result.
     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.
     */
    static fromResult(result) {
        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);
    }
    get language() {
        return this.privLanguage;
    }
    get languageDetectionConfidence() {
        return this.privLanguageDetectionConfidence;
    }
}

//# sourceMappingURL=AutoDetectSourceLanguageResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js ***!
  \**********************************************************************************************************/
/*! exports provided: BotFrameworkConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "BotFrameworkConfig", function() { return BotFrameworkConfig; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.
 * @class BotFrameworkConfig
 */
class BotFrameworkConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"] {
    /**
     * Creates an instance of BotFrameworkConfig.
     */
    constructor() {
        super();
    }
    /**
     * Creates a bot framework configuration instance with the provided subscription information.
     * @member BotFrameworkConfig.fromSubscription
     * @function
     * @public
     * @param subscription Subscription key associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     *        resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromSubscription(subscription, region, botId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(subscription, "subscription");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscription);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        if (botId) {
            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, botId);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates a bot framework configuration instance for the specified authorization token and region.
     * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the
     *       caller must refresh it by setting the authorizationToken property on the corresponding
     *       DialogServiceConnector instance created with this config. The contents of configuration objects are copied
     *       when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the
     *       original configuration's authorization token. Create a new configuration instance or set the
     *       SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create
     *       further DialogServiceConnectors.
     * @member BotFrameworkConfig.fromAuthorizationToken
     * @function
     * @public
     * @param authorizationToken The authorization token associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     *        resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromAuthorizationToken(authorizationToken, region, botId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, authorizationToken);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        if (botId) {
            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, botId);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates an instance of a BotFrameworkConfig.
     * This method is intended only for users who use a non-default service host. The standard resource path will be
     * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken
     *       property on the created BotFrameworkConfig instance.
     * Note: Added in version 1.15.0.
     * @member BotFrameworkConfig.fromHost
     * @function
     * @public
     * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.
     *        wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in
     *        wss://{host}.convai.speech.azure.us.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
     *        token must be set.
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     *        resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromHost(host, subscriptionKey, botId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(host, "host");
        const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(resolvedHost, "resolvedHost");
        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Host, resolvedHost.toString());
        if (undefined !== subscriptionKey) {
            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates an instance of a BotFrameworkConfig.
     * This method is intended only for users who use a non-standard service endpoint or parameters.
     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
     *       fromEndpoint method, and then set authorizationToken="token" on the created BotFrameworkConfig instance to
     *       use the authorization token.
     * Note: Added in version 1.15.0.
     * @member BotFrameworkConfig.fromEndpoint
     * @function
     * @public
     * @param {URL} endpoint - The service endpoint to connect to.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
     *        token must be set.
     * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.
     */
    static fromEndpoint(endpoint, subscriptionKey) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNull(endpoint, "endpoint");
        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint, endpoint.toString());
        if (undefined !== subscriptionKey) {
            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        }
        return botFrameworkConfig;
    }
}

//# sourceMappingURL=BotFrameworkConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js ***!
  \***********************************************************************************************************/
/*! exports provided: CancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationDetails", function() { return CancellationDetails; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CancellationDetailsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetails
 */
class CancellationDetails extends _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_1__["CancellationDetailsBase"] {
    constructor(reason, errorDetails, errorCode) {
        super(reason, errorDetails, errorCode);
    }
    /**
     * Creates an instance of CancellationDetails object for the canceled RecognitionResult.
     * @member CancellationDetails.fromResult
     * @function
     * @public
     * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.
     * @returns {CancellationDetails} The cancellation details object being created.
     */
    static fromResult(result) {
        let reason = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error;
        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError;
        if (result instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__["RecognitionResult"] && !!result.json) {
            const simpleSpeech = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SimpleSpeechPhrase"].fromJSON(result.json);
            reason = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["EnumTranslation"].implTranslateCancelResult(simpleSpeech.RecognitionStatus);
        }
        if (!!result.properties) {
            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError])];
        }
        return new CancellationDetails(reason, result.errorDetails, errorCode);
    }
}

//# sourceMappingURL=CancellationDetails.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js ***!
  \***************************************************************************************************************/
/*! exports provided: CancellationDetailsBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationDetailsBase", function() { return CancellationDetailsBase; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetailsBase
 */
class CancellationDetailsBase {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {CancellationReason} reason - The cancellation reason.
     * @param {string} errorDetails - The error details, if provided.
     */
    constructor(reason, errorDetails, errorCode) {
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privErrorCode = errorCode;
    }
    /**
     * The reason the recognition was canceled.
     * @member CancellationDetailsBase.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member CancellationDetailsBase.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     * The error code in case of an unsuccessful recognition.
     * Added in version 1.1.0.
     * @return An error code that represents the error reason.
     */
    get ErrorCode() {
        return this.privErrorCode;
    }
}

//# sourceMappingURL=CancellationDetailsBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js ***!
  \**************************************************************************************************************/
/*! exports provided: CancellationErrorCode */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationErrorCode", function() { return CancellationErrorCode; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 *  Defines error code in case that CancellationReason is Error.
 *  Added in version 1.1.0.
 */
var CancellationErrorCode;
(function (CancellationErrorCode) {
    /**
     * Indicates that no error occurred during speech recognition.
     */
    CancellationErrorCode[CancellationErrorCode["NoError"] = 0] = "NoError";
    /**
     * Indicates an authentication error.
     */
    CancellationErrorCode[CancellationErrorCode["AuthenticationFailure"] = 1] = "AuthenticationFailure";
    /**
     * Indicates that one or more recognition parameters are invalid.
     */
    CancellationErrorCode[CancellationErrorCode["BadRequestParameters"] = 2] = "BadRequestParameters";
    /**
     * Indicates that the number of parallel requests exceeded the number of allowed
     * concurrent transcriptions for the subscription.
     */
    CancellationErrorCode[CancellationErrorCode["TooManyRequests"] = 3] = "TooManyRequests";
    /**
     * Indicates a connection error.
     */
    CancellationErrorCode[CancellationErrorCode["ConnectionFailure"] = 4] = "ConnectionFailure";
    /**
     * Indicates a time-out error when waiting for response from service.
     */
    CancellationErrorCode[CancellationErrorCode["ServiceTimeout"] = 5] = "ServiceTimeout";
    /**
     * Indicates that an error is returned by the service.
     */
    CancellationErrorCode[CancellationErrorCode["ServiceError"] = 6] = "ServiceError";
    /**
     * Indicates an unexpected runtime error.
     */
    CancellationErrorCode[CancellationErrorCode["RuntimeError"] = 7] = "RuntimeError";
})(CancellationErrorCode || (CancellationErrorCode = {}));

//# sourceMappingURL=CancellationErrorCodes.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js ***!
  \*****************************************************************************************************************/
/*! exports provided: CancellationEventArgsBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationEventArgsBase", function() { return CancellationEventArgsBase; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines content of a CancellationEvent.
 * @class CancellationEventArgsBase
 */
class CancellationEventArgsBase extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {CancellationReason} reason - The cancellation reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(reason, errorDetails, errorCode, offset, sessionId) {
        super(offset, sessionId);
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privErrorCode = errorCode;
    }
    /**
     * The reason the recognition was canceled.
     * @member CancellationEventArgsBase.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * The error code in case of an unsuccessful operation.
     * @return An error code that represents the error reason.
     */
    get errorCode() {
        return this.privErrorCode;
    }
    /**
     * In case of an unsuccessful operation, provides details of the occurred error.
     * @member CancellationEventArgsBase.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
}

//# sourceMappingURL=CancellationEventArgsBase.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js ***!
  \**********************************************************************************************************/
/*! exports provided: CancellationReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CancellationReason", function() { return CancellationReason; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might be canceled.
 * @class CancellationReason
 */
var CancellationReason;
(function (CancellationReason) {
    /**
     * Indicates that an error occurred during speech recognition.
     * @member CancellationReason.Error
     */
    CancellationReason[CancellationReason["Error"] = 0] = "Error";
    /**
     * Indicates that the end of the audio stream was reached.
     * @member CancellationReason.EndOfStream
     */
    CancellationReason[CancellationReason["EndOfStream"] = 1] = "EndOfStream";
})(CancellationReason || (CancellationReason = {}));

//# sourceMappingURL=CancellationReason.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js ***!
  \**************************************************************************************************/
/*! exports provided: Connection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Connection", function() { return Connection; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//





/**
 * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.
 * By default, a Recognizer autonomously manages connection to service when needed.
 * The Connection class provides additional methods for users to explicitly open or close a connection and
 * to subscribe to connection status changes.
 * The use of Connection is optional, and mainly for scenarios where fine tuning of application
 * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection
 * in advance before starting recognition on the Recognizer associated with this Connection.
 * If the Recognizer needs to connect or disconnect to service, it will
 * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection
 * status via Connected/Disconnected events.
 * Added in version 1.2.1.
 */
class Connection {
    /**
     * Gets the Connection instance from the specified recognizer.
     * @param recognizer The recognizer associated with the connection.
     * @return The Connection instance of the recognizer.
     */
    static fromRecognizer(recognizer) {
        const recoBase = recognizer.internalData;
        const ret = new Connection();
        ret.privInternalData = recoBase;
        ret.setupEvents();
        return ret;
    }
    /**
     * Gets the Connection instance from the specified synthesizer.
     * @param synthesizer The synthesizer associated with the connection.
     * @return The Connection instance of the synthesizer.
     */
    static fromSynthesizer(synthesizer) {
        const synthBase = synthesizer.internalData;
        const ret = new Connection();
        ret.privInternalData = synthBase;
        ret.setupEvents();
        return ret;
    }
    /**
     * Starts to set up connection to the service.
     * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the
     * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect
     *
     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
     * be notified when the connection is established.
     */
    openConnection(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.privInternalData.connect(), cb, err);
    }
    /**
     * Closes the connection the service.
     * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.
     *
     * If closeConnection() is called during recognition, recognition will fail and cancel with an error.
     */
    closeConnection(cb, err) {
        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesisAdapterBase"]) {
            throw new Error("Disconnecting a synthesizer's connection is currently not supported");
        }
        else {
            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.privInternalData.disconnect(), cb, err);
        }
    }
    /**
     * Appends a parameter in a message to service.
     * Added in version 1.12.1.
     * @param path The path of the network message.
     * @param propertyName Name of the property
     * @param propertyValue Value of the property. This is a json string.
     */
    setMessageProperty(path, propertyName, propertyValue) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrWhitespace(propertyName, "propertyName");
        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServiceRecognizerBase"]) {
            if (path.toLowerCase() !== "speech.context") {
                throw new Error("Only speech.context message property sets are currently supported for recognizer");
            }
            else {
                this.privInternalData.speechContext.setSection(propertyName, propertyValue);
            }
        }
        else if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesisAdapterBase"]) {
            if (path.toLowerCase() !== "synthesis.context") {
                throw new Error("Only synthesis.context message property sets are currently supported for synthesizer");
            }
            else {
                this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);
            }
        }
    }
    /**
     * Sends a message to the speech service.
     * Added in version 1.13.0.
     * @param path The WebSocket path of the message
     * @param payload The payload of the message. This is a json string or a ArrayBuffer.
     * @param success A callback to indicate success.
     * @param error A callback to indicate an error.
     */
    sendMessageAsync(path, payload, success, error) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.privInternalData.sendNetworkMessage(path, payload), success, error);
    }
    /**
     * Dispose of associated resources.
     */
    close() {
        /* tslint:disable:no-empty */
    }
    setupEvents() {
        this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionEstablishedEvent") {
                if (!!this.connected) {
                    this.connected(new _Exports__WEBPACK_IMPORTED_MODULE_4__["ConnectionEventArgs"](connectionEvent.connectionId));
                }
            }
            else if (connectionEvent.name === "ConnectionClosedEvent") {
                if (!!this.disconnected) {
                    this.disconnected(new _Exports__WEBPACK_IMPORTED_MODULE_4__["ConnectionEventArgs"](connectionEvent.connectionId));
                }
            }
            else if (connectionEvent.name === "ConnectionMessageSentEvent") {
                if (!!this.messageSent) {
                    this.messageSent(new _Exports__WEBPACK_IMPORTED_MODULE_4__["ConnectionMessageEventArgs"](new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__["ConnectionMessageImpl"](connectionEvent.message)));
                }
            }
            else if (connectionEvent.name === "ConnectionMessageReceivedEvent") {
                if (!!this.messageReceived) {
                    this.messageReceived(new _Exports__WEBPACK_IMPORTED_MODULE_4__["ConnectionMessageEventArgs"](new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__["ConnectionMessageImpl"](connectionEvent.message)));
                }
            }
        });
        this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {
            if (!!this.receivedServiceMessage) {
                this.receivedServiceMessage(new _Exports__WEBPACK_IMPORTED_MODULE_4__["ServiceEventArgs"](e.jsonString, e.name));
            }
        });
    }
}

//# sourceMappingURL=Connection.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js ***!
  \***********************************************************************************************************/
/*! exports provided: ConnectionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionEventArgs", function() { return ConnectionEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//

/**
 * Defines payload for connection events like Connected/Disconnected.
 * Added in version 1.2.0
 */
class ConnectionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
}

//# sourceMappingURL=ConnectionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js ***!
  \*********************************************************************************************************/
/*! exports provided: ConnectionMessage, ConnectionMessageImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessage", function() { return ConnectionMessage; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageImpl", function() { return ConnectionMessageImpl; });
/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./PropertyCollection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//




/**
 * ConnectionMessage represents implementation specific messages sent to and received from
 * the speech service. These messages are provided for debugging purposes and should not
 * be used for production use cases with the Azure Cognitive Services Speech Service.
 * Messages sent to and received from the Speech Service are subject to change without
 * notice. This includes message contents, headers, payloads, ordering, etc.
 * Added in version 1.11.0.
 */
class ConnectionMessage {
}
// tslint:disable-next-line:max-classes-per-file
class ConnectionMessageImpl {
    constructor(message) {
        this.privConnectionMessage = message;
        this.privProperties = new _PropertyCollection__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
        if (!!this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__["HeaderNames"].ConnectionId]) {
            this.privProperties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].Speech_SessionId, this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__["HeaderNames"].ConnectionId]);
        }
        Object.keys(this.privConnectionMessage.headers).forEach((header, index, array) => {
            this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);
        });
    }
    /**
     * The message path.
     */
    get path() {
        return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === "path".toLowerCase())];
    }
    /**
     * Checks to see if the ConnectionMessage is a text message.
     * See also IsBinaryMessage().
     */
    get isTextMessage() {
        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Text;
    }
    /**
     * Checks to see if the ConnectionMessage is a binary message.
     * See also GetBinaryMessage().
     */
    get isBinaryMessage() {
        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__["MessageType"].Binary;
    }
    /**
     * Gets the text message payload. Typically the text message content-type is
     * application/json. To determine other content-types use
     * Properties.GetProperty("Content-Type").
     */
    get TextMessage() {
        return this.privConnectionMessage.textBody;
    }
    /**
     * Gets the binary message payload.
     */
    get binaryMessage() {
        return this.privConnectionMessage.binaryBody;
    }
    /**
     * A collection of properties and their values defined for this <see cref="ConnectionMessage"/>.
     * Message headers can be accessed via this collection (e.g. "Content-Type").
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Returns a string that represents the connection message.
     */
    toString() {
        return "";
    }
}

//# sourceMappingURL=ConnectionMessage.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: ConnectionMessageEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageEventArgs", function() { return ConnectionMessageEventArgs; });
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
class ConnectionMessageEventArgs {
    constructor(message) {
        this.privConnectionMessage = message;
    }
    /**
     * Gets the <see cref="ConnectionMessage"/> associated with this <see cref="ConnectionMessageEventArgs"/>.
     */
    get message() {
        return this.privConnectionMessage;
    }
    /**
     * Returns a string that represents the connection message event.
     */
    toString() {
        return "Message: " + this.privConnectionMessage.toString();
    }
}

//# sourceMappingURL=ConnectionMessageEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js ***!
  \*************************************************************************************************/
/*! exports provided: Contracts */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Contracts", function() { return Contracts; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class Contracts
 * @private
 */
class Contracts {
    static throwIfNullOrUndefined(param, name) {
        if (param === undefined || param === null) {
            throw new Error("throwIfNullOrUndefined:" + name);
        }
    }
    static throwIfNull(param, name) {
        if (param === null) {
            throw new Error("throwIfNull:" + name);
        }
    }
    static throwIfNullOrWhitespace(param, name) {
        Contracts.throwIfNullOrUndefined(param, name);
        if (("" + param).trim().length < 1) {
            throw new Error("throwIfNullOrWhitespace:" + name);
        }
    }
    static throwIfDisposed(isDisposed) {
        if (isDisposed) {
            throw new Error("the object is already disposed");
        }
    }
    static throwIfArrayEmptyOrWhitespace(array, name) {
        Contracts.throwIfNullOrUndefined(array, name);
        if (array.length === 0) {
            throw new Error("throwIfArrayEmptyOrWhitespace:" + name);
        }
        for (const item of array) {
            Contracts.throwIfNullOrWhitespace(item, name);
        }
    }
    static throwIfFileDoesNotExist(param, name) {
        Contracts.throwIfNullOrWhitespace(param, name);
        // TODO check for file existence.
    }
    static throwIfNotUndefined(param, name) {
        if (param !== undefined) {
            throw new Error("throwIfNotUndefined:" + name);
        }
    }
}

//# sourceMappingURL=Contracts.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: ConversationTranscriptionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionCanceledEventArgs", function() { return ConversationTranscriptionCanceledEventArgs; });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines content of a RecognitionErrorEvent.
 * @class ConversationTranscriptionCanceledEventArgs
 */
class ConversationTranscriptionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__["CancellationEventArgsBase"] {
}

//# sourceMappingURL=ConversationTranscriptionCanceledEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js ***!
  \************************************************************************************************************/
/*! exports provided: CustomCommandsConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "CustomCommandsConfig", function() { return CustomCommandsConfig; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.
 * @class CustomCommandsConfig
 */
class CustomCommandsConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"] {
    /**
     * Creates an instance of CustomCommandsConfig.
     */
    constructor() {
        super();
    }
    /**
     * Creates an instance of the bot framework config with the specified subscription and region.
     * @member CustomCommandsConfig.fromSubscription
     * @function
     * @public
     * @param applicationId Speech Commands application id.
     * @param subscription Subscription key associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {CustomCommandsConfig} A new bot framework config.
     */
    static fromSubscription(applicationId, subscription, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(applicationId, "applicationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(subscription, "subscription");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.CustomCommands);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, applicationId);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscription);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        return customCommandsConfig;
    }
    /**
     * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     * expires, the caller needs to refresh it by calling this setter with a new valid token.
     * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member CustomCommandsConfig.fromAuthorizationToken
     * @function
     * @public
     * @param applicationId Speech Commands application id.
     * @param authorizationToken The authorization token associated with the application.
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {CustomCommandsConfig} A new speech commands config.
     */
    static fromAuthorizationToken(applicationId, authorizationToken, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(applicationId, "applicationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfigImpl"]();
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__["DialogServiceConfig"].DialogTypes.CustomCommands);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, applicationId);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, authorizationToken);
        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        return customCommandsConfig;
    }
    /**
     * Sets the corresponding backend application identifier.
     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to set.
     */
    set applicationId(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(value, "value");
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId, value);
    }
    /**
     * Gets the corresponding backend application identifier.
     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to get.
     */
    get applicationId() {
        return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].Conversation_ApplicationId);
    }
}

//# sourceMappingURL=CustomCommandsConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js ***!
  \***********************************************************************************************************/
/*! exports provided: DialogServiceConfig, DialogServiceConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConfig", function() { return DialogServiceConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConfigImpl", function() { return DialogServiceConfigImpl; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var _a;


/**
 * Class that defines base configurations for dialog service connector
 * @class DialogServiceConfig
 */
class DialogServiceConfig {
    /**
     * Creates an instance of DialogService config.
     * @constructor
     */
    constructor() { }
    /**
     * Sets the corresponding backend application identifier.
     * @member DialogServiceConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to set.
     */
    // tslint:disable-next-line: no-empty
    set applicationId(value) { }
}
DialogServiceConfig.DialogTypes = (_a = class {
    },
    _a.BotFramework = "bot_framework",
    _a.CustomCommands = "custom_commands",
    _a);
/**
 * Dialog Service configuration.
 * @class DialogServiceConfigImpl
 */
// tslint:disable-next-line:max-classes-per-file
class DialogServiceConfigImpl extends DialogServiceConfig {
    /**
     * Creates an instance of dialogService config.
     */
    constructor() {
        super();
        this.privSpeechConfig = new _Exports__WEBPACK_IMPORTED_MODULE_1__["SpeechConfigImpl"]();
    }
    /**
     * Provides access to custom properties.
     * @member DialogServiceConfigImpl.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The properties.
     */
    get properties() {
        return this.privSpeechConfig.properties;
    }
    /**
     * Gets the speech recognition language.
     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     */
    get speechRecognitionLanguage() {
        return this.privSpeechConfig.speechRecognitionLanguage;
    }
    /**
     * Sets the speech recognition language.
     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @param {string} value - The language to set.
     */
    set speechRecognitionLanguage(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(value, "value");
        this.privSpeechConfig.speechRecognitionLanguage = value;
    }
    get outputFormat() {
        return this.privSpeechConfig.outputFormat;
    }
    set outputFormat(value) {
        this.privSpeechConfig.outputFormat = value;
    }
    /**
     * Sets a named property as value
     * @member DialogServiceConfigImpl.prototype.setProperty
     * @function
     * @public
     * @param {PropertyId | string} name - The property to set.
     * @param {string} value - The value.
     */
    setProperty(name, value) {
        this.privSpeechConfig.setProperty(name, value);
    }
    /**
     * Sets a named property as value
     * @member DialogServiceConfigImpl.prototype.getProperty
     * @function
     * @public
     * @param {PropertyId | string} name - The property to get.
     * @param {string} def - The default value to return in case the property is not known.
     * @returns {string} The current value, or provided default, of the given property.
     */
    getProperty(name, def) {
        return this.privSpeechConfig.getProperty(name);
    }
    /**
     * Sets the proxy configuration.
     * Only relevant in Node.js environments.
     * Added in version 1.4.0.
     * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
     * @param proxyPort The port number of the proxy server.
     * @param proxyUserName The user name of the proxy server.
     * @param proxyPassword The password of the proxy server.
     */
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_ProxyHostName, proxyHostName);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_ProxyPort, `${proxyPort}`);
        if (proxyUserName) {
            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_ProxyUserName, proxyUserName);
        }
        if (proxyPassword) {
            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceConnection_ProxyPassword, proxyPassword);
        }
    }
    setServiceProperty(name, value, channel) {
        this.privSpeechConfig.setServiceProperty(name, value, channel);
    }
    /**
     * Dispose of associated resources.
     * @member DialogServiceConfigImpl.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
}

//# sourceMappingURL=DialogServiceConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js ***!
  \**************************************************************************************************************/
/*! exports provided: DialogServiceConnector */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConnector", function() { return DialogServiceConnector; });
/* harmony import */ var _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/DialogConnectorFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};






/**
 * Dialog Service Connector
 * @class DialogServiceConnector
 */
class DialogServiceConnector extends _Exports__WEBPACK_IMPORTED_MODULE_4__["Recognizer"] {
    /**
     * Initializes an instance of the DialogServiceConnector.
     * @constructor
     * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.
     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
     */
    constructor(dialogConfig, audioConfig) {
        const dialogServiceConfigImpl = dialogConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNull(dialogConfig, "dialogConfig");
        super(audioConfig, dialogServiceConfigImpl.properties, new _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_0__["DialogConnectionFactory"]());
        this.isTurnComplete = true;
        this.privIsDisposed = false;
        this.privProperties = dialogServiceConfigImpl.properties.clone();
        const agentConfig = this.buildAgentConfig();
        this.privReco.agentConfig.set(agentConfig);
    }
    /**
     * Starts a connection to the service.
     * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.
     *
     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
     * be notified when the connection is established.
     * @member DialogServiceConnector.prototype.connect
     * @function
     * @public
     */
    connect(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["marshalPromiseToCallbacks"])(this.privReco.connect(), cb, err);
    }
    /**
     * Closes the connection the service.
     * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.
     *
     * If disconnect() is called during a recognition, recognition will fail and cancel with an error.
     */
    disconnect(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["marshalPromiseToCallbacks"])(this.privReco.disconnect(), cb, err);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member DialogServiceConnector.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Sets the authorization token used to communicate with the service.
     * @member DialogServiceConnector.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this DialogServiceConnector.
     * @member DialogServiceConnector.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.
     */
    get properties() {
        return this.privProperties;
    }
    /** Gets the template for the activity generated by service from speech.
     * Properties from the template will be stamped on the generated activity.
     * It can be empty
     */
    get speechActivityTemplate() {
        return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].Conversation_Speech_Activity_Template);
    }
    /** Sets the template for the activity generated by service from speech.
     * Properties from the template will be stamped on the generated activity.
     * It can be null or empty.
     * Note: it has to be a valid Json object.
     */
    set speechActivityTemplate(speechActivityTemplate) {
        this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].Conversation_Speech_Activity_Template, speechActivityTemplate);
    }
    /**
     * Starts recognition and stops after the first utterance is recognized.
     * @member DialogServiceConnector.prototype.listenOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the result when the reco has completed.
     * @param err - Callback invoked in case of an error.
     */
    listenOnceAsync(cb, err) {
        if (this.isTurnComplete) {
            _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privIsDisposed);
            const callbackHolder = () => __awaiter(this, void 0, void 0, function* () {
                yield this.privReco.connect();
                yield this.implRecognizerStop();
                this.isTurnComplete = false;
                const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__["Deferred"]();
                yield this.privReco.recognize(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["RecognitionMode"].Conversation, ret.resolve, ret.reject);
                const e = yield ret.promise;
                yield this.implRecognizerStop();
                return e;
            });
            const retPromise = callbackHolder();
            retPromise.catch(() => {
                // Destroy the recognizer.
                /* tslint:disable:no-empty */ // We've done all we can here.
                this.dispose(true).catch(() => { });
            });
            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["marshalPromiseToCallbacks"])(retPromise.finally(() => {
                this.isTurnComplete = true;
            }), cb, err);
        }
    }
    sendActivityAsync(activity, cb, errCb) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["marshalPromiseToCallbacks"])(this.privReco.sendMessage(activity), cb, errCb);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member DialogServiceConnector.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privIsDisposed);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__["marshalPromiseToCallbacks"])(this.dispose(true), cb, err);
    }
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privIsDisposed) {
                return;
            }
            if (disposing) {
                this.privIsDisposed = true;
                yield this.implRecognizerStop();
                yield _super.dispose.call(this, disposing);
            }
        });
    }
    createRecognizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["RecognizerConfig"](speechConfig, this.privProperties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const audioSource = audioConfig;
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__["DialogServiceAdapter"](authentication, connectionFactory, audioSource, recognizerConfig, this);
    }
    buildAgentConfig() {
        const communicationType = this.properties.getProperty("Conversation_Communication_Type", "Default");
        return {
            botInfo: {
                commType: communicationType,
                commandsCulture: undefined,
                connectionId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].Conversation_Agent_Connection_Id),
                conversationId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].Conversation_Conversation_Id, undefined),
                fromId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].Conversation_From_Id, undefined),
                ttsAudioFormat: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, undefined)
            },
            version: 0.2
        };
    }
}

//# sourceMappingURL=DialogServiceConnector.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js ***!
  \***********************************************************************************************/
/*! exports provided: AudioConfig, AudioStreamFormat, AudioInputStream, PullAudioInputStream, PushAudioInputStream, AudioOutputStream, PullAudioOutputStream, PushAudioOutputStream, CancellationReason, PullAudioInputStreamCallback, PushAudioOutputStreamCallback, KeywordRecognitionModel, SessionEventArgs, RecognitionEventArgs, OutputFormat, IntentRecognitionEventArgs, RecognitionResult, SpeechRecognitionResult, IntentRecognitionResult, LanguageUnderstandingModel, SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs, SpeechRecognitionCanceledEventArgs, TranslationRecognitionEventArgs, TranslationSynthesisEventArgs, TranslationRecognitionResult, TranslationSynthesisResult, ResultReason, SpeechConfig, SpeechConfigImpl, SpeechTranslationConfig, SpeechTranslationConfigImpl, PropertyCollection, PropertyId, Recognizer, SpeechRecognizer, IntentRecognizer, VoiceProfileType, TranslationRecognizer, Translations, NoMatchReason, NoMatchDetails, TranslationRecognitionCanceledEventArgs, IntentRecognitionCanceledEventArgs, CancellationDetailsBase, CancellationDetails, CancellationErrorCode, ConnectionEventArgs, ServiceEventArgs, Connection, PhraseListGrammar, DialogServiceConfig, BotFrameworkConfig, CustomCommandsConfig, DialogServiceConnector, ActivityReceivedEventArgs, TurnStatusReceivedEventArgs, ServicePropertyChannel, ProfanityOption, BaseAudioPlayer, ConnectionMessageEventArgs, ConnectionMessage, VoiceProfile, VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails, VoiceProfileResult, VoiceProfileCancellationDetails, VoiceProfilePhraseResult, VoiceProfileClient, SpeakerRecognizer, SpeakerIdentificationModel, SpeakerVerificationModel, AutoDetectSourceLanguageConfig, AutoDetectSourceLanguageResult, SourceLanguageConfig, SpeakerRecognitionResult, SpeakerRecognitionResultType, SpeakerRecognitionCancellationDetails, Conversation, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, ParticipantChangedReason, User, SpeechSynthesisOutputFormat, SpeechSynthesizer, SpeechSynthesisResult, SpeechSynthesisEventArgs, SpeechSynthesisWordBoundaryEventArgs, SpeechSynthesisBookmarkEventArgs, SpeechSynthesisVisemeEventArgs, SpeakerAudioDestination, ConversationTranscriptionCanceledEventArgs, PronunciationAssessmentGradingSystem, PronunciationAssessmentGranularity, PronunciationAssessmentConfig, PronunciationAssessmentResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Audio/AudioConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioConfig", function() { return _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__["AudioConfig"]; });

/* harmony import */ var _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioStreamFormat", function() { return _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__["AudioStreamFormat"]; });

/* harmony import */ var _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioInputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioInputStream", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__["AudioInputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStream", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__["PullAudioInputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioInputStream", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__["PushAudioInputStream"]; });

/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AudioOutputStream", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__["AudioOutputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioOutputStream", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__["PullAudioOutputStream"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStream", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__["PushAudioOutputStream"]; });

/* harmony import */ var _CancellationReason__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./CancellationReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationReason", function() { return _CancellationReason__WEBPACK_IMPORTED_MODULE_4__["CancellationReason"]; });

/* harmony import */ var _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PullAudioInputStreamCallback", function() { return _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__["PullAudioInputStreamCallback"]; });

/* harmony import */ var _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PushAudioOutputStreamCallback", function() { return _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__["PushAudioOutputStreamCallback"]; });

/* harmony import */ var _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./KeywordRecognitionModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "KeywordRecognitionModel", function() { return _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__["KeywordRecognitionModel"]; });

/* harmony import */ var _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SessionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SessionEventArgs", function() { return _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__["SessionEventArgs"]; });

/* harmony import */ var _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionEventArgs", function() { return _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__["RecognitionEventArgs"]; });

/* harmony import */ var _OutputFormat__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./OutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "OutputFormat", function() { return _OutputFormat__WEBPACK_IMPORTED_MODULE_10__["OutputFormat"]; });

/* harmony import */ var _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IntentRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionEventArgs", function() { return _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__["IntentRecognitionEventArgs"]; });

/* harmony import */ var _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./RecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RecognitionResult", function() { return _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__["RecognitionResult"]; });

/* harmony import */ var _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionResult", function() { return _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__["SpeechRecognitionResult"]; });

/* harmony import */ var _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IntentRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionResult", function() { return _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__["IntentRecognitionResult"]; });

/* harmony import */ var _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./LanguageUnderstandingModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "LanguageUnderstandingModel", function() { return _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__["LanguageUnderstandingModel"]; });

/* harmony import */ var _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./SpeechRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionEventArgs", function() { return _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__["SpeechRecognitionEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionEventArgs", function() { return _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__["ConversationTranscriptionEventArgs"]; });

/* harmony import */ var _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionCanceledEventArgs", function() { return _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__["SpeechRecognitionCanceledEventArgs"]; });

/* harmony import */ var _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./TranslationRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionEventArgs", function() { return _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__["TranslationRecognitionEventArgs"]; });

/* harmony import */ var _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./TranslationSynthesisEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisEventArgs", function() { return _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__["TranslationSynthesisEventArgs"]; });

/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionResult", function() { return _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__["TranslationRecognitionResult"]; });

/* harmony import */ var _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./TranslationSynthesisResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisResult", function() { return _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__["TranslationSynthesisResult"]; });

/* harmony import */ var _ResultReason__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ResultReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ResultReason", function() { return _ResultReason__WEBPACK_IMPORTED_MODULE_22__["ResultReason"]; });

/* harmony import */ var _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./SpeechConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechConfig", function() { return _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__["SpeechConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechConfigImpl", function() { return _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__["SpeechConfigImpl"]; });

/* harmony import */ var _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechTranslationConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfig", function() { return _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__["SpeechTranslationConfig"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfigImpl", function() { return _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__["SpeechTranslationConfigImpl"]; });

/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./PropertyCollection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PropertyCollection", function() { return _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__["PropertyCollection"]; });

/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PropertyId", function() { return _PropertyId__WEBPACK_IMPORTED_MODULE_26__["PropertyId"]; });

/* harmony import */ var _Recognizer__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./Recognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Recognizer", function() { return _Recognizer__WEBPACK_IMPORTED_MODULE_27__["Recognizer"]; });

/* harmony import */ var _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./SpeechRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognizer", function() { return _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__["SpeechRecognizer"]; });

/* harmony import */ var _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognizer", function() { return _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__["IntentRecognizer"]; });

/* harmony import */ var _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./VoiceProfileType */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileType", function() { return _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__["VoiceProfileType"]; });

/* harmony import */ var _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./TranslationRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognizer", function() { return _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__["TranslationRecognizer"]; });

/* harmony import */ var _Translations__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./Translations */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Translations", function() { return _Translations__WEBPACK_IMPORTED_MODULE_32__["Translations"]; });

/* harmony import */ var _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./NoMatchReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "NoMatchReason", function() { return _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__["NoMatchReason"]; });

/* harmony import */ var _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./NoMatchDetails */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "NoMatchDetails", function() { return _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__["NoMatchDetails"]; });

/* harmony import */ var _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionCanceledEventArgs", function() { return _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__["TranslationRecognitionCanceledEventArgs"]; });

/* harmony import */ var _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./IntentRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionCanceledEventArgs", function() { return _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__["IntentRecognitionCanceledEventArgs"]; });

/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./CancellationDetailsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationDetailsBase", function() { return _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__["CancellationDetailsBase"]; });

/* harmony import */ var _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./CancellationDetails */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationDetails", function() { return _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__["CancellationDetails"]; });

/* harmony import */ var _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./CancellationErrorCodes */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CancellationErrorCode", function() { return _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__["CancellationErrorCode"]; });

/* harmony import */ var _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./ConnectionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionEventArgs", function() { return _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__["ConnectionEventArgs"]; });

/* harmony import */ var _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./ServiceEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServiceEventArgs", function() { return _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__["ServiceEventArgs"]; });

/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./Connection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Connection", function() { return _Connection__WEBPACK_IMPORTED_MODULE_42__["Connection"]; });

/* harmony import */ var _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./PhraseListGrammar */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PhraseListGrammar", function() { return _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__["PhraseListGrammar"]; });

/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConfig", function() { return _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__["DialogServiceConfig"]; });

/* harmony import */ var _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./BotFrameworkConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BotFrameworkConfig", function() { return _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__["BotFrameworkConfig"]; });

/* harmony import */ var _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./CustomCommandsConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CustomCommandsConfig", function() { return _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__["CustomCommandsConfig"]; });

/* harmony import */ var _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./DialogServiceConnector */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DialogServiceConnector", function() { return _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__["DialogServiceConnector"]; });

/* harmony import */ var _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./ActivityReceivedEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ActivityReceivedEventArgs", function() { return _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__["ActivityReceivedEventArgs"]; });

/* harmony import */ var _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./TurnStatusReceivedEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TurnStatusReceivedEventArgs", function() { return _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__["TurnStatusReceivedEventArgs"]; });

/* harmony import */ var _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./ServicePropertyChannel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ServicePropertyChannel", function() { return _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__["ServicePropertyChannel"]; });

/* harmony import */ var _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./ProfanityOption */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ProfanityOption", function() { return _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__["ProfanityOption"]; });

/* harmony import */ var _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./Audio/BaseAudioPlayer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "BaseAudioPlayer", function() { return _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__["BaseAudioPlayer"]; });

/* harmony import */ var _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./ConnectionMessageEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessageEventArgs", function() { return _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__["ConnectionMessageEventArgs"]; });

/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConnectionMessage", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__["ConnectionMessage"]; });

/* harmony import */ var _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./VoiceProfile */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfile", function() { return _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__["VoiceProfile"]; });

/* harmony import */ var _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./VoiceProfileEnrollmentResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentResult", function() { return _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__["VoiceProfileEnrollmentResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentCancellationDetails", function() { return _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__["VoiceProfileEnrollmentCancellationDetails"]; });

/* harmony import */ var _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./VoiceProfileResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileResult", function() { return _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__["VoiceProfileResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileCancellationDetails", function() { return _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__["VoiceProfileCancellationDetails"]; });

/* harmony import */ var _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./VoiceProfilePhraseResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfilePhraseResult", function() { return _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__["VoiceProfilePhraseResult"]; });

/* harmony import */ var _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./VoiceProfileClient */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileClient", function() { return _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__["VoiceProfileClient"]; });

/* harmony import */ var _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./SpeakerRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognizer", function() { return _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__["SpeakerRecognizer"]; });

/* harmony import */ var _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./SpeakerIdentificationModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerIdentificationModel", function() { return _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__["SpeakerIdentificationModel"]; });

/* harmony import */ var _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./SpeakerVerificationModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerVerificationModel", function() { return _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__["SpeakerVerificationModel"]; });

/* harmony import */ var _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageConfig", function() { return _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__["AutoDetectSourceLanguageConfig"]; });

/* harmony import */ var _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./AutoDetectSourceLanguageResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AutoDetectSourceLanguageResult", function() { return _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__["AutoDetectSourceLanguageResult"]; });

/* harmony import */ var _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./SourceLanguageConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SourceLanguageConfig", function() { return _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__["SourceLanguageConfig"]; });

/* harmony import */ var _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./SpeakerRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResult", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__["SpeakerRecognitionResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResultType", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__["SpeakerRecognitionResultType"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionCancellationDetails", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__["SpeakerRecognitionCancellationDetails"]; });

/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Conversation", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["Conversation"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationExpirationEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationExpirationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationParticipantsChangedEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationParticipantsChangedEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationCanceledEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationTranslationCanceledEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationEventArgs", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationTranslationEventArgs"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationResult", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationTranslationResult"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslator", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationTranslator"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriber", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ConversationTranscriber"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Participant", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["Participant"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantChangedReason", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["ParticipantChangedReason"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "User", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__["User"]; });

/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./SpeechSynthesisOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisOutputFormat", function() { return _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_68__["SpeechSynthesisOutputFormat"]; });

/* harmony import */ var _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./SpeechSynthesizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesizer", function() { return _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_69__["SpeechSynthesizer"]; });

/* harmony import */ var _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./SpeechSynthesisResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisResult", function() { return _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_70__["SpeechSynthesisResult"]; });

/* harmony import */ var _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./SpeechSynthesisEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisEventArgs", function() { return _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_71__["SpeechSynthesisEventArgs"]; });

/* harmony import */ var _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisWordBoundaryEventArgs", function() { return _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_72__["SpeechSynthesisWordBoundaryEventArgs"]; });

/* harmony import */ var _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisBookmarkEventArgs", function() { return _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_73__["SpeechSynthesisBookmarkEventArgs"]; });

/* harmony import */ var _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisVisemeEventArgs", function() { return _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_74__["SpeechSynthesisVisemeEventArgs"]; });

/* harmony import */ var _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./Audio/SpeakerAudioDestination */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SpeakerAudioDestination", function() { return _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_75__["SpeakerAudioDestination"]; });

/* harmony import */ var _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionCanceledEventArgs", function() { return _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_76__["ConversationTranscriptionCanceledEventArgs"]; });

/* harmony import */ var _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGradingSystem", function() { return _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_77__["PronunciationAssessmentGradingSystem"]; });

/* harmony import */ var _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./PronunciationAssessmentGranularity */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGranularity", function() { return _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_78__["PronunciationAssessmentGranularity"]; });

/* harmony import */ var _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./PronunciationAssessmentConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentConfig", function() { return _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_79__["PronunciationAssessmentConfig"]; });

/* harmony import */ var _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./PronunciationAssessmentResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentResult", function() { return _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_80__["PronunciationAssessmentResult"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


















































































//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/*! exports provided: IntentRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionCanceledEventArgs", function() { return IntentRecognitionCanceledEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Define payload of intent recognition canceled result events.
 * @class IntentRecognitionCanceledEventArgs
 */
class IntentRecognitionCanceledEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["IntentRecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {CancellationReason} result - The result of the intent recognition.
     * @param {string} offset - The offset.
     * @param {IntentRecognitionResult} sessionId - The session id.
     */
    constructor(reason, errorDetails, errorCode, result, offset, sessionId) {
        super(result, offset, sessionId);
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privErrorCode = errorCode;
    }
    /**
     * The reason the recognition was canceled.
     * @member IntentRecognitionCanceledEventArgs.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * The error code in case of an unsuccessful recognition.
     * Added in version 1.1.0.
     * @return An error code that represents the error reason.
     */
    get errorCode() {
        return this.privErrorCode;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
}

//# sourceMappingURL=IntentRecognitionCanceledEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: IntentRecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionEventArgs", function() { return IntentRecognitionEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Intent recognition result event arguments.
 * @class
 */
class IntentRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param result - The result of the intent recognition.
     * @param offset - The offset.
     * @param sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Represents the intent recognition result.
     * @member IntentRecognitionEventArgs.prototype.result
     * @function
     * @public
     * @returns {IntentRecognitionResult} Represents the intent recognition result.
     */
    get result() {
        return this.privResult;
    }
}

//# sourceMappingURL=IntentRecognitionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js ***!
  \***************************************************************************************************************/
/*! exports provided: IntentRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentRecognitionResult", function() { return IntentRecognitionResult; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Intent recognition result.
 * @class
 */
class IntentRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param intentId - The intent id.
     * @param resultId - The result id.
     * @param reason - The reason.
     * @param text - The recognized text.
     * @param duration - The duration.
     * @param offset - The offset into the stream.
     * @param language - Primary Language detected, if provided.
     * @param languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param errorDetails - Error details, if provided.
     * @param json - Additional Json, if provided.
     * @param properties - Additional properties, if provided.
     */
    constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);
        this.privIntentId = intentId;
    }
    /**
     * A String that represents the intent identifier being recognized.
     * @member IntentRecognitionResult.prototype.intentId
     * @function
     * @public
     * @returns {string} A String that represents the intent identifier being recognized.
     */
    get intentId() {
        return this.privIntentId;
    }
}

//# sourceMappingURL=IntentRecognitionResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js ***!
  \********************************************************************************************************/
/*! exports provided: IntentRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "IntentRecognizer", function() { return IntentRecognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Intent recognizer.
 * @class
 */
class IntentRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__["Recognizer"] {
    /**
     * Initializes an instance of the IntentRecognizer.
     * @constructor
     * @param {SpeechConfig} speechConfig - The set of configuration properties.
     * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
     */
    constructor(speechConfig, audioConfig) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(speechConfig, "speechConfig");
        const configImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(configImpl, "speechConfig");
        super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["IntentConnectionFactory"]());
        this.privAddedIntents = [];
        this.privAddedLmIntents = {};
        this.privDisposedIntentRecognizer = false;
        this.privProperties = configImpl.properties;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
    }
    /**
     * Gets the spoken language of recognition.
     * @member IntentRecognizer.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} the spoken language of recognition.
     */
    get speechRecognitionLanguage() {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedIntentRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member IntentRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.
     * @member IntentRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} value - Authorization token.
     */
    set authorizationToken(value) {
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, value);
    }
    /**
     * The collection of properties and their values defined for this IntentRecognizer.
     * @member IntentRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their
     *          values defined for this IntentRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts intent recognition, and stops after the first utterance is recognized.
     * The task returns the recognition text and intent as result.
     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
     *       so it is suitable only for single shot recognition like command or query.
     *       For long-running recognition, use StartContinuousRecognitionAsync() instead.
     * @member IntentRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedIntentRecognizer);
        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {
            const context = this.buildSpeechContext();
            this.privReco.speechContext.setSection("intent", context.Intent);
            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
            const intentReco = this.privReco;
            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
        }
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Interactive), cb, err);
    }
    /**
     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * @member IntentRecognizer.prototype.startContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startContinuousRecognitionAsync(cb, err) {
        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {
            const context = this.buildSpeechContext();
            this.privReco.speechContext.setSection("intent", context.Intent);
            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
            const intentReco = this.privReco;
            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
        }
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Conversation), cb, err);
    }
    /**
     * Stops continuous intent recognition.
     * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * Note: Key word spotting functionality is only available on the Speech Devices SDK.
     *       This functionality is currently not included in the SDK itself.
     * @member IntentRecognizer.prototype.startKeywordRecognitionAsync
     * @function
     * @public
     * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startKeywordRecognitionAsync(model, cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(model, "model");
        if (!!err) {
            err("Not yet implemented.");
        }
    }
    /**
     * Stops continuous speech recognition.
     * Note: Key word spotting functionality is only available on the Speech Devices SDK.
     *       This functionality is currently not included in the SDK itself.
     * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopKeywordRecognitionAsync(cb, err) {
        if (!!cb) {
            cb();
        }
    }
    /**
     * Adds a phrase that should be recognized as intent.
     * @member IntentRecognizer.prototype.addIntent
     * @function
     * @public
     * @param {string} intentId - A String that represents the identifier of the intent to be recognized.
     * @param {string} phrase - A String that specifies the phrase representing the intent.
     */
    addIntent(simplePhrase, intentId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedIntentRecognizer);
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(intentId, "intentId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(simplePhrase, "simplePhrase");
        this.privAddedIntents.push([intentId, simplePhrase]);
    }
    /**
     * Adds an intent from Language Understanding service for recognition.
     * @member IntentRecognizer.prototype.addIntentWithLanguageModel
     * @function
     * @public
     * @param {string} intentId - A String that represents the identifier of the intent
     *        to be recognized. Ignored if intentName is empty.
     * @param {string} model - The intent model from Language Understanding service.
     * @param {string} intentName - The intent name defined in the intent model. If it
     *        is empty, all intent names defined in the model will be added.
     */
    addIntentWithLanguageModel(intentId, model, intentName) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedIntentRecognizer);
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(intentId, "intentId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(model, "model");
        const modelImpl = model;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
        this.privAddedLmIntents[intentId] = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["AddedLmIntent"](modelImpl, intentName);
    }
    /**
     * @summary Adds all intents from the specified Language Understanding Model.
     * @member IntentRecognizer.prototype.addAllIntents
     * @function
     * @public
     * @function
     * @public
     * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.
     * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.
     */
    addAllIntents(model, intentId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(model, "model");
        const modelImpl = model;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
        this.privUmbrellaIntent = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["AddedLmIntent"](modelImpl, intentId);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member IntentRecognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedIntentRecognizer);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, errorCb);
    }
    createRecognizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognizerConfig"](speechConfig, this.properties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const audioImpl = audioConfig;
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["IntentServiceRecognizer"](authentication, connectionFactory, audioImpl, recognizerConfig, this);
    }
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposedIntentRecognizer) {
                return;
            }
            if (disposing) {
                this.privDisposedIntentRecognizer = true;
                yield _super.dispose.call(this, disposing);
            }
        });
    }
    buildSpeechContext() {
        let appId;
        let region;
        let subscriptionKey;
        const refGrammers = [];
        if (undefined !== this.privUmbrellaIntent) {
            appId = this.privUmbrellaIntent.modelImpl.appId;
            region = this.privUmbrellaIntent.modelImpl.region;
            subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;
        }
        // Build the reference grammer array.
        for (const intentId of Object.keys(this.privAddedLmIntents)) {
            const addedLmIntent = this.privAddedLmIntents[intentId];
            // validate all the same model, region, and key...
            if (appId === undefined) {
                appId = addedLmIntent.modelImpl.appId;
            }
            else {
                if (appId !== addedLmIntent.modelImpl.appId) {
                    throw new Error("Intents must all be from the same LUIS model");
                }
            }
            if (region === undefined) {
                region = addedLmIntent.modelImpl.region;
            }
            else {
                if (region !== addedLmIntent.modelImpl.region) {
                    throw new Error("Intents must all be from the same LUIS model in a single region");
                }
            }
            if (subscriptionKey === undefined) {
                subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;
            }
            else {
                if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {
                    throw new Error("Intents must all use the same subscription key");
                }
            }
            const grammer = "luis/" + appId + "-PRODUCTION#" + intentId;
            refGrammers.push(grammer);
        }
        return {
            Intent: {
                id: appId,
                key: (subscriptionKey === undefined) ? this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Key]) : subscriptionKey,
                provider: "LUIS",
            },
            ReferenceGrammars: (undefined === this.privUmbrellaIntent) ? refGrammers : ["luis/" + appId + "-PRODUCTION"],
        };
    }
}

//# sourceMappingURL=IntentRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js ***!
  \***************************************************************************************************************/
/*! exports provided: KeywordRecognitionModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "KeywordRecognitionModel", function() { return KeywordRecognitionModel; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents a keyword recognition model for recognizing when
 * the user says a keyword to initiate further speech recognition.
 * @class KeywordRecognitionModel
 */
class KeywordRecognitionModel {
    /**
     * Create and initializes a new instance.
     * @constructor
     */
    constructor() {
        this.privDisposed = false;
    }
    /**
     * Creates a keyword recognition model using the specified filename.
     * @member KeywordRecognitionModel.fromFile
     * @function
     * @public
     * @param {string} fileName - A string that represents file name for the keyword recognition model.
     *        Note, the file can point to a zip file in which case the model
     *        will be extracted from the zip.
     * @returns {KeywordRecognitionModel} The keyword recognition model being created.
     */
    static fromFile(fileName) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfFileDoesNotExist(fileName, "fileName");
        throw new Error("Not yet implemented.");
    }
    /**
     * Creates a keyword recognition model using the specified filename.
     * @member KeywordRecognitionModel.fromStream
     * @function
     * @public
     * @param {string} file - A File that represents file for the keyword recognition model.
     *        Note, the file can point to a zip file in which case the model will be extracted from the zip.
     * @returns {KeywordRecognitionModel} The keyword recognition model being created.
     */
    static fromStream(file) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNull(file, "file");
        throw new Error("Not yet implemented.");
    }
    /**
     * Dispose of associated resources.
     * @member KeywordRecognitionModel.prototype.close
     * @function
     * @public
     */
    close() {
        if (this.privDisposed) {
            return;
        }
        this.privDisposed = true;
    }
}

//# sourceMappingURL=KeywordRecognitionModel.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js ***!
  \******************************************************************************************************************/
/*! exports provided: LanguageUnderstandingModel, LanguageUnderstandingModelImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LanguageUnderstandingModel", function() { return LanguageUnderstandingModel; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "LanguageUnderstandingModelImpl", function() { return LanguageUnderstandingModelImpl; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Language understanding model
 * @class LanguageUnderstandingModel
 */
class LanguageUnderstandingModel {
    /**
     * Creates and initializes a new instance
     * @constructor
     */
    constructor() {
    }
    /**
     * Creates an language understanding model using the specified endpoint.
     * @member LanguageUnderstandingModel.fromEndpoint
     * @function
     * @public
     * @param {URL} uri - A String that represents the endpoint of the language understanding model.
     * @returns {LanguageUnderstandingModel} The language understanding model being created.
     */
    static fromEndpoint(uri) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNull(uri, "uri");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(uri.hostname, "uri");
        const langModelImp = new LanguageUnderstandingModelImpl();
        // Need to extract the app ID from the URL.
        // URL is in the format: https://<region>.api.cognitive.microsoft.com/luis/v2.0/apps/<Guid>?subscription-key=<key>&timezoneOffset=-360
        // Start tearing the string apart.
        // region can be extracted from the host name.
        const firstDot = uri.host.indexOf(".");
        if (-1 === firstDot) {
            throw new Error("Could not determine region from endpoint");
        }
        langModelImp.region = uri.host.substr(0, firstDot);
        // Now the app ID.
        const lastSegment = uri.pathname.lastIndexOf("/") + 1;
        if (-1 === lastSegment) {
            throw new Error("Could not determine appId from endpoint");
        }
        langModelImp.appId = uri.pathname.substr(lastSegment);
        // And finally the key.
        langModelImp.subscriptionKey = uri.searchParams.get("subscription-key");
        if (undefined === langModelImp.subscriptionKey) {
            throw new Error("Could not determine subscription key from endpoint");
        }
        return langModelImp;
    }
    /**
     * Creates an language understanding model using the application id of Language Understanding service.
     * @member LanguageUnderstandingModel.fromAppId
     * @function
     * @public
     * @param {string} appId - A String that represents the application id of Language Understanding service.
     * @returns {LanguageUnderstandingModel} The language understanding model being created.
     */
    static fromAppId(appId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(appId, "appId");
        const langModelImp = new LanguageUnderstandingModelImpl();
        langModelImp.appId = appId;
        return langModelImp;
    }
    /**
     * Creates a language understanding model using hostname, subscription key and application
     * id of Language Understanding service.
     * @member LanguageUnderstandingModel.fromSubscription
     * @function
     * @public
     * @param {string} subscriptionKey - A String that represents the subscription key of
     *        Language Understanding service.
     * @param {string} appId - A String that represents the application id of Language
     *        Understanding service.
     * @param {LanguageUnderstandingModel} region - A String that represents the region
     *        of the Language Understanding service (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {LanguageUnderstandingModel} The language understanding model being created.
     */
    static fromSubscription(subscriptionKey, appId, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(appId, "appId");
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const langModelImp = new LanguageUnderstandingModelImpl();
        langModelImp.appId = appId;
        langModelImp.region = region;
        langModelImp.subscriptionKey = subscriptionKey;
        return langModelImp;
    }
}
/**
 * @private
 * @class LanguageUnderstandingModelImpl
 */
// tslint:disable-next-line:max-classes-per-file
class LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {
}

//# sourceMappingURL=LanguageUnderstandingModel.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js ***!
  \******************************************************************************************************/
/*! exports provided: NoMatchDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NoMatchDetails", function() { return NoMatchDetails; });
/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../src/common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Contains detailed information for NoMatch recognition results.
 * @class NoMatchDetails
 */
class NoMatchDetails {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {NoMatchReason} reason - The no-match reason.
     */
    constructor(reason) {
        this.privReason = reason;
    }
    /**
     * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.
     * @member NoMatchDetails.fromResult
     * @function
     * @public
     * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}
     *        result - The recognition result that was not recognized.
     * @returns {NoMatchDetails} The no match details object being created.
     */
    static fromResult(result) {
        const simpleSpeech = _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SimpleSpeechPhrase"].fromJSON(result.json);
        let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__["NoMatchReason"].NotRecognized;
        switch (simpleSpeech.RecognitionStatus) {
            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionStatus"].BabbleTimeout:
                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__["NoMatchReason"].InitialBabbleTimeout;
                break;
            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionStatus"].InitialSilenceTimeout:
                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__["NoMatchReason"].InitialSilenceTimeout;
                break;
            default:
                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__["NoMatchReason"].NotRecognized;
                break;
        }
        return new NoMatchDetails(reason);
    }
    /**
     * The reason the recognition was canceled.
     * @member NoMatchDetails.prototype.reason
     * @function
     * @public
     * @returns {NoMatchReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
}

//# sourceMappingURL=NoMatchDetails.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js ***!
  \*****************************************************************************************************/
/*! exports provided: NoMatchReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "NoMatchReason", function() { return NoMatchReason; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might not be recognized.
 * @class NoMatchReason
 */
var NoMatchReason;
(function (NoMatchReason) {
    /**
     * Indicates that speech was detected, but not recognized.
     * @member NoMatchReason.NotRecognized
     */
    NoMatchReason[NoMatchReason["NotRecognized"] = 0] = "NotRecognized";
    /**
     * Indicates that the start of the audio stream contained only silence,
     * and the service timed out waiting for speech.
     * @member NoMatchReason.InitialSilenceTimeout
     */
    NoMatchReason[NoMatchReason["InitialSilenceTimeout"] = 1] = "InitialSilenceTimeout";
    /**
     * Indicates that the start of the audio stream contained only noise,
     * and the service timed out waiting for speech.
     * @member NoMatchReason.InitialBabbleTimeout
     */
    NoMatchReason[NoMatchReason["InitialBabbleTimeout"] = 2] = "InitialBabbleTimeout";
})(NoMatchReason || (NoMatchReason = {}));

//# sourceMappingURL=NoMatchReason.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js ***!
  \****************************************************************************************************/
/*! exports provided: OutputFormat */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OutputFormat", function() { return OutputFormat; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define Speech Recognizer output formats.
 * @class OutputFormat
 */
var OutputFormat;
(function (OutputFormat) {
    /**
     * @member OutputFormat.Simple
     */
    OutputFormat[OutputFormat["Simple"] = 0] = "Simple";
    /**
     * @member OutputFormat.Detailed
     */
    OutputFormat[OutputFormat["Detailed"] = 1] = "Detailed";
})(OutputFormat || (OutputFormat = {}));

//# sourceMappingURL=OutputFormat.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js ***!
  \*********************************************************************************************************/
/*! exports provided: PhraseListGrammar */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PhraseListGrammar", function() { return PhraseListGrammar; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Allows additions of new phrases to improve speech recognition.
 *
 * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect
 * to the speech service.
 */
class PhraseListGrammar {
    constructor(recogBase) {
        this.privGrammerBuilder = recogBase.dynamicGrammar;
    }
    /**
     * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.
     * @param recognizer The recognizer to add phrase lists to.
     */
    static fromRecognizer(recognizer) {
        const recoBase = recognizer.internalData;
        return new PhraseListGrammar(recoBase);
    }
    /**
     * Adds a single phrase to the current recognizer.
     * @param phrase Phrase to add.
     */
    addPhrase(phrase) {
        this.privGrammerBuilder.addPhrase(phrase);
    }
    /**
     * Adds multiple phrases to the current recognizer.
     * @param phrases Array of phrases to add.
     */
    addPhrases(phrases) {
        this.privGrammerBuilder.addPhrase(phrases);
    }
    /**
     * Clears all phrases added to the current recognizer.
     */
    clear() {
        this.privGrammerBuilder.clearPhrases();
    }
}

//# sourceMappingURL=PhraseListGrammar.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js ***!
  \*******************************************************************************************************/
/*! exports provided: ProfanityOption */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ProfanityOption", function() { return ProfanityOption; });
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Profanity option.
 * Added in version 1.7.0.
 */
var ProfanityOption;
(function (ProfanityOption) {
    ProfanityOption[ProfanityOption["Masked"] = 0] = "Masked";
    ProfanityOption[ProfanityOption["Removed"] = 1] = "Removed";
    ProfanityOption[ProfanityOption["Raw"] = 2] = "Raw";
})(ProfanityOption || (ProfanityOption = {}));

//# sourceMappingURL=ProfanityOption.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js ***!
  \*********************************************************************************************************************/
/*! exports provided: PronunciationAssessmentConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentConfig", function() { return PronunciationAssessmentConfig; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Pronunciation assessment configuration.
 * @class PronunciationAssessmentConfig
 * Added in version 1.15.0.
 */
class PronunciationAssessmentConfig {
    /**
     * PronunciationAssessmentConfig constructor.
     * @constructor
     * @param {string} referenceText
     * @param gradingSystem
     * @param granularity
     * @param enableMiscue
     */
    constructor(referenceText, gradingSystem = _Exports__WEBPACK_IMPORTED_MODULE_1__["PronunciationAssessmentGradingSystem"].FivePoint, granularity = _Exports__WEBPACK_IMPORTED_MODULE_1__["PronunciationAssessmentGranularity"].Phoneme, enableMiscue = false) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(referenceText, "referenceText");
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_ReferenceText, referenceText);
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_GradingSystem, _Exports__WEBPACK_IMPORTED_MODULE_1__["PronunciationAssessmentGradingSystem"][gradingSystem]);
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Granularity, _Exports__WEBPACK_IMPORTED_MODULE_1__["PronunciationAssessmentGranularity"][granularity]);
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_EnableMiscue, String(enableMiscue));
    }
    /**
     * @member PronunciationAssessmentConfig.fromJSON
     * @function
     * @public
     * @param {string} json The json string containing the pronunciation assessment parameters.
     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
     * @summary Creates an instance of the PronunciationAssessmentConfig from json.
     */
    static fromJSON(json) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(json, "json");
        const config = new PronunciationAssessmentConfig("");
        config.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Json, json);
        return config;
    }
    toJSON() {
        this.updateJson();
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Params);
    }
    applyTo(recognizer) {
        this.updateJson();
        const recoBase = recognizer.internalData;
        recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Params));
    }
    /**
     * Gets the reference text.
     * @member PronunciationAssessmentConfig.prototype.referenceText
     * @function
     * @public
     * @returns {string} Reference text.
     */
    get referenceText() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_ReferenceText);
    }
    /**
     * Gets/Sets the reference text.
     * @member PronunciationAssessmentConfig.prototype.referenceText
     * @function
     * @public
     * @param {string} referenceText - Reference text.
     */
    set referenceText(referenceText) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrWhitespace(referenceText, "referenceText");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_ReferenceText, referenceText);
    }
    /**
     * @member PronunciationAssessmentConfig.prototype.properties
     * @function
     * @public
     * @return {PropertyCollection} Properties of the config.
     * @summary Gets a pronunciation assessment config properties
     */
    get properties() {
        return this.privProperties;
    }
    updateJson() {
        const jsonString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Json, "{}");
        const paramsJson = JSON.parse(jsonString);
        const referenceText = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_ReferenceText);
        if (referenceText) {
            paramsJson.referenceText = referenceText;
        }
        const gradingSystem = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_GradingSystem);
        if (gradingSystem) {
            paramsJson.gradingSystem = gradingSystem;
        }
        const granularity = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Granularity);
        if (granularity) {
            paramsJson.granularity = granularity;
        }
        // always set dimension to Comprehensive
        paramsJson.dimension = "Comprehensive";
        const enableMiscueString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_EnableMiscue);
        if (enableMiscueString === "true") {
            paramsJson.enableMiscue = true;
        }
        else if (enableMiscueString === "false") {
            paramsJson.enableMiscue = false;
        }
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].PronunciationAssessment_Params, JSON.stringify(paramsJson));
    }
}

//# sourceMappingURL=PronunciationAssessmentConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \****************************************************************************************************************************/
/*! exports provided: PronunciationAssessmentGradingSystem */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGradingSystem", function() { return PronunciationAssessmentGradingSystem; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the point system for pronunciation score calibration; default value is FivePoint.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGradingSystem
 */
var PronunciationAssessmentGradingSystem;
(function (PronunciationAssessmentGradingSystem) {
    /**
     * Five point calibration
     * @member PronunciationAssessmentGradingSystem.FivePoint
     */
    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["FivePoint"] = 1] = "FivePoint";
    /**
     * Hundred mark
     * @member PronunciationAssessmentGradingSystem.HundredMark
     */
    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["HundredMark"] = 2] = "HundredMark";
})(PronunciationAssessmentGradingSystem || (PronunciationAssessmentGradingSystem = {}));

//# sourceMappingURL=PronunciationAssessmentGradingSystem.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js ***!
  \**************************************************************************************************************************/
/*! exports provided: PronunciationAssessmentGranularity */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentGranularity", function() { return PronunciationAssessmentGranularity; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the pronunciation evaluation granularity; default value is Phoneme.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGranularity
 */
var PronunciationAssessmentGranularity;
(function (PronunciationAssessmentGranularity) {
    /**
     * Shows the score on the full text, word and phoneme level
     * @member PronunciationAssessmentGranularity.Phoneme
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Phoneme"] = 1] = "Phoneme";
    /**
     * Shows the score on the full text and word level
     * @member PronunciationAssessmentGranularity.Word
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Word"] = 2] = "Word";
    /**
     * Shows the score on the full text level only
     * @member PronunciationAssessmentGranularity.FullText
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["FullText"] = 3] = "FullText";
})(PronunciationAssessmentGranularity || (PronunciationAssessmentGranularity = {}));

//# sourceMappingURL=PronunciationAssessmentGranularity.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js ***!
  \*********************************************************************************************************************/
/*! exports provided: PronunciationAssessmentResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PronunciationAssessmentResult", function() { return PronunciationAssessmentResult; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Pronunciation assessment results.
 * @class PronunciationAssessmentResult
 * Added in version 1.15.0.
 */
class PronunciationAssessmentResult {
    constructor(jsonString) {
        const j = JSON.parse(jsonString);
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(j.NBest[0], "NBest");
        this.privPronJson = j.NBest[0];
    }
    /**
     * @member PronunciationAssessmentResult.fromResult
     * @function
     * @public
     * @param {RecognitionResult} result The recognition result.
     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
     * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.
     */
    static fromResult(result) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(result, "result");
        const json = result.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyId"].SpeechServiceResponse_JsonResult);
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(json, "json");
        return new PronunciationAssessmentResult(json);
    }
    /**
     * Gets the detail result of pronunciation assessment.
     * @member PronunciationAssessmentConfig.prototype.detailResult
     * @function
     * @public
     * @returns {any} detail result.
     */
    get detailResult() {
        return this.privPronJson;
    }
    /**
     * The score indicating the pronunciation accuracy of the given speech, which indicates
     * how closely the phonemes match a native speaker's pronunciation.
     * @member PronunciationAssessmentResult.prototype.accuracyScore
     * @function
     * @public
     * @returns {number} Accuracy score.
     */
    get accuracyScore() {
        return this.detailResult.PronunciationAssessment.AccuracyScore;
    }
    /**
     * The overall score indicating the pronunciation quality of the given speech.
     * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.
     * @member PronunciationAssessmentResult.prototype.pronunciationScore
     * @function
     * @public
     * @returns {number} Pronunciation score.
     */
    get pronunciationScore() {
        return this.detailResult.PronunciationAssessment.PronScore;
    }
    /**
     * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.
     * @member PronunciationAssessmentResult.prototype.completenessScore
     * @function
     * @public
     * @returns {number} Completeness score.
     */
    get completenessScore() {
        return this.detailResult.PronunciationAssessment.CompletenessScore;
    }
    /**
     * The score indicating the fluency of the given speech.
     * @member PronunciationAssessmentResult.prototype.fluencyScore
     * @function
     * @public
     * @returns {number} Fluency score.
     */
    get fluencyScore() {
        return this.detailResult.PronunciationAssessment.FluencyScore;
    }
}

//# sourceMappingURL=PronunciationAssessmentResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js ***!
  \**********************************************************************************************************/
/*! exports provided: PropertyCollection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PropertyCollection", function() { return PropertyCollection; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents collection of properties and their values.
 * @class PropertyCollection
 */
class PropertyCollection {
    constructor() {
        this.privKeys = [];
        this.privValues = [];
    }
    /**
     * Returns the property value in type String. The parameter must have the same type as String.
     * Currently only String, int and bool are allowed.
     * If the name is not available, the specified defaultValue is returned.
     * @member PropertyCollection.prototype.getProperty
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} def - The default value which is returned if the parameter
     *        is not available in the collection.
     * @returns {string} value of the parameter.
     */
    getProperty(key, def) {
        let keyToUse;
        if (typeof key === "string") {
            keyToUse = key;
        }
        else {
            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"][key];
        }
        for (let n = 0; n < this.privKeys.length; n++) {
            if (this.privKeys[n] === keyToUse) {
                return this.privValues[n];
            }
        }
        return def;
    }
    /**
     * Sets the String value of the parameter specified by name.
     * @member PropertyCollection.prototype.setProperty
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} value - The value of the parameter.
     */
    setProperty(key, value) {
        let keyToUse;
        if (typeof key === "string") {
            keyToUse = key;
        }
        else {
            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyId"][key];
        }
        for (let n = 0; n < this.privKeys.length; n++) {
            if (this.privKeys[n] === keyToUse) {
                this.privValues[n] = value;
                return;
            }
        }
        this.privKeys.push(keyToUse);
        this.privValues.push(value);
    }
    /**
     * Clones the collection.
     * @member PropertyCollection.prototype.clone
     * @function
     * @public
     * @returns {PropertyCollection} A copy of the collection.
     */
    clone() {
        const clonedMap = new PropertyCollection();
        for (let n = 0; n < this.privKeys.length; n++) {
            clonedMap.privKeys.push(this.privKeys[n]);
            clonedMap.privValues.push(this.privValues[n]);
        }
        return clonedMap;
    }
    /**
     * Merges this set of properties into another, no overwrites.
     * @member PropertyCollection.prototype.mergeTo
     * @function
     * @public
     * @param {PropertyCollection} The collection to merge into.
     */
    mergeTo(destinationCollection) {
        this.privKeys.forEach((key) => {
            if (destinationCollection.getProperty(key, undefined) === undefined) {
                const value = this.getProperty(key);
                destinationCollection.setProperty(key, value);
            }
        });
    }
    /**
     * Get the keys in Property Collection.
     * @member PropertyCollection.prototype.keys
     * @function
     * @public
     * @returns {string []} Keys in the collection.
     */
    get keys() {
        return this.privKeys;
    }
}

//# sourceMappingURL=PropertyCollection.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js ***!
  \**************************************************************************************************/
/*! exports provided: PropertyId */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PropertyId", function() { return PropertyId; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines speech property ids.
 * @class PropertyId
 */
var PropertyId;
(function (PropertyId) {
    /**
     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to specify
     * to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.fromSubscription]].
     * @member PropertyId.SpeechServiceConnection_Key
     */
    PropertyId[PropertyId["SpeechServiceConnection_Key"] = 0] = "SpeechServiceConnection_Key";
    /**
     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.fromEndpoint]].
     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
     * @member PropertyId.SpeechServiceConnection_Endpoint
     */
    PropertyId[PropertyId["SpeechServiceConnection_Endpoint"] = 1] = "SpeechServiceConnection_Endpoint";
    /**
     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to
     * use this property directly.
     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].
     * @member PropertyId.SpeechServiceConnection_Region
     */
    PropertyId[PropertyId["SpeechServiceConnection_Region"] = 2] = "SpeechServiceConnection_Region";
    /**
     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,
     * you shouldn't have to use this property directly.
     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],
     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].
     * @member PropertyId.SpeechServiceAuthorization_Token
     */
    PropertyId[PropertyId["SpeechServiceAuthorization_Token"] = 3] = "SpeechServiceAuthorization_Token";
    /**
     * The Cognitive Services Speech Service authorization type. Currently unused.
     * @member PropertyId.SpeechServiceAuthorization_Type
     */
    PropertyId[PropertyId["SpeechServiceAuthorization_Type"] = 4] = "SpeechServiceAuthorization_Type";
    /**
     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.endpointId]].
     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.
     * @member PropertyId.SpeechServiceConnection_EndpointId
     */
    PropertyId[PropertyId["SpeechServiceConnection_EndpointId"] = 5] = "SpeechServiceConnection_EndpointId";
    /**
     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,
     * you shouldn't have to use this property directly.
     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],
     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].
     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationToLanguages"] = 6] = "SpeechServiceConnection_TranslationToLanguages";
    /**
     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this
     * property directly.
     * Instead, use [[SpeechTranslationConfig.voiceName]].
     * NOTE: Valid voice names can be found <a href="https://aka.ms/csspeech/voicenames">here</a>.
     * @member PropertyId.SpeechServiceConnection_TranslationVoice
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationVoice"] = 7] = "SpeechServiceConnection_TranslationVoice";
    /**
     * Translation features.
     * @member PropertyId.SpeechServiceConnection_TranslationFeatures
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationFeatures"] = 8] = "SpeechServiceConnection_TranslationFeatures";
    /**
     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.
     * Instead, use [[LanguageUnderstandingModel]].
     * @member PropertyId.SpeechServiceConnection_IntentRegion
     */
    PropertyId[PropertyId["SpeechServiceConnection_IntentRegion"] = 9] = "SpeechServiceConnection_IntentRegion";
    /**
     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyHostName"] = 10] = "SpeechServiceConnection_ProxyHostName";
    /**
     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyPort"] = 11] = "SpeechServiceConnection_ProxyPort";
    /**
     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyUserName"] = 12] = "SpeechServiceConnection_ProxyUserName";
    /**
     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyPassword"] = 13] = "SpeechServiceConnection_ProxyPassword";
    /**
     * The Cognitive Services Speech Service recognition Mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION".
     * This property is intended to be read-only. The SDK is using it internally.
     * @member PropertyId.SpeechServiceConnection_RecoMode
     */
    PropertyId[PropertyId["SpeechServiceConnection_RecoMode"] = 14] = "SpeechServiceConnection_RecoMode";
    /**
     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property
     * directly.
     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].
     * @member PropertyId.SpeechServiceConnection_RecoLanguage
     */
    PropertyId[PropertyId["SpeechServiceConnection_RecoLanguage"] = 15] = "SpeechServiceConnection_RecoLanguage";
    /**
     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this
     * property directly.
     * Instead use [[SessionEventArgs.sessionId]].
     * @member PropertyId.Speech_SessionId
     */
    PropertyId[PropertyId["Speech_SessionId"] = 16] = "Speech_SessionId";
    /**
     * The spoken language to be synthesized (e.g. en-US)
     * @member PropertyId.SpeechServiceConnection_SynthLanguage
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthLanguage"] = 17] = "SpeechServiceConnection_SynthLanguage";
    /**
     * The name of the TTS voice to be used for speech synthesis
     * @member PropertyId.SpeechServiceConnection_SynthVoice
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthVoice"] = 18] = "SpeechServiceConnection_SynthVoice";
    /**
     * The string to specify TTS output audio format
     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthOutputFormat"] = 19] = "SpeechServiceConnection_SynthOutputFormat";
    /**
     * The list of comma separated languages used as possible source languages
     * Added in version 1.13.0
     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
     */
    PropertyId[PropertyId["SpeechServiceConnection_AutoDetectSourceLanguages"] = 20] = "SpeechServiceConnection_AutoDetectSourceLanguages";
    /**
     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have
     * to use this property directly.
     * Instead use [[SpeechConfig.outputFormat]].
     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestDetailedResultTrueFalse"] = 21] = "SpeechServiceResponse_RequestDetailedResultTrueFalse";
    /**
     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.
     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestProfanityFilterTrueFalse"] = 22] = "SpeechServiceResponse_RequestProfanityFilterTrueFalse";
    /**
     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.
     * @member PropertyId.SpeechServiceResponse_JsonResult
     */
    PropertyId[PropertyId["SpeechServiceResponse_JsonResult"] = 23] = "SpeechServiceResponse_JsonResult";
    /**
     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to
     * use this property directly. Instead use [[CancellationDetails.errorDetails]].
     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails
     */
    PropertyId[PropertyId["SpeechServiceResponse_JsonErrorDetails"] = 24] = "SpeechServiceResponse_JsonErrorDetails";
    /**
     * The cancellation reason. Currently unused.
     * @member PropertyId.CancellationDetails_Reason
     */
    PropertyId[PropertyId["CancellationDetails_Reason"] = 25] = "CancellationDetails_Reason";
    /**
     * The cancellation text. Currently unused.
     * @member PropertyId.CancellationDetails_ReasonText
     */
    PropertyId[PropertyId["CancellationDetails_ReasonText"] = 26] = "CancellationDetails_ReasonText";
    /**
     * The Cancellation detailed text. Currently unused.
     * @member PropertyId.CancellationDetails_ReasonDetailedText
     */
    PropertyId[PropertyId["CancellationDetails_ReasonDetailedText"] = 27] = "CancellationDetails_ReasonDetailedText";
    /**
     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]
     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult
     */
    PropertyId[PropertyId["LanguageUnderstandingServiceResponse_JsonResult"] = 28] = "LanguageUnderstandingServiceResponse_JsonResult";
    /**
     * The URL string built from speech configuration.
     * This property is intended to be read-only. The SDK is using it internally.
     * NOTE: Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_Url"] = 29] = "SpeechServiceConnection_Url";
    /**
     * The initial silence timeout value (in milliseconds) used by the service.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_InitialSilenceTimeoutMs"] = 30] = "SpeechServiceConnection_InitialSilenceTimeoutMs";
    /**
     * The end silence timeout value (in milliseconds) used by the service.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_EndSilenceTimeoutMs"] = 31] = "SpeechServiceConnection_EndSilenceTimeoutMs";
    /**
     * A boolean value specifying whether audio logging is enabled in the service or not.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_EnableAudioLogging"] = 32] = "SpeechServiceConnection_EnableAudioLogging";
    /**
     * The requested Cognitive Services Speech Service response output profanity setting.
     * Allowed values are "masked", "removed", and "raw".
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_ProfanityOption"] = 33] = "SpeechServiceResponse_ProfanityOption";
    /**
     * A string value specifying which post processing option should be used by service.
     * Allowed values are "TrueText".
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_PostProcessingOption"] = 34] = "SpeechServiceResponse_PostProcessingOption";
    /**
     *  A boolean value specifying whether to include word-level timestamps in the response result.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestWordLevelTimestamps"] = 35] = "SpeechServiceResponse_RequestWordLevelTimestamps";
    /**
     * The number of times a word has to be in partial results to be returned.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_StablePartialResultThreshold"] = 36] = "SpeechServiceResponse_StablePartialResultThreshold";
    /**
     * A string value specifying the output format option in the response result. Internal use only.
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_OutputFormatOption"] = 37] = "SpeechServiceResponse_OutputFormatOption";
    /**
     * A boolean value to request for stabilizing translation partial results by omitting words in the end.
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_TranslationRequestStablePartialResult"] = 38] = "SpeechServiceResponse_TranslationRequestStablePartialResult";
    /**
     * Identifier used to connect to the backend service.
     * @member PropertyId.Conversation_ApplicationId
     */
    PropertyId[PropertyId["Conversation_ApplicationId"] = 39] = "Conversation_ApplicationId";
    /**
     * Type of dialog backend to connect to.
     * @member PropertyId.Conversation_DialogType
     */
    PropertyId[PropertyId["Conversation_DialogType"] = 40] = "Conversation_DialogType";
    /**
     * Silence timeout for listening
     * @member PropertyId.Conversation_Initial_Silence_Timeout
     */
    PropertyId[PropertyId["Conversation_Initial_Silence_Timeout"] = 41] = "Conversation_Initial_Silence_Timeout";
    /**
     * From Id to add to speech recognition activities.
     * @member PropertyId.Conversation_From_Id
     */
    PropertyId[PropertyId["Conversation_From_Id"] = 42] = "Conversation_From_Id";
    /**
     * ConversationId for the session.
     * @member PropertyId.Conversation_Conversation_Id
     */
    PropertyId[PropertyId["Conversation_Conversation_Id"] = 43] = "Conversation_Conversation_Id";
    /**
     * Comma separated list of custom voice deployment ids.
     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids
     */
    PropertyId[PropertyId["Conversation_Custom_Voice_Deployment_Ids"] = 44] = "Conversation_Custom_Voice_Deployment_Ids";
    /**
     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.
     * @member PropertyId.Conversation_Speech_Activity_Template
     * Added in version 1.10.0.
     */
    PropertyId[PropertyId["Conversation_Speech_Activity_Template"] = 45] = "Conversation_Speech_Activity_Template";
    /**
     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.
     * @member PropertyId.Conversation_Request_Bot_Status_Messages
     * Added in version 1.15.0.
     */
    PropertyId[PropertyId["Conversation_Request_Bot_Status_Messages"] = 46] = "Conversation_Request_Bot_Status_Messages";
    /**
     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for
     * channel authentication.
     * Added in version 1.15.1.
     */
    PropertyId[PropertyId["Conversation_Agent_Connection_Id"] = 47] = "Conversation_Agent_Connection_Id";
    /**
     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.
     * Instead, use [[SpeechConfig.fromHost]].
     */
    PropertyId[PropertyId["SpeechServiceConnection_Host"] = 48] = "SpeechServiceConnection_Host";
    /**
     * Set the host for service calls to the Conversation Translator REST management and websocket calls.
     */
    PropertyId[PropertyId["ConversationTranslator_Host"] = 49] = "ConversationTranslator_Host";
    /**
     * Optionally set the the host's display name.
     * Used when joining a conversation.
     */
    PropertyId[PropertyId["ConversationTranslator_Name"] = 50] = "ConversationTranslator_Name";
    /**
     * Optionally set a value for the X-CorrelationId request header.
     * Used for troubleshooting errors in the server logs. It should be a valid guid.
     */
    PropertyId[PropertyId["ConversationTranslator_CorrelationId"] = 51] = "ConversationTranslator_CorrelationId";
    /**
     * Set the conversation token to be sent to the speech service. This enables the
     * service to service call from the speech service to the Conversation Translator service for relaying
     * recognitions. For internal use.
     */
    PropertyId[PropertyId["ConversationTranslator_Token"] = 52] = "ConversationTranslator_Token";
    /**
     * The reference text of the audio for pronunciation evaluation.
     * For this and the following pronunciation assessment parameters, see
     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_ReferenceText"] = 53] = "PronunciationAssessment_ReferenceText";
    /**
     * The point system for pronunciation score calibration (FivePoint or HundredMark).
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_GradingSystem"] = 54] = "PronunciationAssessment_GradingSystem";
    /**
     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Granularity"] = 55] = "PronunciationAssessment_Granularity";
    /**
     * Defines if enable miscue calculation.
     * With this enabled, the pronounced words will be compared to the reference text,
     * and will be marked with omission/insertion based on the comparison. The default setting is False.
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_EnableMiscue"] = 56] = "PronunciationAssessment_EnableMiscue";
    /**
     * The json string of pronunciation assessment parameters
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Json"] = 57] = "PronunciationAssessment_Json";
    /**
     * Pronunciation assessment parameters.
     * This property is intended to be read-only. The SDK is using it internally.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Params"] = 58] = "PronunciationAssessment_Params";
    /**
     * Version of Speaker Recognition API to use.
     * Added in version 1.18.0
     */
    PropertyId[PropertyId["SpeakerRecognition_Api_Version"] = 59] = "SpeakerRecognition_Api_Version";
})(PropertyId || (PropertyId = {}));

//# sourceMappingURL=PropertyId.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js ***!
  \************************************************************************************************************/
/*! exports provided: RecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionEventArgs", function() { return RecognitionEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines payload for session events like Speech Start/End Detected
 * @class
 */
class RecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(offset, sessionId) {
        super(sessionId);
        this.privOffset = offset;
    }
    /**
     * Represents the message offset
     * @member RecognitionEventArgs.prototype.offset
     * @function
     * @public
     */
    get offset() {
        return this.privOffset;
    }
}

//# sourceMappingURL=RecognitionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js ***!
  \*********************************************************************************************************/
/*! exports provided: RecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RecognitionResult", function() { return RecognitionResult; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines result of speech recognition.
 * @class RecognitionResult
 */
class RecognitionResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
        this.privResultId = resultId;
        this.privReason = reason;
        this.privText = text;
        this.privDuration = duration;
        this.privOffset = offset;
        this.privLanguage = language;
        this.privLanguageDetectionConfidence = languageDetectionConfidence;
        this.privErrorDetails = errorDetails;
        this.privJson = json;
        this.privProperties = properties;
    }
    /**
     * Specifies the result identifier.
     * @member RecognitionResult.prototype.resultId
     * @function
     * @public
     * @returns {string} Specifies the result identifier.
     */
    get resultId() {
        return this.privResultId;
    }
    /**
     * Specifies status of the result.
     * @member RecognitionResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} Specifies status of the result.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * Presents the recognized text in the result.
     * @member RecognitionResult.prototype.text
     * @function
     * @public
     * @returns {string} Presents the recognized text in the result.
     */
    get text() {
        return this.privText;
    }
    /**
     * Duration of recognized speech in 100 nano second incements.
     * @member RecognitionResult.prototype.duration
     * @function
     * @public
     * @returns {number} Duration of recognized speech in 100 nano second incements.
     */
    get duration() {
        return this.privDuration;
    }
    /**
     * Offset of recognized speech in 100 nano second incements.
     * @member RecognitionResult.prototype.offset
     * @function
     * @public
     * @returns {number} Offset of recognized speech in 100 nano second incements.
     */
    get offset() {
        return this.privOffset;
    }
    /**
     * Primary Language detected.
     * @member RecognitionResult.prototype.language
     * @function
     * @public
     * @returns {string} language detected.
     */
    get language() {
        return this.privLanguage;
    }
    /**
     * Primary Language detection confidence (Unknown, Low, Medium, High).
     * @member RecognitionResult.prototype.languageDetectionConfidence
     * @function
     * @public
     * @returns {string} detection confidence strength.
     */
    get languageDetectionConfidence() {
        return this.privLanguageDetectionConfidence;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member RecognitionResult.prototype.errorDetails
     * @function
     * @public
     * @returns {string} a brief description of an error.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     * A string containing Json serialized recognition result as it was received from the service.
     * @member RecognitionResult.prototype.json
     * @function
     * @private
     * @returns {string} Json serialized representation of the result.
     */
    get json() {
        return this.privJson;
    }
    /**
     *  The set of properties exposed in the result.
     * @member RecognitionResult.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The set of properties exposed in the result.
     */
    get properties() {
        return this.privProperties;
    }
}

//# sourceMappingURL=RecognitionResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js ***!
  \**************************************************************************************************/
/*! exports provided: Recognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Recognizer", function() { return Recognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Defines the base class Recognizer which mainly contains common event handlers.
 * @class Recognizer
 */
class Recognizer {
    /**
     * Creates and initializes an instance of a Recognizer
     * @constructor
     * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer
     */
    constructor(audioConfig, properties, connectionFactory) {
        this.audioConfig = (audioConfig !== undefined) ? audioConfig : _Exports__WEBPACK_IMPORTED_MODULE_3__["AudioConfig"].fromDefaultMicrophoneInput();
        this.privDisposed = false;
        this.privProperties = properties.clone();
        this.privConnectionFactory = connectionFactory;
        this.implCommonRecognizerSetup();
    }
    /**
     * Dispose of associated resources.
     * @member Recognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposed);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, errorCb);
    }
    /**
     * @Internal
     * Internal data member to support fromRecognizer* pattern methods on other classes.
     * Do not use externally, object returned will change without warning or notice.
     */
    get internalData() {
        return this.privReco;
    }
    /**
     * This method performs cleanup of resources.
     * The Boolean parameter disposing indicates whether the method is called
     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
     * Derived classes should override this method to dispose resource if needed.
     * @member Recognizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - Flag to request disposal.
     */
    dispose(disposing) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposed) {
                return;
            }
            this.privDisposed = true;
            if (disposing) {
                if (this.privReco) {
                    yield this.privReco.audioSource.turnOff();
                    yield this.privReco.dispose();
                }
            }
        });
    }
    /**
     * This method returns the current state of the telemetry setting.
     * @member Recognizer.prototype.telemetryEnabled
     * @function
     * @public
     * @returns true if the telemetry is enabled, false otherwise.
     */
    static get telemetryEnabled() {
        return _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServiceRecognizerBase"].telemetryDataEnabled;
    }
    /**
     * This method globally enables or disables telemetry.
     * @member Recognizer.prototype.enableTelemetry
     * @function
     * @public
     * @param enabled - Global setting for telemetry collection.
     * If set to true, telemetry information like microphone errors,
     * recognition errors are collected and sent to Microsoft.
     * If set to false, no telemetry is sent to Microsoft.
     */
    /* tslint:disable:member-ordering */
    static enableTelemetry(enabled) {
        _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServiceRecognizerBase"].telemetryDataEnabled = enabled;
    }
    // Does the generic recognizer setup that is common across all recognizer types.
    implCommonRecognizerSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const recognizerConfig = this.createRecognizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechServiceConfig"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OS"](osPlatform, osName, osVersion))));
        this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);
    }
    recognizeOnceAsyncImpl(recognitionMode) {
        return __awaiter(this, void 0, void 0, function* () {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposed);
            const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Deferred"]();
            yield this.implRecognizerStop();
            yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);
            const result = yield ret.promise;
            yield this.implRecognizerStop();
            return result;
        });
    }
    startContinuousRecognitionAsyncImpl(recognitionMode) {
        return __awaiter(this, void 0, void 0, function* () {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposed);
            yield this.implRecognizerStop();
            yield this.privReco.recognize(recognitionMode, undefined, undefined);
        });
    }
    stopContinuousRecognitionAsyncImpl() {
        return __awaiter(this, void 0, void 0, function* () {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposed);
            yield this.implRecognizerStop();
        });
    }
    implRecognizerStop() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privReco) {
                yield this.privReco.stopRecognizing();
            }
            return;
        });
    }
    static getAuthFromProperties(properties) {
        const subscriptionKey = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Key, undefined);
        const authentication = (subscriptionKey && subscriptionKey !== "") ?
            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CognitiveSubscriptionKeyAuthentication"](subscriptionKey) :
            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CognitiveTokenAuthentication"]((authFetchEventId) => {
                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, undefined);
                return Promise.resolve(authorizationToken);
            }, (authFetchEventId) => {
                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, undefined);
                return Promise.resolve(authorizationToken);
            });
        return authentication;
    }
}

//# sourceMappingURL=Recognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js ***!
  \****************************************************************************************************/
/*! exports provided: ResultReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ResultReason", function() { return ResultReason; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might be generated.
 * @class ResultReason
 */
var ResultReason;
(function (ResultReason) {
    /**
     * Indicates speech could not be recognized. More details
     * can be found in the NoMatchDetails object.
     * @member ResultReason.NoMatch
     */
    ResultReason[ResultReason["NoMatch"] = 0] = "NoMatch";
    /**
     * Indicates that the recognition was canceled. More details
     * can be found using the CancellationDetails object.
     * @member ResultReason.Canceled
     */
    ResultReason[ResultReason["Canceled"] = 1] = "Canceled";
    /**
     * Indicates the speech result contains hypothesis text.
     * @member ResultReason.RecognizedSpeech
     */
    ResultReason[ResultReason["RecognizingSpeech"] = 2] = "RecognizingSpeech";
    /**
     * Indicates the speech result contains final text that has been recognized.
     * Speech Recognition is now complete for this phrase.
     * @member ResultReason.RecognizedSpeech
     */
    ResultReason[ResultReason["RecognizedSpeech"] = 3] = "RecognizedSpeech";
    /**
     * Indicates the speech result contains a finalized acceptance of a provided keyword.
     * Speech recognition will continue unless otherwise configured.
     * @member ResultReason.RecognizedKeyword
     */
    ResultReason[ResultReason["RecognizedKeyword"] = 4] = "RecognizedKeyword";
    /**
     * Indicates the intent result contains hypothesis text and intent.
     * @member ResultReason.RecognizingIntent
     */
    ResultReason[ResultReason["RecognizingIntent"] = 5] = "RecognizingIntent";
    /**
     * Indicates the intent result contains final text and intent.
     * Speech Recognition and Intent determination are now complete for this phrase.
     * @member ResultReason.RecognizedIntent
     */
    ResultReason[ResultReason["RecognizedIntent"] = 6] = "RecognizedIntent";
    /**
     * Indicates the translation result contains hypothesis text and its translation(s).
     * @member ResultReason.TranslatingSpeech
     */
    ResultReason[ResultReason["TranslatingSpeech"] = 7] = "TranslatingSpeech";
    /**
     * Indicates the translation result contains final text and corresponding translation(s).
     * Speech Recognition and Translation are now complete for this phrase.
     * @member ResultReason.TranslatedSpeech
     */
    ResultReason[ResultReason["TranslatedSpeech"] = 8] = "TranslatedSpeech";
    /**
     * Indicates the synthesized audio result contains a non-zero amount of audio data
     * @member ResultReason.SynthesizingAudio
     */
    ResultReason[ResultReason["SynthesizingAudio"] = 9] = "SynthesizingAudio";
    /**
     * Indicates the synthesized audio is now complete for this phrase.
     * @member ResultReason.SynthesizingAudioCompleted
     */
    ResultReason[ResultReason["SynthesizingAudioCompleted"] = 10] = "SynthesizingAudioCompleted";
    /**
     * Indicates the speech synthesis is now started
     * @member ResultReason.SynthesizingAudioStarted
     */
    ResultReason[ResultReason["SynthesizingAudioStarted"] = 11] = "SynthesizingAudioStarted";
    /**
     * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.
     * @member ResultReason.EnrollingVoiceProfile
     */
    ResultReason[ResultReason["EnrollingVoiceProfile"] = 12] = "EnrollingVoiceProfile";
    /**
     * Indicates the voice profile has been enrolled.
     * @member ResultReason.EnrolledVoiceProfile
     */
    ResultReason[ResultReason["EnrolledVoiceProfile"] = 13] = "EnrolledVoiceProfile";
    /**
     * Indicates successful identification of some speakers.
     * @member ResultReason.RecognizedSpeakers
     */
    ResultReason[ResultReason["RecognizedSpeakers"] = 14] = "RecognizedSpeakers";
    /**
     * Indicates successfully verified one speaker.
     * @member ResultReason.RecognizedSpeaker
     */
    ResultReason[ResultReason["RecognizedSpeaker"] = 15] = "RecognizedSpeaker";
    /**
     * Indicates a voice profile has been reset successfully.
     * @member ResultReason.ResetVoiceProfile
     */
    ResultReason[ResultReason["ResetVoiceProfile"] = 16] = "ResetVoiceProfile";
    /**
     * Indicates a voice profile has been deleted successfully.
     * @member ResultReason.DeletedVoiceProfile
     */
    ResultReason[ResultReason["DeletedVoiceProfile"] = 17] = "DeletedVoiceProfile";
})(ResultReason || (ResultReason = {}));

//# sourceMappingURL=ResultReason.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js ***!
  \********************************************************************************************************/
/*! exports provided: ServiceEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServiceEventArgs", function() { return ServiceEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//

/**
 * Defines payload for any Service message event
 * Added in version 1.9.0
 */
class ServiceEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} json - json payload of the USP message.
     */
    constructor(json, name, sessionId) {
        super(sessionId);
        this.privJsonResult = json;
        this.privEventName = name;
    }
    get jsonString() {
        return this.privJsonResult;
    }
    get eventName() {
        return this.privEventName;
    }
}

//# sourceMappingURL=ServiceEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js ***!
  \**************************************************************************************************************/
/*! exports provided: ServicePropertyChannel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ServicePropertyChannel", function() { return ServicePropertyChannel; });
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Defines channels used to pass property settings to service.
 * Added in version 1.7.0.
 */
var ServicePropertyChannel;
(function (ServicePropertyChannel) {
    /**
     * Uses URI query parameter to pass property settings to service.
     */
    ServicePropertyChannel[ServicePropertyChannel["UriQueryParameter"] = 0] = "UriQueryParameter";
})(ServicePropertyChannel || (ServicePropertyChannel = {}));

//# sourceMappingURL=ServicePropertyChannel.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js ***!
  \********************************************************************************************************/
/*! exports provided: SessionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SessionEventArgs", function() { return SessionEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.
 * @class SessionEventArgs
 */
class SessionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} sessionId - The session id.
     */
    constructor(sessionId) {
        this.privSessionId = sessionId;
    }
    /**
     * Represents the session identifier.
     * @member SessionEventArgs.prototype.sessionId
     * @function
     * @public
     * @returns {string} Represents the session identifier.
     */
    get sessionId() {
        return this.privSessionId;
    }
}

//# sourceMappingURL=SessionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js ***!
  \************************************************************************************************************/
/*! exports provided: SourceLanguageConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SourceLanguageConfig", function() { return SourceLanguageConfig; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Source Language configuration.
 * @class SourceLanguageConfig
 */
class SourceLanguageConfig {
    constructor(language, endpointId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(language, "language");
        this.privLanguage = language;
        this.privEndpointId = endpointId;
    }
    /**
     * @member SourceLanguageConfig.fromLanguage
     * @function
     * @public
     * @param {string} language language (eg. "en-US") value of config.
     * @param {string?} endpointId endpointId of model bound to given language of config.
     * @return {SourceLanguageConfig} Instance of SourceLanguageConfig
     * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.
     * Added in version 1.13.0.
     */
    static fromLanguage(language, endpointId) {
        return new SourceLanguageConfig(language, endpointId);
    }
    get language() {
        return this.privLanguage;
    }
    get endpointId() {
        return this.privEndpointId;
    }
}

//# sourceMappingURL=SourceLanguageConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js ***!
  \******************************************************************************************************************/
/*! exports provided: SpeakerIdentificationModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerIdentificationModel", function() { return SpeakerIdentificationModel; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Defines SpeakerIdentificationModel class for Speaker Recognition
 * Model contains a set of profiles against which to identify speaker(s)
 * @class SpeakerIdentificationModel
 */
class SpeakerIdentificationModel {
    constructor(profiles) {
        this.privVoiceProfiles = [];
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(profiles, "VoiceProfiles");
        if (profiles.length === 0) {
            throw new Error("Empty Voice Profiles array");
        }
        profiles.forEach((profile) => {
            if (profile.profileType !== _Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileType"].TextIndependentIdentification) {
                throw new Error("Identification model can only be created from Identification profile: " + profile.profileId);
            }
            this.privVoiceProfiles.push(profile);
        });
    }
    static fromProfiles(profiles) {
        return new SpeakerIdentificationModel(profiles);
    }
    get voiceProfileIds() {
        return this.privVoiceProfiles.map((profile) => profile.profileId).join(",");
    }
}

//# sourceMappingURL=SpeakerIdentificationModel.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeakerRecognitionResultType, SpeakerRecognitionResult, SpeakerRecognitionCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResultType", function() { return SpeakerRecognitionResultType; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionResult", function() { return SpeakerRecognitionResult; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognitionCancellationDetails", function() { return SpeakerRecognitionCancellationDetails; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



var SpeakerRecognitionResultType;
(function (SpeakerRecognitionResultType) {
    SpeakerRecognitionResultType[SpeakerRecognitionResultType["Verify"] = 0] = "Verify";
    SpeakerRecognitionResultType[SpeakerRecognitionResultType["Identify"] = 1] = "Identify";
})(SpeakerRecognitionResultType || (SpeakerRecognitionResultType = {}));
/**
 * Output format
 * @class SpeakerRecognitionResult
 */
class SpeakerRecognitionResult {
    constructor(resultType, data, profileId, resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__["ResultReason"].RecognizedSpeaker) {
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
        this.privReason = resultReason;
        if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_2__["ResultReason"].Canceled) {
            if (resultType === SpeakerRecognitionResultType.Identify) {
                const json = JSON.parse(data);
                _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(json, "JSON");
                this.privProfileId = json.identifiedProfile.profileId;
                this.privScore = json.identifiedProfile.score;
            }
            else {
                const json = JSON.parse(data);
                _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(json, "JSON");
                this.privScore = json.score;
                if (json.recognitionResult.toLowerCase() !== "accept") {
                    this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_2__["ResultReason"].NoMatch;
                }
                if (profileId !== undefined && profileId !== "") {
                    this.privProfileId = profileId;
                }
            }
        }
        else {
            const json = JSON.parse(data);
            _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(json, "JSON");
            this.privErrorDetails = json.statusText;
            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].ServiceError]);
        }
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceResponse_JsonResult, data);
    }
    get properties() {
        return this.privProperties;
    }
    get reason() {
        return this.privReason;
    }
    get profileId() {
        return this.privProfileId;
    }
    get errorDetails() {
        return this.privErrorDetails;
    }
    get score() {
        return this.privScore;
    }
}
/**
 * @class SpeakerRecognitionCancellationDetails
 */
// tslint:disable-next-line:max-classes-per-file
class SpeakerRecognitionCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationDetailsBase"] {
    constructor(reason, errorDetails, errorCode) {
        super(reason, errorDetails, errorCode);
    }
    /**
     * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult
     * @member SpeakerRecognitionCancellationDetails.fromResult
     * @function
     * @public
     * @param {SpeakerRecognitionResult} result - The result that was canceled.
     * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.
     */
    static fromResult(result) {
        const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error;
        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError;
        if (!!result.properties) {
            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError])];
        }
        return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);
    }
}

//# sourceMappingURL=SpeakerRecognitionResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js ***!
  \*********************************************************************************************************/
/*! exports provided: SpeakerRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerRecognizer", function() { return SpeakerRecognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Defines SpeakerRecognizer class for Speaker Recognition
 * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)
 * @class SpeakerRecognizer
 */
class SpeakerRecognizer {
    /**
     * SpeakerRecognizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - An set of initial properties for this recognizer (authentication key, region, &c)
     */
    constructor(speechConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(speechConfigImpl, "speechConfig");
        this.privAudioConfigImpl = audioConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(this.privAudioConfigImpl, "audioConfig");
        this.privProperties = speechConfigImpl.properties.clone();
        this.implSRSetup();
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member SpeakerRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member SpeakerRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this SpeakerRecognizer.
     * @member SpeakerRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Get recognition result for model using given audio
     * @member SpeakerRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param {SpeakerIdentificationModel} model Model containing Voice Profiles to be identified
     * @param cb - Callback invoked once result is returned.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(model, cb, err) {
        if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeakerIdentificationModel"]) {
            const responsePromise = this.privAdapter.identifySpeaker(model, this.privAudioConfigImpl);
            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeakerRecognitionResultType"].Identify, undefined), cb, err);
        }
        else if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeakerVerificationModel"]) {
            const responsePromise = this.privAdapter.verifySpeaker(model, this.privAudioConfigImpl);
            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeakerRecognitionResultType"].Verify, model.voiceProfile.profileId), cb, err);
        }
        else {
            throw new Error("SpeakerRecognizer.recognizeOnce: Unexpected model type");
        }
    }
    /**
     * Included for compatibility
     * @member SpeakerRecognizer.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
    // Does class setup, swiped from Recognizer.
    implSRSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeakerRecognitionConfig"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OS"](osPlatform, osName, osVersion)), this.privProperties);
        this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeakerIdMessageAdapter"](recognizerConfig);
    }
    getResult(responsePromise, resultType, profileId) {
        return __awaiter(this, void 0, void 0, function* () {
            const response = yield responsePromise;
            return new _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeakerRecognitionResult"](resultType, response.data, profileId, response.ok ? _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].RecognizedSpeaker : _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].Canceled);
        });
    }
}

//# sourceMappingURL=SpeakerRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeakerVerificationModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeakerVerificationModel", function() { return SpeakerVerificationModel; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Defines SpeakerVerificationModel class for Speaker Recognition
 * Model contains a profile against which to verify a speaker
 * @class SpeakerVerificationModel
 */
class SpeakerVerificationModel {
    constructor(profile) {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(profile, "VoiceProfile");
        if (profile.profileType === _Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileType"].TextIndependentIdentification) {
            throw new Error("Verification model cannot be created from Identification profile");
        }
        this.privVoiceProfile = profile;
    }
    static fromProfile(profile) {
        return new SpeakerVerificationModel(profile);
    }
    get voiceProfile() {
        return this.privVoiceProfile;
    }
}

//# sourceMappingURL=SpeakerVerificationModel.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js ***!
  \****************************************************************************************************/
/*! exports provided: SpeechConfig, SpeechConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechConfig", function() { return SpeechConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechConfigImpl", function() { return SpeechConfigImpl; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Speech configuration.
 * @class SpeechConfig
 */
class SpeechConfig {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() { }
    /**
     * Static instance of SpeechConfig returned by passing subscriptionKey and service region.
     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
     * @member SpeechConfig.fromSubscription
     * @function
     * @public
     * @param {string} subscriptionKey - The subscription key.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechConfig} The speech factory
     */
    static fromSubscription(subscriptionKey, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_IntentRegion, region);
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        return speechImpl;
    }
    /**
     * Creates an instance of the speech config with specified endpoint and subscription key.
     * This method is intended only for users who use a non-standard service endpoint or parameters.
     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
     * For example, if language is defined in the uri as query parameter "language=de-DE", and also set by
     *              SpeechConfig.speechRecognitionLanguage = "en-US", the language setting in uri takes precedence,
     *              and the effective language is "de-DE". Only the parameters that are not specified in the
     *              endpoint URL can be set by other APIs.
     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
     *       fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
     *       use the authorization token.
     * @member SpeechConfig.fromEndpoint
     * @function
     * @public
     * @param {URL} endpoint - The service endpoint to connect to.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromEndpoint(endpoint, subscriptionKey) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(endpoint, "endpoint");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint, endpoint.href);
        if (undefined !== subscriptionKey) {
            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        }
        return speechImpl;
    }
    /**
     * Creates an instance of the speech config with specified host and subscription key.
     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL),
     * and then set the AuthorizationToken property on the created SpeechConfig instance.
     * Note: Added in version 1.9.0.
     * @member SpeechConfig.fromHost
     * @function
     * @public
     * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromHost(hostName, subscriptionKey) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(hostName, "hostName");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
        if (undefined !== subscriptionKey) {
            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        }
        return speechImpl;
    }
    /**
     * Creates an instance of the speech factory with specified initial authorization token and region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     *       expires, the caller needs to refresh it by calling this setter with a new valid token.
     * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want
     *       to use the Intent recognizer. As configuration values are copied when creating a new recognizer,
     *       the new token value will not apply to recognizers that have already been created. For recognizers
     *       that have been created before, you need to set authorization token of the corresponding recognizer
     *       to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member SpeechConfig.fromAuthorizationToken
     * @function
     * @public
     * @param {string} authorizationToken - The initial authorization token.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromAuthorizationToken(authorizationToken, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(authorizationToken, "authorizationToken");
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_IntentRegion, region);
        speechImpl.authorizationToken = authorizationToken;
        return speechImpl;
    }
    /**
     * Closes the configuration.
     * @member SpeechConfig.prototype.close
     * @function
     * @public
     */
    /* tslint:disable:no-empty */
    close() { }
}
/**
 * @public
 * @class SpeechConfigImpl
 */
// tslint:disable-next-line:max-classes-per-file
class SpeechConfigImpl extends SpeechConfig {
    constructor() {
        super();
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
        this.speechRecognitionLanguage = "en-US"; // Should we have a default?
        this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"].Simple;
    }
    get properties() {
        return this.privProperties;
    }
    get endPoint() {
        return new URL(this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint));
    }
    get subscriptionKey() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key);
    }
    get region() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region);
    }
    get authorizationToken() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    set authorizationToken(value) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, value);
    }
    get speechRecognitionLanguage() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    set speechRecognitionLanguage(value) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage, value);
    }
    get autoDetectSourceLanguages() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages);
    }
    set autoDetectSourceLanguages(value) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages, value);
    }
    get outputFormat() {
        return _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormatPropertyName"], undefined)];
    }
    set outputFormat(value) {
        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormatPropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][value]);
    }
    get endpointId() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId);
    }
    set endpointId(value) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId, value);
    }
    setProperty(name, value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(value, "value");
        this.privProperties.setProperty(name, value);
    }
    getProperty(name, def) {
        return this.privProperties.getProperty(name, def);
    }
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyHostName], proxyHostName);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyPort], proxyPort);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyUserName], proxyUserName);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyPassword], proxyPassword);
    }
    setServiceProperty(name, value, channel) {
        const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServicePropertiesPropertyName"], "{}"));
        currentProperties[name] = value;
        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServicePropertiesPropertyName"], JSON.stringify(currentProperties));
    }
    setProfanity(profanity) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_2__["ProfanityOption"][profanity]);
    }
    enableAudioLogging() {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EnableAudioLogging, "true");
    }
    requestWordLevelTimestamps() {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceResponse_RequestWordLevelTimestamps, "true");
    }
    enableDictation() {
        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ForceDictationPropertyName"], "true");
    }
    clone() {
        const ret = new SpeechConfigImpl();
        ret.privProperties = this.privProperties.clone();
        return ret;
    }
    get speechSynthesisLanguage() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthLanguage);
    }
    set speechSynthesisLanguage(language) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthLanguage, language);
    }
    get speechSynthesisVoiceName() {
        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthVoice);
    }
    set speechSynthesisVoiceName(voice) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthVoice, voice);
    }
    get speechSynthesisOutputFormat() {
        return _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisOutputFormat"][this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, undefined)];
    }
    set speechSynthesisOutputFormat(format) {
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisOutputFormat"][format]);
    }
}

//# sourceMappingURL=SpeechConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/*! exports provided: SpeechRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionCanceledEventArgs", function() { return SpeechRecognitionCanceledEventArgs; });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SpeechRecognitionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__["CancellationEventArgsBase"] {
}

//# sourceMappingURL=SpeechRecognitionCanceledEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionEventArgs", function() { return SpeechRecognitionEventArgs; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriptionEventArgs", function() { return ConversationTranscriptionEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines contents of speech recognizing/recognized event.
 * @class SpeechRecognitionEventArgs
 */
class SpeechRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {SpeechRecognitionResult} result - The speech recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @member SpeechRecognitionEventArgs.prototype.result
     * @function
     * @public
     * @returns {SpeechRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}
/**
 * Defines contents of conversation transcribed/transcribing event.
 * @class ConversationTranscriptionEventArgs
 */
// tslint:disable-next-line:max-classes-per-file
class ConversationTranscriptionEventArgs extends SpeechRecognitionEventArgs {
}

//# sourceMappingURL=SpeechRecognitionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognitionResult", function() { return SpeechRecognitionResult; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines result of speech recognition.
 * @class SpeechRecognitionResult
 */
class SpeechRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionResult"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @public
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} speakerId - speaker id for conversation transcription, if provided.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);
        this.privSpeakerId = speakerId;
    }
    /**
     * speaker id from conversation transcription/id scenarios
     * @member SpeechRecognitionResult.prototype.speakerId
     * @function
     * @public
     * @returns {string} id of speaker in given result
     */
    get speakerId() {
        return this.privSpeakerId;
    }
}

//# sourceMappingURL=SpeechRecognitionResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js ***!
  \********************************************************************************************************/
/*! exports provided: SpeechRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechRecognizer", function() { return SpeechRecognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
 * @class SpeechRecognizer
 */
class SpeechRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__["Recognizer"] {
    /**
     * SpeechRecognizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(speechConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(speechConfigImpl, "speechConfig");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
        super(audioConfig, speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechConnectionFactory"]());
        this.privDisposedRecognizer = false;
    }
    /**
     * SpeechRecognizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
        const recognizer = new SpeechRecognizer(speechConfig, audioConfig);
        return recognizer;
    }
    /**
     * Gets the endpoint id of a customized speech model that is used for speech recognition.
     * @member SpeechRecognizer.prototype.endpointId
     * @function
     * @public
     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
     */
    get endpointId() {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_EndpointId, "00000000-0000-0000-0000-000000000000");
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member SpeechRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member SpeechRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * Gets the spoken language of recognition.
     * @member SpeechRecognizer.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} The spoken language of recognition.
     */
    get speechRecognitionLanguage() {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets the output format of recognition.
     * @member SpeechRecognizer.prototype.outputFormat
     * @function
     * @public
     * @returns {OutputFormat} The output format of recognition.
     */
    get outputFormat() {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        if (this.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormatPropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"][_Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"].Simple]) === _Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"][_Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"].Simple]) {
            return _Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"].Simple;
        }
        else {
            return _Exports__WEBPACK_IMPORTED_MODULE_3__["OutputFormat"].Detailed;
        }
    }
    /**
     * The collection of properties and their values defined for this SpeechRecognizer.
     * @member SpeechRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts speech recognition, and stops after the first utterance is recognized.
     * The task returns the recognition text as result.
     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
     *       so it is suitable only for single shot recognition
     *       like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
     * @member SpeechRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the SpeechRecognitionResult.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Interactive), cb, err);
    }
    /**
     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Conversation), cb, err);
    }
    /**
     * Stops continuous speech recognition.
     * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * Starts speech recognition with keyword spotting, until
     * stopKeywordRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * Note: Key word spotting functionality is only available on the
     *      Speech Devices SDK. This functionality is currently not included in the SDK itself.
     * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync
     * @function
     * @public
     * @param {KeywordRecognitionModel} model The keyword recognition model that
     *        specifies the keyword to be recognized.
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startKeywordRecognitionAsync(model, cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(model, "model");
        if (!!err) {
            err("Not yet implemented.");
        }
    }
    /**
     * Stops continuous speech recognition.
     * Note: Key word spotting functionality is only available on the
     *       Speech Devices SDK. This functionality is currently not included in the SDK itself.
     * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopKeywordRecognitionAsync(cb, err) {
        if (!!cb) {
            cb();
        }
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member SpeechRecognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, errorCb);
    }
    /**
     * Disposes any resources held by the object.
     * @member SpeechRecognizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposedRecognizer) {
                return;
            }
            if (disposing) {
                this.privDisposedRecognizer = true;
                yield this.implRecognizerStop();
            }
            yield _super.dispose.call(this, disposing);
        });
    }
    createRecognizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognizerConfig"](speechConfig, this.properties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechServiceRecognizer"](authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
}

//# sourceMappingURL=SpeechRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \************************************************************************************************************************/
/*! exports provided: SpeechSynthesisBookmarkEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisBookmarkEventArgs", function() { return SpeechSynthesisBookmarkEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis bookmark event.
 * @class SpeechSynthesisBookmarkEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisBookmarkEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {string} text - The bookmark text.
     */
    constructor(audioOffset, text) {
        this.privAudioOffset = audioOffset;
        this.privText = text;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the bookmark.
     * @member SpeechSynthesisBookmarkEventArgs.prototype.text
     * @function
     * @public
     * @returns {string} the bookmark text.
     */
    get text() {
        return this.privText;
    }
}

//# sourceMappingURL=SpeechSynthesisBookmarkEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeechSynthesisEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisEventArgs", function() { return SpeechSynthesisEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis events.
 * @class SpeechSynthesisEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {SpeechSynthesisResult} result - The speech synthesis result.
     */
    constructor(result) {
        this.privResult = result;
    }
    /**
     * Specifies the synthesis result.
     * @member SpeechSynthesisEventArgs.prototype.result
     * @function
     * @public
     * @returns {SpeechSynthesisResult} the synthesis result.
     */
    get result() {
        return this.privResult;
    }
}

//# sourceMappingURL=SpeechSynthesisEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SpeechSynthesisOutputFormat */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisOutputFormat", function() { return SpeechSynthesisOutputFormat; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define speech synthesis audio output formats.
 * @enum SpeechSynthesisOutputFormat
 * Updated in version 1.17.0
 */
var SpeechSynthesisOutputFormat;
(function (SpeechSynthesisOutputFormat) {
    /**
     * raw-8khz-8bit-mono-mulaw
     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoMULaw"] = 0] = "Raw8Khz8BitMonoMULaw";
    /**
     * riff-16khz-16kbps-mono-siren
     * @note Unsupported by the service. Do not use this value.
     * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16KbpsMonoSiren"] = 1] = "Riff16Khz16KbpsMonoSiren";
    /**
     * audio-16khz-16kbps-mono-siren
     * @note Unsupported by the service. Do not use this value.
     * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz16KbpsMonoSiren"] = 2] = "Audio16Khz16KbpsMonoSiren";
    /**
     * audio-16khz-32kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz32KBitRateMonoMp3"] = 3] = "Audio16Khz32KBitRateMonoMp3";
    /**
     * audio-16khz-128kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz128KBitRateMonoMp3"] = 4] = "Audio16Khz128KBitRateMonoMp3";
    /**
     * audio-16khz-64kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz64KBitRateMonoMp3"] = 5] = "Audio16Khz64KBitRateMonoMp3";
    /**
     * audio-24khz-48kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz48KBitRateMonoMp3"] = 6] = "Audio24Khz48KBitRateMonoMp3";
    /**
     * audio-24khz-96kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz96KBitRateMonoMp3"] = 7] = "Audio24Khz96KBitRateMonoMp3";
    /**
     * audio-24khz-160kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz160KBitRateMonoMp3"] = 8] = "Audio24Khz160KBitRateMonoMp3";
    /**
     * raw-16khz-16bit-mono-truesilk
     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoTrueSilk"] = 9] = "Raw16Khz16BitMonoTrueSilk";
    /**
     * riff-16khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16BitMonoPcm"] = 10] = "Riff16Khz16BitMonoPcm";
    /**
     * riff-8khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz16BitMonoPcm"] = 11] = "Riff8Khz16BitMonoPcm";
    /**
     * riff-24khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff24Khz16BitMonoPcm"] = 12] = "Riff24Khz16BitMonoPcm";
    /**
     * riff-8khz-8bit-mono-mulaw
     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoMULaw"] = 13] = "Riff8Khz8BitMonoMULaw";
    /**
     * raw-16khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoPcm"] = 14] = "Raw16Khz16BitMonoPcm";
    /**
     * raw-24khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoPcm"] = 15] = "Raw24Khz16BitMonoPcm";
    /**
     * raw-8khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz16BitMonoPcm"] = 16] = "Raw8Khz16BitMonoPcm";
    /**
     * ogg-16khz-16bit-mono-opus
     * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg16Khz16BitMonoOpus"] = 17] = "Ogg16Khz16BitMonoOpus";
    /**
     * ogg-24khz-16bit-mono-opus
     * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg24Khz16BitMonoOpus"] = 18] = "Ogg24Khz16BitMonoOpus";
    /**
     * raw-48khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw48Khz16BitMonoPcm"] = 19] = "Raw48Khz16BitMonoPcm";
    /**
     * riff-48khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff48Khz16BitMonoPcm"] = 20] = "Riff48Khz16BitMonoPcm";
    /**
     * audio-48khz-96kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz96KBitRateMonoMp3"] = 21] = "Audio48Khz96KBitRateMonoMp3";
    /**
     * audio-48khz-192kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz192KBitRateMonoMp3"] = 22] = "Audio48Khz192KBitRateMonoMp3";
    /**
     * ogg-48khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg48Khz16BitMonoOpus"] = 23] = "Ogg48Khz16BitMonoOpus";
    /**
     * webm-16khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm16Khz16BitMonoOpus"] = 24] = "Webm16Khz16BitMonoOpus";
    /**
     * webm-24khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm24Khz16BitMonoOpus"] = 25] = "Webm24Khz16BitMonoOpus";
    /**
     * raw-24khz-16bit-mono-truesilk
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoTrueSilk"] = 26] = "Raw24Khz16BitMonoTrueSilk";
    /**
     * raw-8khz-8bit-mono-alaw
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoALaw"] = 27] = "Raw8Khz8BitMonoALaw";
    /**
     * riff-8khz-8bit-mono-alaw
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoALaw"] = 28] = "Riff8Khz8BitMonoALaw";
})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));

//# sourceMappingURL=SpeechSynthesisOutputFormat.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js ***!
  \*************************************************************************************************************/
/*! exports provided: SpeechSynthesisResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisResult", function() { return SpeechSynthesisResult; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines result of speech synthesis.
 * @class SpeechSynthesisResult
 * Added in version 1.11.0
 */
class SpeechSynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {number} audioData - The offset into the stream.
     * @param {string} errorDetails - Error details, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, audioData, errorDetails, properties) {
        this.privResultId = resultId;
        this.privReason = reason;
        this.privAudioData = audioData;
        this.privErrorDetails = errorDetails;
        this.privProperties = properties;
    }
    /**
     * Specifies the result identifier.
     * @member SpeechSynthesisResult.prototype.resultId
     * @function
     * @public
     * @returns {string} Specifies the result identifier.
     */
    get resultId() {
        return this.privResultId;
    }
    /**
     * Specifies status of the result.
     * @member SpeechSynthesisResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} Specifies status of the result.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * The synthesized audio data
     * @member SpeechSynthesisResult.prototype.audioData
     * @function
     * @public
     * @returns {ArrayBuffer} The synthesized audio data.
     */
    get audioData() {
        return this.privAudioData;
    }
    /**
     * In case of an unsuccessful synthesis, provides details of the occurred error.
     * @member SpeechSynthesisResult.prototype.errorDetails
     * @function
     * @public
     * @returns {string} a brief description of an error.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     *  The set of properties exposed in the result.
     * @member SpeechSynthesisResult.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The set of properties exposed in the result.
     */
    get properties() {
        return this.privProperties;
    }
}

//# sourceMappingURL=SpeechSynthesisResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \**********************************************************************************************************************/
/*! exports provided: SpeechSynthesisVisemeEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisVisemeEventArgs", function() { return SpeechSynthesisVisemeEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis viseme event.
 * @class SpeechSynthesisVisemeEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisVisemeEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {number} visemeId - The viseme ID.
     * @param {string} animation - The animation, could be in svg or other format.
     */
    constructor(audioOffset, visemeId, animation) {
        this.privAudioOffset = audioOffset;
        this.privVisemeId = visemeId;
        this.privAnimation = animation;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the viseme ID.
     * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId
     * @function
     * @public
     * @returns {number} the viseme ID.
     */
    get visemeId() {
        return this.privVisemeId;
    }
    /**
     * Specifies the animation.
     * @member SpeechSynthesisVisemeEventArgs.prototype.animation
     * @function
     * @public
     * @returns {string} the animation, could be in svg or other format.
     */
    get animation() {
        return this.privAnimation;
    }
}

//# sourceMappingURL=SpeechSynthesisVisemeEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \****************************************************************************************************************************/
/*! exports provided: SpeechSynthesisWordBoundaryEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesisWordBoundaryEventArgs", function() { return SpeechSynthesisWordBoundaryEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis word boundary event.
 * @class SpeechSynthesisWordBoundaryEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisWordBoundaryEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {string} text - The text.
     * @param {number} wordLength - The length of the word.
     * @param {number} textOffset - The text offset.
     */
    constructor(audioOffset, text, wordLength, textOffset) {
        this.privAudioOffset = audioOffset;
        this.privText = text;
        this.privWordLength = wordLength;
        this.privTextOffset = textOffset;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the text of the word boundary event.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text
     * @function
     * @public
     * @returns {string} the text.
     */
    get text() {
        return this.privText;
    }
    /**
     * Specifies the word length
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength
     * @function
     * @public
     * @returns {number} the word length
     */
    get wordLength() {
        return this.privWordLength;
    }
    /**
     * Specifies the text offset.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset
     * @function
     * @public
     * @returns {number} the text offset.
     */
    get textOffset() {
        return this.privTextOffset;
    }
}

//# sourceMappingURL=SpeechSynthesisWordBoundaryEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js ***!
  \*********************************************************************************************************/
/*! exports provided: SpeechSynthesizer, SynthesisRequest */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechSynthesizer", function() { return SpeechSynthesizer; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SynthesisRequest", function() { return SynthesisRequest; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioFileWriter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js");
/* harmony import */ var _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};







/**
 * Defines the class SpeechSynthesizer for text to speech.
 * Updated in version 1.16.0
 * @class SpeechSynthesizer
 */
class SpeechSynthesizer {
    /**
     * SpeechSynthesizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.
     */
    constructor(speechConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_5__["Contracts"].throwIfNull(speechConfigImpl, "speechConfig");
        if (audioConfig !== null) {
            if (audioConfig === undefined) {
                this.audioConfig = (typeof window === "undefined") ? undefined : _Exports__WEBPACK_IMPORTED_MODULE_6__["AudioConfig"].fromDefaultSpeakerOutput();
            }
            else {
                this.audioConfig = audioConfig;
            }
        }
        this.privProperties = speechConfigImpl.properties.clone();
        this.privDisposed = false;
        this.privSynthesizing = false;
        this.privConnectionFactory = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechSynthesisConnectionFactory"]();
        this.synthesisRequestQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__["Queue"]();
        this.implCommonSynthesizeSetup();
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member SpeechSynthesizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member SpeechSynthesizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_5__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this SpeechSynthesizer.
     * @member SpeechSynthesizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Indicates if auto detect source language is enabled
     * @member SpeechSynthesizer.prototype.properties
     * @function
     * @public
     * @returns {boolean} if auto detect source language is enabled
     */
    get autoDetectSourceLanguage() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceConnection_AutoDetectSourceLanguages) === _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["AutoDetectSourceLanguagesOpenRangeOptionName"];
    }
    /**
     * SpeechSynthesizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer
     */
    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
        return new SpeechSynthesizer(speechConfig, audioConfig);
    }
    buildSsml(text) {
        const languageToDefaultVoice = {
            ["ar-EG"]: "ar-EG-SalmaNeural",
            ["ar-SA"]: "ar-SA-HamedNeural",
            ["bg-BG"]: "bg-BG-BorislavNeural",
            ["ca-ES"]: "ca-ES-JoanaNeural",
            ["cs-CZ"]: "cs-CZ-AntoninNeural",
            ["cy-GB"]: "cy-GB-AledNeural",
            ["da-DK"]: "da-DK-ChristelNeural",
            ["de-AT"]: "de-AT-IngridNeural",
            ["de-CH"]: "de-CH-JanNeural",
            ["de-DE"]: "de-DE-KatjaNeural",
            ["el-GR"]: "el-GR-AthinaNeural",
            ["en-AU"]: "en-AU-NatashaNeural",
            ["en-CA"]: "en-CA-ClaraNeural",
            ["en-GB"]: "en-GB-LibbyNeural",
            ["en-HK"]: "en-HK-SamNeural",
            ["en-IE"]: "en-IE-ConnorNeural",
            ["en-IN"]: "en-IN-NeerjaNeural",
            ["en-NZ"]: "en-NZ-MitchellNeural",
            ["en-PH"]: "en-PH-JamesNeural",
            ["en-SG"]: "en-SG-LunaNeural",
            ["en-US"]: "en-US-JennyNeural",
            ["en-ZA"]: "en-ZA-LeahNeural",
            ["es-AR"]: "es-AR-ElenaNeural",
            ["es-CO"]: "es-CO-GonzaloNeural",
            ["es-ES"]: "es-ES-AlvaroNeural",
            ["es-MX"]: "es-MX-DaliaNeural",
            ["es-US"]: "es-US-AlonsoNeural",
            ["et-EE"]: "et-EE-AnuNeural",
            ["fi-FI"]: "fi-FI-SelmaNeural",
            ["fr-BE"]: "fr-BE-CharlineNeural",
            ["fr-CA"]: "fr-CA-SylvieNeural",
            ["fr-CH"]: "fr-CH-ArianeNeural",
            ["fr-FR"]: "fr-FR-DeniseNeural",
            ["ga-IE"]: "ga-IE-ColmNeural",
            ["gu-IN"]: "gu-IN-DhwaniNeural",
            ["he-IL"]: "he-IL-AvriNeural",
            ["hi-IN"]: "hi-IN-MadhurNeural",
            ["hr-HR"]: "hr-HR-GabrijelaNeural",
            ["hu-HU"]: "hu-HU-NoemiNeural",
            ["id-ID"]: "id-ID-ArdiNeural",
            ["it-IT"]: "it-IT-IsabellaNeural",
            ["ja-JP"]: "ja-JP-NanamiNeural",
            ["ko-KR"]: "ko-KR-SunHiNeural",
            ["lt-LT"]: "lt-LT-LeonasNeural",
            ["lv-LV"]: "lv-LV-EveritaNeural",
            ["mr-IN"]: "mr-IN-AarohiNeural",
            ["ms-MY"]: "ms-MY-OsmanNeural",
            ["mt-MT"]: "mt-MT-GraceNeural",
            ["nb-NO"]: "nb-NO-PernilleNeural",
            ["nl-BE"]: "nl-BE-ArnaudNeural",
            ["nl-NL"]: "nl-NL-ColetteNeural",
            ["pl-PL"]: "pl-PL-AgnieszkaNeural",
            ["pt-BR"]: "pt-BR-FranciscaNeural",
            ["pt-PT"]: "pt-PT-DuarteNeural",
            ["ro-RO"]: "ro-RO-AlinaNeural",
            ["ru-RU"]: "ru-RU-SvetlanaNeural",
            ["sk-SK"]: "sk-SK-LukasNeural",
            ["sl-SI"]: "sl-SI-PetraNeural",
            ["sv-SE"]: "sv-SE-SofieNeural",
            ["sw-KE"]: "sw-KE-RafikiNeural",
            ["ta-IN"]: "ta-IN-PallaviNeural",
            ["te-IN"]: "te-IN-MohanNeural",
            ["th-TH"]: "th-TH-PremwadeeNeural",
            ["tr-TR"]: "tr-TR-AhmetNeural",
            ["uk-UA"]: "uk-UA-OstapNeural",
            ["ur-PK"]: "ur-PK-AsadNeural",
            ["vi-VN"]: "vi-VN-HoaiMyNeural",
            ["zh-CN"]: "zh-CN-XiaoxiaoNeural",
            ["zh-HK"]: "zh-HK-HiuMaanNeural",
            ["zh-TW"]: "zh-TW-HsiaoChenNeural",
        };
        let language = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceConnection_SynthLanguage, "en-US");
        let voice = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceConnection_SynthVoice, "");
        let ssml = SpeechSynthesizer.XMLEncode(text);
        if (this.autoDetectSourceLanguage) {
            language = "en-US";
        }
        else {
            voice = voice || languageToDefaultVoice[language];
        }
        if (voice) {
            ssml = `<voice name='${voice}'>${ssml}</voice>`;
        }
        ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;
        return ssml;
    }
    /**
     * Executes speech synthesis on plain text.
     * The task returns the synthesis result.
     * @member SpeechSynthesizer.prototype.speakTextAsync
     * @function
     * @public
     * @param text - Text to be synthesized.
     * @param cb - Callback that received the SpeechSynthesisResult.
     * @param err - Callback invoked in case of an error.
     * @param stream - AudioOutputStream to receive the synthesized audio.
     */
    speakTextAsync(text, cb, err, stream) {
        this.speakImpl(text, false, cb, err, stream);
    }
    /**
     * Executes speech synthesis on SSML.
     * The task returns the synthesis result.
     * @member SpeechSynthesizer.prototype.speakSsmlAsync
     * @function
     * @public
     * @param ssml - SSML to be synthesized.
     * @param cb - Callback that received the SpeechSynthesisResult.
     * @param err - Callback invoked in case of an error.
     * @param stream - AudioOutputStream to receive the synthesized audio.
     */
    speakSsmlAsync(ssml, cb, err, stream) {
        this.speakImpl(ssml, true, cb, err, stream);
    }
    /**
     * Dispose of associated resources.
     * @member SpeechSynthesizer.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_5__["Contracts"].throwIfDisposed(this.privDisposed);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, err);
    }
    /**
     * @Internal
     * Do not use externally, object returned will change without warning or notice.
     */
    get internalData() {
        return this.privAdapter;
    }
    /**
     * This method performs cleanup of resources.
     * The Boolean parameter disposing indicates whether the method is called
     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
     * Derived classes should override this method to dispose resource if needed.
     * @member SpeechSynthesizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - Flag to request disposal.
     */
    dispose(disposing) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposed) {
                return;
            }
            if (disposing) {
                if (this.privAdapter) {
                    yield this.privAdapter.dispose();
                }
            }
            this.privDisposed = true;
        });
    }
    //
    // ################################################################################################################
    // IMPLEMENTATION.
    // Move to independent class
    // ################################################################################################################
    //
    createSynthesizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesizerConfig"](speechConfig, this.privProperties);
    }
    // Creates the synthesis adapter
    createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SynthesisAdapterBase"](authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);
    }
    implCommonSynthesizeSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const synthesizerConfig = this.createSynthesizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechServiceConfig"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OS"](osPlatform, osName, osVersion))));
        const subscriptionKey = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceConnection_Key, undefined);
        const authentication = (subscriptionKey && subscriptionKey !== "") ?
            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CognitiveSubscriptionKeyAuthentication"](subscriptionKey) :
            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CognitiveTokenAuthentication"]((authFetchEventId) => {
                const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceAuthorization_Token, undefined);
                return Promise.resolve(authorizationToken);
            }, (authFetchEventId) => {
                const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceAuthorization_Token, undefined);
                return Promise.resolve(authorizationToken);
            });
        this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);
        this.privAdapter.audioOutputFormat = _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__["AudioOutputFormatImpl"].fromSpeechSynthesisOutputFormat(_Exports__WEBPACK_IMPORTED_MODULE_6__["SpeechSynthesisOutputFormat"][this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, undefined)]);
    }
    speakImpl(text, IsSsml, cb, err, dataStream) {
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_5__["Contracts"].throwIfDisposed(this.privDisposed);
            const requestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["createNoDashGuid"])();
            let audioDestination;
            if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_6__["PushAudioOutputStreamCallback"]) {
                audioDestination = new _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_4__["PushAudioOutputStreamImpl"](dataStream);
            }
            else if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_6__["PullAudioOutputStream"]) {
                audioDestination = dataStream;
            }
            else if (dataStream !== undefined) {
                audioDestination = new _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_2__["AudioFileWriter"](dataStream);
            }
            else {
                audioDestination = undefined;
            }
            this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, (e) => {
                this.privSynthesizing = false;
                if (!!cb) {
                    try {
                        cb(e);
                    }
                    catch (e) {
                        if (!!err) {
                            err(e);
                        }
                    }
                }
                cb = undefined;
                /* tslint:disable:no-empty */
                this.adapterSpeak().catch(() => { });
            }, (e) => {
                if (!!err) {
                    err(e);
                }
            }, audioDestination));
            /* tslint:disable:no-empty */
            this.adapterSpeak().catch(() => { });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the synthesizer.
            /* tslint:disable:no-empty */
            this.dispose(true).catch(() => { });
        }
    }
    adapterSpeak() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.privDisposed && !this.privSynthesizing) {
                this.privSynthesizing = true;
                const request = yield this.synthesisRequestQueue.dequeue();
                return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);
            }
        });
    }
    static XMLEncode(text) {
        return text.replace(/&/g, "&amp;")
            .replace(/</g, "&lt;")
            .replace(/>/g, "&gt;")
            .replace(/"/g, "&quot;")
            .replace(/'/g, "&apos;");
    }
}
// tslint:disable-next-line:max-classes-per-file
class SynthesisRequest {
    constructor(requestId, text, isSSML, cb, err, dataStream) {
        this.requestId = requestId;
        this.text = text;
        this.isSSML = isSSML;
        this.cb = cb;
        this.err = err;
        this.dataStream = dataStream;
    }
}

//# sourceMappingURL=SpeechSynthesizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechTranslationConfig, SpeechTranslationConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfig", function() { return SpeechTranslationConfig; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechTranslationConfigImpl", function() { return SpeechTranslationConfigImpl; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Speech translation configuration.
 * @class SpeechTranslationConfig
 */
class SpeechTranslationConfig extends _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechConfig"] {
    /**
     * Creates an instance of recognizer config.
     */
    constructor() {
        super();
    }
    /**
     * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.
     * @member SpeechTranslationConfig.fromSubscription
     * @function
     * @public
     * @param {string} subscriptionKey - The subscription key.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechTranslationConfig} The speech translation config.
     */
    static fromSubscription(subscriptionKey, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const ret = new SpeechTranslationConfigImpl();
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        return ret;
    }
    /**
     * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     *       expires, the caller needs to refresh it by setting the property authorizationToken with a new
     *       valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance
     *       will encounter errors during recognition.
     * As configuration values are copied when creating a new recognizer, the new token value will not apply
     * to recognizers that have already been created.
     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member SpeechTranslationConfig.fromAuthorizationToken
     * @function
     * @public
     * @param {string} authorizationToken - The authorization token.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechTranslationConfig} The speech translation config.
     */
    static fromAuthorizationToken(authorizationToken, region) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(region, "region");
        const ret = new SpeechTranslationConfigImpl();
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, authorizationToken);
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region, region);
        return ret;
    }
    /**
     * Creates an instance of the speech config with specified host and subscription key.
     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL),
     * and then set the AuthorizationToken property on the created SpeechConfig instance.
     * Note: Added in version 1.9.0.
     * @member SpeechConfig.fromHost
     * @function
     * @public
     * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromHost(hostName, subscriptionKey) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(hostName, "hostName");
        const speechImpl = new SpeechTranslationConfigImpl();
        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
        if (undefined !== subscriptionKey) {
            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        }
        return speechImpl;
    }
    /**
     * Creates an instance of the speech translation config with specified endpoint and subscription key.
     * This method is intended only for users who use a non-standard service endpoint or paramters.
     * Note: The query properties specified in the endpoint URL are not changed, even if they are
     *       set by any other APIs. For example, if language is defined in the uri as query parameter
     *       "language=de-DE", and also set by the speechRecognitionLanguage property, the language
     *       setting in uri takes precedence, and the effective language is "de-DE".
     * Only the properties that are not specified in the endpoint URL can be set by other APIs.
     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
     *       fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
     *       use the authorization token.
     * @member SpeechTranslationConfig.fromEndpoint
     * @function
     * @public
     * @param {URL} endpoint - The service endpoint to connect to.
     * @param {string} subscriptionKey - The subscription key.
     * @returns {SpeechTranslationConfig} A speech config instance.
     */
    static fromEndpoint(endpoint, subscriptionKey) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(endpoint, "endpoint");
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNull(subscriptionKey, "subscriptionKey");
        const ret = new SpeechTranslationConfigImpl();
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Endpoint, endpoint.href);
        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key, subscriptionKey);
        return ret;
    }
}
/**
 * @private
 * @class SpeechTranslationConfigImpl
 */
// tslint:disable-next-line:max-classes-per-file
class SpeechTranslationConfigImpl extends SpeechTranslationConfig {
    constructor() {
        super();
        this.privSpeechProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
        this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"].Simple;
    }
    /**
     * Gets/Sets the authorization token.
     * If this is set, subscription key is ignored.
     * User needs to make sure the provided authorization token is valid and not expired.
     * @member SpeechTranslationConfigImpl.prototype.authorizationToken
     * @function
     * @public
     * @param {string} value - The authorization token.
     */
    set authorizationToken(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceAuthorization_Token, value);
    }
    /**
     * Sets the speech recognition language.
     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @param {string} value - The authorization token.
     */
    set speechRecognitionLanguage(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage, value);
    }
    /**
     * Gets the speech recognition language.
     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @return {string} The speechRecognitionLanguage.
     */
    get speechRecognitionLanguage() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
    }
    /**
     * @member SpeechTranslationConfigImpl.prototype.subscriptionKey
     * @function
     * @public
     */
    get subscriptionKey() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Key]);
    }
    /**
     * Gets the output format
     * @member SpeechTranslationConfigImpl.prototype.outputFormat
     * @function
     * @public
     */
    get outputFormat() {
        return _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormatPropertyName"], undefined)];
    }
    /**
     * Gets/Sets the output format
     * @member SpeechTranslationConfigImpl.prototype.outputFormat
     * @function
     * @public
     */
    set outputFormat(value) {
        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OutputFormatPropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["OutputFormat"][value]);
    }
    /**
     * Gets the endpoint id.
     * @member SpeechTranslationConfigImpl.prototype.endpointId
     * @function
     * @public
     */
    get endpointId() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId);
    }
    /**
     * Gets/Sets the endpoint id.
     * @member SpeechTranslationConfigImpl.prototype.endpointId
     * @function
     * @public
     */
    set endpointId(value) {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EndpointId, value);
    }
    /**
     * Add a (text) target language to translate into.
     * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage
     * @function
     * @public
     * @param {string} value - The language such as de-DE
     */
    addTargetLanguage(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(value, "value");
        const languages = this.targetLanguages;
        languages.push(value);
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, languages.join(","));
    }
    /**
     * Gets the (text) target language to translate into.
     * @member SpeechTranslationConfigImpl.prototype.targetLanguages
     * @function
     * @public
     * @param {string} value - The language such as de-DE
     */
    get targetLanguages() {
        if (this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_TranslationToLanguages).split(",");
        }
        else {
            return [];
        }
    }
    /**
     * Gets the voice name.
     * @member SpeechTranslationConfigImpl.prototype.voiceName
     * @function
     * @public
     */
    get voiceName() {
        return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_TranslationVoice]);
    }
    /**
     * Gets/Sets the voice of the translated language, enable voice synthesis output.
     * @member SpeechTranslationConfigImpl.prototype.voiceName
     * @function
     * @public
     * @param {string} value - The name of the voice.
     */
    set voiceName(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_TranslationVoice, value);
    }
    /**
     * Provides the region.
     * @member SpeechTranslationConfigImpl.prototype.region
     * @function
     * @public
     * @returns {string} The region.
     */
    get region() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_Region);
    }
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyHostName], proxyHostName);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyPort], proxyPort);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyUserName], proxyUserName);
        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_ProxyPassword], proxyPassword);
    }
    /**
     * Gets an arbitrary property value.
     * @member SpeechTranslationConfigImpl.prototype.getProperty
     * @function
     * @public
     * @param {string} name - The name of the property.
     * @param {string} def - The default value of the property in case it is not set.
     * @returns {string} The value of the property.
     */
    getProperty(name, def) {
        return this.privSpeechProperties.getProperty(name, def);
    }
    /**
     * Gets/Sets an arbitrary property value.
     * @member SpeechTranslationConfigImpl.prototype.setProperty
     * @function
     * @public
     * @param {string} name - The name of the property.
     * @param {string} value - The value of the property.
     */
    setProperty(name, value) {
        this.privSpeechProperties.setProperty(name, value);
    }
    /**
     * Provides access to custom properties.
     * @member SpeechTranslationConfigImpl.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The properties.
     */
    get properties() {
        return this.privSpeechProperties;
    }
    /**
     * Dispose of associated resources.
     * @member SpeechTranslationConfigImpl.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
    setServiceProperty(name, value, channel) {
        const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServicePropertiesPropertyName"], "{}"));
        currentProperties[name] = value;
        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ServicePropertiesPropertyName"], JSON.stringify(currentProperties));
    }
    setProfanity(profanity) {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_2__["ProfanityOption"][profanity]);
    }
    enableAudioLogging() {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_EnableAudioLogging, "true");
    }
    requestWordLevelTimestamps() {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceResponse_RequestWordLevelTimestamps, "true");
    }
    enableDictation() {
        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ForceDictationPropertyName"], "true");
    }
    get speechSynthesisLanguage() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthLanguage);
    }
    set speechSynthesisLanguage(language) {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthLanguage, language);
    }
    get speechSynthesisVoiceName() {
        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthVoice);
    }
    set speechSynthesisVoiceName(voice) {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthVoice, voice);
    }
    get speechSynthesisOutputFormat() {
        return _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisOutputFormat"][this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, undefined)];
    }
    set speechSynthesisOutputFormat(format) {
        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyId"].SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_2__["SpeechSynthesisOutputFormat"][format]);
    }
}

//# sourceMappingURL=SpeechTranslationConfig.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js ***!
  \******************************************************************************************************************/
/*! exports provided: Conversation, ConversationImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Conversation", function() { return Conversation; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationImpl", function() { return ConversationImpl; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




class Conversation {
    constructor() { }
    /**
     * Create a conversation
     * @param speechConfig
     * @param cb
     * @param err
     */
    static createConversationAsync(speechConfig, arg2, arg3, arg4) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(speechConfig, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].restErrors.invalidArgs.replace("{arg}", "config"));
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(speechConfig.region, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Region"));
        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token])) {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(speechConfig.subscriptionKey, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Key"));
        }
        if (typeof arg2 === "string") {
            const conversationImpl = new ConversationImpl(speechConfig, arg2);
            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () { return; }))(), arg3, arg4);
            return conversationImpl;
        }
        else {
            const conversationImpl = new ConversationImpl(speechConfig);
            const cb = arg2;
            const err = arg3;
            conversationImpl.createConversationAsync((() => {
                if (!!cb) {
                    cb();
                }
            }), (error) => {
                if (!!err) {
                    err(error);
                }
            });
            return conversationImpl;
        }
    }
}
// tslint:disable-next-line:max-classes-per-file
class ConversationImpl extends Conversation {
    /**
     * Create a conversation impl
     * @param speechConfig
     * @param {string} id - optional conversationId
     */
    constructor(speechConfig, id) {
        super();
        this.privIsDisposed = false;
        this.privIsConnected = false;
        this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].restErrors;
        this.privConversationId = "";
        /** websocket callbacks */
        this.onConnected = (e) => {
            this.privIsConnected = true;
            try {
                if (!!this.privConversationTranslator.sessionStarted) {
                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.onDisconnected = (e) => __awaiter(this, void 0, void 0, function* () {
            yield this.close(false);
            try {
                if (!!this.privConversationTranslator.sessionStopped) {
                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        });
        this.onCanceled = (r, e) => __awaiter(this, void 0, void 0, function* () {
            yield this.close(false); // ?
            try {
                if (!!this.privConversationTranslator.canceled) {
                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        });
        this.onParticipantUpdateCommandReceived = (r, e) => {
            var _a, _b;
            try {
                const updatedParticipant = this.privParticipants.getParticipant(e.id);
                if (updatedParticipant !== undefined) {
                    switch (e.key) {
                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].changeNickname:
                            updatedParticipant.displayName = e.value;
                            break;
                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setUseTTS:
                            updatedParticipant.useTts = e.value;
                            break;
                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setProfanityFiltering:
                            updatedParticipant.profanity = e.value;
                            break;
                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setMute:
                            updatedParticipant.isMuted = e.value;
                            break;
                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setTranslateToLanguages:
                            updatedParticipant.translateToLanguages = e.value;
                            break;
                    }
                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);
                    if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.participantsChanged)) {
                        (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"](_Exports__WEBPACK_IMPORTED_MODULE_3__["ParticipantChangedReason"].Updated, [this.toParticipant(updatedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onLockRoomCommandReceived = (r, e) => {
            // TODO
        };
        this.onMuteAllCommandReceived = (r, e) => {
            var _a, _b;
            try {
                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));
                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.participantsChanged)) {
                    (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"](_Exports__WEBPACK_IMPORTED_MODULE_3__["ParticipantChangedReason"].Updated, this.toParticipants(false), e.sessionId));
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantJoinCommandReceived = (r, e) => {
            var _a, _b;
            try {
                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);
                if (newParticipant !== undefined) {
                    if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.participantsChanged)) {
                        (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"](_Exports__WEBPACK_IMPORTED_MODULE_3__["ParticipantChangedReason"].JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantLeaveCommandReceived = (r, e) => {
            var _a, _b;
            try {
                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);
                if (ejectedParticipant !== undefined) {
                    // remove the participant from the internal participants list
                    this.privParticipants.deleteParticipant(e.participant.id);
                    if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.participantsChanged)) {
                        // notify subscribers that the participant has left the conversation
                        (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"](_Exports__WEBPACK_IMPORTED_MODULE_3__["ParticipantChangedReason"].LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onTranslationReceived = (r, e) => {
            var _a, _b, _c, _d, _e, _f;
            try {
                switch (e.command) {
                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].final:
                        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.transcribed)) {
                            (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.transcribed(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationTranslationEventArgs"](e.payload, undefined, e.sessionId));
                        }
                        break;
                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].partial:
                        if (!!((_c = this.privConversationTranslator) === null || _c === void 0 ? void 0 : _c.transcribing)) {
                            (_d = this.privConversationTranslator) === null || _d === void 0 ? void 0 : _d.transcribing(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationTranslationEventArgs"](e.payload, undefined, e.sessionId));
                        }
                        break;
                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].instantMessage:
                        if (!!((_e = this.privConversationTranslator) === null || _e === void 0 ? void 0 : _e.textMessageReceived)) {
                            (_f = this.privConversationTranslator) === null || _f === void 0 ? void 0 : _f.textMessageReceived(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationTranslationEventArgs"](e.payload, undefined, e.sessionId));
                        }
                        break;
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantsListReceived = (r, e) => {
            var _a, _b, _c;
            try {
                // check if the session token needs to be updated
                if (e.sessionToken !== undefined && e.sessionToken !== null) {
                    this.privRoom.token = e.sessionToken;
                }
                // save the participants
                this.privParticipants.participants = [...e.participants];
                // enable the conversation
                if (this.privParticipants.me !== undefined) {
                    this.privIsReady = true;
                }
                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.participantsChanged)) {
                    (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"](_Exports__WEBPACK_IMPORTED_MODULE_3__["ParticipantChangedReason"].JoinedConversation, this.toParticipants(true), e.sessionId));
                }
                // if this is the host, update the nickname if needed
                if (this.me.isHost) {
                    const nickname = (_c = this.privConversationTranslator) === null || _c === void 0 ? void 0 : _c.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Name);
                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {
                        // issue a change nickname request
                        this.changeNicknameAsync(nickname);
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onConversationExpiration = (r, e) => {
            var _a, _b;
            try {
                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.conversationExpiration)) {
                    (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.conversationExpiration(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyCollection"]();
        this.privManager = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationManager"]();
        // check the speech language
        const language = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
        if (!language) {
            speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].defaultLanguageCode);
        }
        this.privLanguage = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
        if (!id) {
            // check the target language(s)
            if (speechConfig.targetLanguages.length === 0) {
                speechConfig.addTargetLanguage(this.privLanguage);
            }
            // check the profanity setting: speech and conversationTranslator should be in sync
            const profanity = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceResponse_ProfanityOption]);
            if (!profanity) {
                speechConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_3__["ProfanityOption"].Masked);
            }
            // check the nickname: it should pass this regex: ^\w+([\s-][\w\(\)]+)*$"
            // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error
            // TODO: check what the max length is and if a truncation is required or if the service handles it without an error
            let hostNickname = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Name]);
            if (hostNickname === undefined || hostNickname === null || hostNickname.length <= 1 || hostNickname.length > 50) {
                hostNickname = "Host";
            }
            speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Name], hostNickname);
        }
        else {
            this.privConversationId = id;
        }
        // save the speech config for future usage
        this.privConfig = speechConfig;
        // save the config properties
        const configImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(configImpl, "speechConfig");
        this.privProperties = configImpl.properties.clone();
        this.privIsConnected = false;
        this.privParticipants = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["InternalParticipants"]();
        this.privIsReady = false;
        this.privTextMessageMaxLength = 1000;
    }
    set conversationTranslator(conversationTranslator) {
        this.privConversationTranslator = conversationTranslator;
    }
    // get the internal data about a conversation
    get room() {
        return this.privRoom;
    }
    // get the wrapper for connecting to the websockets
    get connection() {
        return this.privConversationRecognizer; // this.privConnection;
    }
    // get / set the speech auth token
    get authorizationToken() {
        return this.privToken;
    }
    set authorizationToken(value) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(value, "authorizationToken");
        this.privToken = value;
    }
    // get the config
    get config() {
        return this.privConfig;
    }
    // get the conversation Id
    get conversationId() {
        return this.privRoom ? this.privRoom.roomId : this.privConversationId;
    }
    // get the properties
    get properties() {
        return this.privProperties;
    }
    // get the speech language
    get speechRecognitionLanguage() {
        return this.privLanguage;
    }
    get isMutedByHost() {
        var _a, _b;
        return ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost) ? false : (_b = this.privParticipants.me) === null || _b === void 0 ? void 0 : _b.isMuted;
    }
    get isConnected() {
        return this.privIsConnected && this.privIsReady;
    }
    get participants() {
        return this.toParticipants(true);
    }
    get me() {
        return this.toParticipant(this.privParticipants.me);
    }
    get host() {
        return this.toParticipant(this.privParticipants.host);
    }
    /**
     * Create a new conversation as Host
     * @param cb
     * @param err
     */
    createConversationAsync(cb, err) {
        try {
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {
                if (!room) {
                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);
                }
                this.privRoom = room;
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Starts a new conversation as host.
     * @param cb
     * @param err
     */
    startConversationAsync(cb, err) {
        try {
            // check if there is already a recognizer
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            // check if there is conversation data available
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);
            // connect to the conversation websocket
            this.privParticipants.meId = this.privRoom.participantId;
            this.privConversationRecognizer = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationRecognizerFactory"].fromConfig(this, this.privConfig);
            // Because ConversationTranslator manually sets up and manages the connection, Conversation
            // has to forward serviceRecognizer connection events that usually get passed automatically
            this.privConversationRecognizer.connected = this.onConnected;
            this.privConversationRecognizer.disconnected = this.onDisconnected;
            this.privConversationRecognizer.canceled = this.onCanceled;
            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;
            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;
            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;
            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;
            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;
            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;
            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;
            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;
            this.privConversationRecognizer.connect(this.privRoom.token, (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Join a conversation as a participant.
     * @param { IParticipant } participant - participant to add
     * @param cb
     * @param err
     */
    addParticipantAsync(participant, cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(participant, "Participant");
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.addParticipantImplAsync(participant), cb, err);
    }
    /**
     * Join a conversation as a participant.
     * @param conversation
     * @param nickname
     * @param lang
     * @param cb
     * @param err
     */
    joinConversationAsync(conversationId, nickname, lang, cb, err) {
        try {
            // TODO
            // if (!!this.privConversationRecognizer) {
            //     throw new Error(this.privErrors.permissionDeniedStart);
            // }
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace("{arg}", "conversationId"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace("{arg}", "language"));
            // join the conversation
            this.privManager.createOrJoin(this.privProperties, conversationId, ((room) => {
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);
                this.privRoom = room;
                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;
                // join callback
                if (!!cb) {
                    cb(room.cognitiveSpeechAuthToken);
                }
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Deletes a conversation
     * @param cb
     * @param err
     */
    deleteConversationAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.deleteConversationImplAsync(), cb, err);
    }
    deleteConversationImplAsync() {
        return __awaiter(this, void 0, void 0, function* () {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);
            yield this.privManager.leave(this.privProperties, this.privRoom.token);
            this.dispose();
        });
    }
    /**
     * Issues a request to close the client websockets
     * @param cb
     * @param err
     */
    endConversationAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.endConversationImplAsync(), cb, err);
    }
    endConversationImplAsync() {
        return this.close(true);
    }
    /**
     * Issues a request to lock the conversation
     * @param cb
     * @param err
     */
    lockConversationAsync(cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "lock")), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getLockCommand(true), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute the conversation
     * @param cb
     * @param err
     */
    muteAllParticipantsAsync(cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the user's permissions
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "mute")), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getMuteAllCommand(true), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute a participant in the conversation
     * @param userId
     * @param cb
     * @param err
     */
    muteParticipantAsync(userId, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getMuteCommand(userId, true), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to remove a participant from the conversation
     * @param userId
     * @param cb
     * @param err
     */
    removeParticipantAsync(userId, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty("id")) {
                // Assume this is a transcription participant
                Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.removeParticipantImplAsync(userId), cb, err);
            }
            else {
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
                if (!this.canSendAsHost) {
                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "remove")), err);
                }
                let participantId = "";
                if (typeof userId === "string") {
                    participantId = userId;
                }
                else if (userId.hasOwnProperty("id")) {
                    const participant = userId;
                    participantId = participant.id;
                }
                else if (userId.hasOwnProperty("userId")) {
                    const user = userId;
                    participantId = user.userId;
                }
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
                // check the participant exists
                const index = this.participants.findIndex((p) => p.id === participantId);
                if (index === -1) {
                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
                }
                (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getEjectCommand(participantId), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unlock the conversation
     * @param cb
     * @param err
     */
    unlockConversationAsync(cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unlock")), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getLockCommand(false), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute all participants in the conversation
     * @param cb
     * @param err
     */
    unmuteAllParticipantsAsync(cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unmute all")), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getMuteAllCommand(false), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute a participant in the conversation
     * @param userId
     * @param cb
     * @param err
     */
    unmuteParticipantAsync(userId, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getMuteCommand(userId, false), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Send a text message
     * @param message
     * @param cb
     * @param err
     */
    sendTextMessageAsync(message, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", "message"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // TODO: is a max length check required?
            if (message.length > this.privTextMessageMaxLength) {
                this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "message length")), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getMessageCommand(message), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Change nickname
     * @param message
     * @param cb
     * @param err
     */
    changeNicknameAsync(nickname, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privIsDisposed);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privConversationRecognizer.isDisposed());
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.sendRequest(this.getChangeNicknameCommand(nickname), (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose(reason) {
        var _a;
        if (this.isDisposed) {
            return;
        }
        this.privIsDisposed = true;
        (_a = this.config) === null || _a === void 0 ? void 0 : _a.close();
        this.privConfig = undefined;
        this.privLanguage = undefined;
        this.privProperties = undefined;
        this.privRoom = undefined;
        this.privToken = undefined;
        this.privManager = undefined;
        this.privConversationRecognizer = undefined;
        this.privIsConnected = false;
        this.privIsReady = false;
        this.privParticipants = undefined;
    }
    get transcriberRecognizer() {
        return this.privTranscriberRecognizer;
    }
    connectTranscriberRecognizer(recognizer) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!this.privTranscriberRecognizer) {
                yield this.privTranscriberRecognizer.close();
            }
            this.privTranscriberRecognizer = recognizer;
            this.privTranscriberRecognizer.conversation = this;
        });
    }
    get conversationInfo() {
        const convId = this.conversationId;
        const p = this.participants.map((part) => {
            return {
                id: part.id,
                preferredLanguage: part.preferredLanguage,
                voice: part.voice
            };
        });
        const props = {};
        for (const key of _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].transcriptionEventKeys) {
            const val = this.properties.getProperty(key, "");
            if (val !== "") {
                props[key] = val;
            }
        }
        const info = { id: convId, participants: p, conversationProperties: props };
        return info;
    }
    getKeepAlive() {
        return JSON.stringify({
            // tslint:disable-next-line: object-literal-shorthand
            id: "0",
            nickname: this.me.displayName,
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].keepAlive
        });
    }
    addParticipantImplAsync(participant) {
        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);
        if (newParticipant !== undefined) {
            if (!!this.privTranscriberRecognizer) {
                const conversationInfo = this.conversationInfo;
                conversationInfo.participants = [participant];
                return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "join");
            }
        }
    }
    removeParticipantImplAsync(participant) {
        this.privParticipants.deleteParticipant(participant.id);
        const conversationInfo = this.conversationInfo;
        conversationInfo.participants = [participant];
        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "leave");
    }
    close(dispose) {
        var _a, _b;
        return __awaiter(this, void 0, void 0, function* () {
            try {
                this.privIsConnected = false;
                yield this.privConversationRecognizer.close();
                yield ((_a = this.privTranscriberRecognizer) === null || _a === void 0 ? void 0 : _a.close());
                this.privConversationRecognizer = undefined;
                (_b = this.privConversationTranslator) === null || _b === void 0 ? void 0 : _b.dispose();
            }
            catch (e) {
                // ignore error
            }
            if (dispose) {
                this.dispose();
            }
        });
    }
    /** Helpers */
    get canSend() {
        var _a;
        return this.privIsConnected && !((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isMuted);
    }
    get canSendAsHost() {
        var _a;
        return this.privIsConnected && ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost);
    }
    handleCallback(cb, err) {
        if (!!cb) {
            try {
                cb();
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
            cb = undefined;
        }
    }
    handleError(error, err) {
        if (!!err) {
            if (error instanceof Error) {
                const typedError = error;
                err(typedError.name + ": " + typedError.message);
            }
            else {
                err(error);
            }
        }
    }
    /** Participant Helpers */
    toParticipants(includeHost) {
        const participants = this.privParticipants.participants.map((p) => {
            return this.toParticipant(p);
        });
        if (!includeHost) {
            return participants.filter((p) => p.isHost === false);
        }
        else {
            return participants;
        }
    }
    toParticipant(p) {
        return new _Exports__WEBPACK_IMPORTED_MODULE_3__["Participant"](p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);
    }
    getMuteAllCommand(isMuted) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setMuteAll,
            // tslint:disable-next-line: object-literal-shorthand
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].participantCommand,
            value: isMuted
        });
    }
    getMuteCommand(participantId, isMuted) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setMute,
            // tslint:disable-next-line: object-literal-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].participantCommand,
            value: isMuted
        });
    }
    getLockCommand(isLocked) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].setLockState,
            // tslint:disable-next-line: object-literal-shorthand
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].participantCommand,
            value: isLocked
        });
    }
    getEjectCommand(participantId) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].ejectParticipant,
            // tslint:disable-next-line: object-literal-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].participantCommand,
        });
    }
    getChangeNicknameCommand(nickname) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(nickname, "nickname");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorCommandTypes"].changeNickname,
            nickname,
            // tslint:disable-next-line: object-literal-shorthand
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].participantCommand,
            value: nickname
        });
    }
    getMessageCommand(message) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(message, "message");
        return JSON.stringify({
            // tslint:disable-next-line: object-literal-shorthand
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            text: message,
            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationTranslatorMessageTypes"].instantMessage
        });
    }
}

//# sourceMappingURL=Conversation.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js ***!
  \************************************************************************************************************************/
/*! exports provided: ConversationCommon */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationCommon", function() { return ConversationCommon; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ConversationCommon {
    constructor(audioConfig) {
        this.privAudioConfig = audioConfig;
    }
    handleCallback(cb, err) {
        if (!!cb) {
            try {
                cb();
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
            cb = undefined;
        }
    }
    handleError(error, err) {
        if (!!err) {
            if (error instanceof Error) {
                const typedError = error;
                err(typedError.name + ": " + typedError.message);
            }
            else {
                err(error);
            }
        }
    }
}

//# sourceMappingURL=ConversationCommon.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \*************************************************************************************************************************************/
/*! exports provided: ConversationExpirationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationExpirationEventArgs", function() { return ConversationExpirationEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationExpirationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(expirationTime, sessionId) {
        super(sessionId);
        this.privExpirationTime = expirationTime;
    }
    /** How much longer until the conversation expires (in minutes). */
    get expirationTime() {
        return this.privExpirationTime;
    }
}

//# sourceMappingURL=ConversationExpirationEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \**********************************************************************************************************************************************/
/*! exports provided: ConversationParticipantsChangedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationParticipantsChangedEventArgs", function() { return ConversationParticipantsChangedEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationParticipantsChangedEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    constructor(reason, participants, sessionId) {
        super(sessionId);
        this.privReason = reason;
        this.privParticipant = participants;
    }
    get reason() {
        return this.privReason;
    }
    get participants() {
        return this.privParticipant;
    }
}

//# sourceMappingURL=ConversationParticipantsChangedEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js ***!
  \*****************************************************************************************************************************/
/*! exports provided: ConversationTranscriber */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriber", function() { return ConversationTranscriber; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




class ConversationTranscriber {
    /**
     * ConversationTranscriber constructor.
     * @constructor
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(audioConfig) {
        this.privAudioConfig = audioConfig;
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyCollection"]();
        this.privRecognizer = undefined;
        this.privDisposedRecognizer = false;
    }
    /**
     * @param {Conversation} converation - conversation to be recognized
     */
    joinConversationAsync(conversation, cb, err) {
        const conversationImpl = conversation;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(conversationImpl, "Conversation");
        // ref the conversation object
        // create recognizer and subscribe to recognizer events
        this.privRecognizer = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["TranscriberRecognizer"](conversation.config, this.privAudioConfig);
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privRecognizer, "Recognizer");
        this.privRecognizer.connectCallbacks(this);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(conversationImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member ConversationTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member ConversationTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * Gets the spoken language of recognition.
     * @member ConversationTranscriber.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} The spoken language of recognition.
     */
    get speechRecognitionLanguage() {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    /**
     * The collection of properties and their values defined for this ConversationTranscriber.
     * @member ConversationTranscriber.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this ConversationTranscriber.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts conversation transcription, until stopTranscribingAsync() is called.
     * User must subscribe to events to receive transcription results.
     * @member ConversationTranscriber.prototype.startTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has started.
     * @param err - Callback invoked in case of an error.
     */
    startTranscribingAsync(cb, err) {
        this.privRecognizer.startContinuousRecognitionAsync(cb, err);
    }
    /**
     * Starts conversation transcription, until stopTranscribingAsync() is called.
     * User must subscribe to events to receive transcription results.
     * @member ConversationTranscriber.prototype.stopTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has started.
     * @param err - Callback invoked in case of an error.
     */
    stopTranscribingAsync(cb, err) {
        this.privRecognizer.stopContinuousRecognitionAsync(cb, err);
    }
    /**
     * Leave the current conversation. After this is called, you will no longer receive any events.
     */
    leaveConversationAsync(cb, err) {
        this.privRecognizer.disconnectCallbacks();
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () { return; }))(), cb, err);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member ConversationTranscriber.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfDisposed(this.privDisposedRecognizer);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, errorCb);
    }
    /**
     * Disposes any resources held by the object.
     * @member ConversationTranscriber.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    dispose(disposing) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposedRecognizer) {
                return;
            }
            if (!!this.privRecognizer) {
                yield this.privRecognizer.close();
                this.privRecognizer = undefined;
            }
            if (disposing) {
                this.privDisposedRecognizer = true;
            }
        });
    }
}

//# sourceMappingURL=ConversationTranscriber.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \**********************************************************************************************************************************************/
/*! exports provided: ConversationTranslationCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationCanceledEventArgs", function() { return ConversationTranslationCanceledEventArgs; });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__["CancellationEventArgsBase"] {
}

//# sourceMappingURL=ConversationTranslationCanceledEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \**************************************************************************************************************************************/
/*! exports provided: ConversationTranslationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationEventArgs", function() { return ConversationTranslationEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {ConversationTranslationResult} result - The translation recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @returns {ConversationTranslationResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}

//# sourceMappingURL=ConversationTranslationEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ConversationTranslationResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationResult", function() { return ConversationTranslationResult; });
/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationResult extends _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__["TranslationRecognitionResult"] {
    constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {
        super(translations, resultId, reason, text, duration, offset, errorDetails, json, properties);
        this.privId = participantId;
        this.privOrigLang = originalLanguage;
    }
    /**
     * The unique identifier for the participant this result is for.
     */
    get participantId() {
        return this.privId;
    }
    /**
     * The original language this result was in.
     */
    get originalLang() {
        return this.privOrigLang;
    }
}

//# sourceMappingURL=ConversationTranslationResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js ***!
  \****************************************************************************************************************************/
/*! exports provided: SpeechState, ConversationTranslator */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SpeechState", function() { return SpeechState; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslator", function() { return ConversationTranslator; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Conversation */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};






var SpeechState;
(function (SpeechState) {
    SpeechState[SpeechState["Inactive"] = 0] = "Inactive";
    SpeechState[SpeechState["Connecting"] = 1] = "Connecting";
    SpeechState[SpeechState["Connected"] = 2] = "Connected";
})(SpeechState || (SpeechState = {}));
// tslint:disable:max-classes-per-file
// child class of TranslationRecognizer meant only for use with ConversationTranslator
class ConversationTranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__["TranslationRecognizer"] {
    constructor(speechConfig, audioConfig, translator) {
        super(speechConfig, audioConfig);
        this.privSpeechState = SpeechState.Inactive;
        if (!!translator) {
            this.privTranslator = translator;
            this.sessionStarted = () => {
                this.privSpeechState = SpeechState.Connected;
            };
            this.sessionStopped = () => {
                this.privSpeechState = SpeechState.Inactive;
            };
            this.recognized = (tr, e) => __awaiter(this, void 0, void 0, function* () {
                // TODO: add support for getting recognitions from here if own speech
                var _a;
                // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.
                if ((_a = e.result) === null || _a === void 0 ? void 0 : _a.errorDetails) {
                    yield this.cancelSpeech();
                    // TODO: format the error message contained in 'errorDetails'
                    this.fireCancelEvent(e.result.errorDetails);
                }
            });
            this.canceled = (r, e) => __awaiter(this, void 0, void 0, function* () {
                if (this.privSpeechState !== SpeechState.Inactive) {
                    try {
                        yield this.cancelSpeech();
                    }
                    catch (error) {
                        this.privSpeechState = SpeechState.Inactive;
                    }
                }
            });
        }
    }
    get state() {
        return this.privSpeechState;
    }
    set state(newState) {
        this.privSpeechState = newState;
    }
    onConnection() {
        this.privSpeechState = SpeechState.Connected;
    }
    onDisconnection() {
        return __awaiter(this, void 0, void 0, function* () {
            this.privSpeechState = SpeechState.Inactive;
            yield this.cancelSpeech();
        });
    }
    /**
     * Fire a cancel event
     * @param error
     */
    fireCancelEvent(error) {
        var _a, _b, _c;
        try {
            if (!!this.privTranslator.canceled) {
                const cancelEvent = new _Exports__WEBPACK_IMPORTED_MODULE_5__["ConversationTranslationCanceledEventArgs"]((_a = error === null || error === void 0 ? void 0 : error.reason) !== null && _a !== void 0 ? _a : _Exports__WEBPACK_IMPORTED_MODULE_3__["CancellationReason"].Error, (_b = error === null || error === void 0 ? void 0 : error.errorDetails) !== null && _b !== void 0 ? _b : error, (_c = error === null || error === void 0 ? void 0 : error.errorCode) !== null && _c !== void 0 ? _c : _Exports__WEBPACK_IMPORTED_MODULE_3__["CancellationErrorCode"].RuntimeError, undefined, error === null || error === void 0 ? void 0 : error.sessionId);
                this.privTranslator.canceled(this.privTranslator, cancelEvent);
            }
        }
        catch (e) {
            //
        }
    }
    cancelSpeech() {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            try {
                this.stopContinuousRecognitionAsync();
                yield ((_a = this.privReco) === null || _a === void 0 ? void 0 : _a.disconnect());
                this.privSpeechState = SpeechState.Inactive;
            }
            catch (e) {
                // ignore the error
            }
        });
    }
}
/***
 * Join, leave or connect to a conversation.
 */
class ConversationTranslator extends _Exports__WEBPACK_IMPORTED_MODULE_5__["ConversationCommon"] {
    constructor(audioConfig) {
        super(audioConfig);
        this.privIsDisposed = false;
        this.privIsSpeaking = false;
        this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].restErrors;
        this.privPlaceholderKey = "abcdefghijklmnopqrstuvwxyz012345";
        this.privPlaceholderRegion = "westus";
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyCollection"]();
    }
    get properties() {
        return this.privProperties;
    }
    get speechRecognitionLanguage() {
        return this.privSpeechRecognitionLanguage;
    }
    get participants() {
        var _a;
        return (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.participants;
    }
    joinConversationAsync(conversation, nickname, param1, param2, param3) {
        try {
            if (typeof conversation === "string") {
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
                if (!!this.privConversation) {
                    this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);
                }
                let lang = param1;
                if (lang === undefined || lang === null || lang === "") {
                    lang = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].defaultLanguageCode;
                }
                // create a placeholder config
                this.privSpeechTranslationConfig = _Exports__WEBPACK_IMPORTED_MODULE_3__["SpeechTranslationConfig"].fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);
                this.privSpeechTranslationConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_3__["ProfanityOption"].Masked);
                this.privSpeechTranslationConfig.addTargetLanguage(lang);
                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_RecoLanguage], lang);
                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Name], nickname);
                const endpoint = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Host);
                if (endpoint) {
                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Host], endpoint);
                }
                const speechEndpointHost = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Host);
                if (speechEndpointHost) {
                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Host], speechEndpointHost);
                }
                // join the conversation
                this.privConversation = new _Conversation__WEBPACK_IMPORTED_MODULE_4__["ConversationImpl"](this.privSpeechTranslationConfig);
                this.privConversation.conversationTranslator = this;
                this.privConversation.joinConversationAsync(conversation, nickname, lang, ((result) => {
                    if (!result) {
                        this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);
                    }
                    this.privSpeechTranslationConfig.authorizationToken = result;
                    // connect to the ws
                    this.privConversation.startConversationAsync((() => {
                        this.handleCallback(param2, param3);
                    }), ((error) => {
                        this.handleError(error, param3);
                    }));
                }), ((error) => {
                    this.handleError(error, param3);
                }));
            }
            else if (typeof conversation === "object") {
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
                // save the nickname
                this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].ConversationTranslator_Name, nickname);
                // ref the conversation object
                this.privConversation = conversation;
                // ref the conversation translator object
                this.privConversation.conversationTranslator = this;
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
                this.privSpeechTranslationConfig = conversation.config;
                this.handleCallback(param1, param2);
            }
            else {
                this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "invalid conversation type")), param2);
            }
        }
        catch (error) {
            this.handleError(error, typeof param1 === "string" ? param3 : param2);
        }
    }
    /**
     * Leave the conversation
     * @param cb
     * @param err
     */
    leaveConversationAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            // stop the speech websocket
            yield this.cancelSpeech();
            // stop the websocket
            yield this.privConversation.endConversationImplAsync();
            // https delete request
            yield this.privConversation.deleteConversationImplAsync();
            this.dispose();
        }))(), cb, err);
    }
    /**
     * Send a text message
     * @param message
     * @param cb
     * @param err
     */
    sendTextMessageAsync(message, cb, err) {
        var _a;
        try {
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", message));
            (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.sendTextMessageAsync(message, cb, err);
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Start speaking
     * @param cb
     * @param err
     */
    startTranscribingAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            try {
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
                if (this.privCTRecognizer === undefined) {
                    yield this.connectTranslatorRecognizer();
                }
                _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);
                if (!this.canSpeak) {
                    this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
                }
                yield this.startContinuousRecognition();
                this.privIsSpeaking = true;
            }
            catch (error) {
                this.privIsSpeaking = false;
                yield this.cancelSpeech();
                throw error;
            }
        }))(), cb, err);
    }
    /**
     * Stop speaking
     * @param cb
     * @param err
     */
    stopTranscribingAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            try {
                if (!this.privIsSpeaking) {
                    // stop speech
                    yield this.cancelSpeech();
                    return;
                }
                // stop the recognition but leave the websocket open
                this.privIsSpeaking = false;
                yield new Promise((resolve, reject) => {
                    var _a;
                    (_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.stopContinuousRecognitionAsync(resolve, reject);
                });
            }
            catch (error) {
                yield this.cancelSpeech();
            }
        }))(), cb, err);
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose(reason, success, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            var _a, _b;
            if (this.isDisposed && !this.privIsSpeaking) {
                return;
            }
            yield this.cancelSpeech();
            this.privIsDisposed = true;
            (_a = this.privSpeechTranslationConfig) === null || _a === void 0 ? void 0 : _a.close();
            this.privSpeechRecognitionLanguage = undefined;
            this.privProperties = undefined;
            this.privAudioConfig = undefined;
            this.privSpeechTranslationConfig = undefined;
            (_b = this.privConversation) === null || _b === void 0 ? void 0 : _b.dispose();
            this.privConversation = undefined;
        }))(), success, err);
    }
    /**
     * Cancel the speech websocket
     */
    cancelSpeech() {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            try {
                this.privIsSpeaking = false;
                yield ((_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.onDisconnection());
                this.privCTRecognizer = undefined;
            }
            catch (e) {
                // ignore the error
            }
        });
    }
    /**
     * Connect to the speech translation recognizer.
     * Currently there is no language validation performed before sending the SpeechLanguage code to the service.
     * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'
     * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'
     * @param cb
     * @param err
     */
    connectTranslatorRecognizer() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                if (this.privAudioConfig === undefined) {
                    this.privAudioConfig = _Exports__WEBPACK_IMPORTED_MODULE_3__["AudioConfig"].fromDefaultMicrophoneInput();
                }
                // clear the temp subscription key if it's a participant joining
                if (this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Key])
                    === this.privPlaceholderKey) {
                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Key], "");
                }
                // TODO
                const token = encodeURIComponent(this.privConversation.room.token);
                let endpointHost = this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Host], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].speechHost);
                endpointHost = endpointHost.replace("{region}", this.privConversation.room.cognitiveSpeechRegion);
                const url = `wss://${endpointHost}${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].speechPath}?${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["ConversationConnectionConfig"].configParams.token}=${token}`;
                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceConnection_Endpoint], url);
                this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this);
            }
            catch (error) {
                yield this.cancelSpeech();
                throw error;
            }
        });
    }
    /**
     * Handle the start speaking request
     * @param cb
     * @param err
     */
    startContinuousRecognition() {
        return new Promise((resolve, reject) => {
            this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);
        });
    }
    get canSpeak() {
        // is there a Conversation websocket available and has the Recognizer been set up
        if (!this.privConversation.isConnected || !this.privCTRecognizer) {
            return false;
        }
        // is the user already speaking
        if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {
            return false;
        }
        // is the user muted
        if (this.privConversation.isMutedByHost) {
            return false;
        }
        return true;
    }
}

//# sourceMappingURL=ConversationTranslator.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js ***!
  \*************************************************************************************************************/
/*! exports provided: Conversation, ConversationImpl, ConversationCommon, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, User, ParticipantChangedReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Conversation */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Conversation", function() { return _Conversation__WEBPACK_IMPORTED_MODULE_0__["Conversation"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationImpl", function() { return _Conversation__WEBPACK_IMPORTED_MODULE_0__["ConversationImpl"]; });

/* harmony import */ var _ConversationCommon__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationCommon */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationCommon", function() { return _ConversationCommon__WEBPACK_IMPORTED_MODULE_1__["ConversationCommon"]; });

/* harmony import */ var _ConversationExpirationEventArgs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationExpirationEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationExpirationEventArgs", function() { return _ConversationExpirationEventArgs__WEBPACK_IMPORTED_MODULE_2__["ConversationExpirationEventArgs"]; });

/* harmony import */ var _ConversationParticipantsChangedEventArgs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationParticipantsChangedEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationParticipantsChangedEventArgs", function() { return _ConversationParticipantsChangedEventArgs__WEBPACK_IMPORTED_MODULE_3__["ConversationParticipantsChangedEventArgs"]; });

/* harmony import */ var _ConversationTranslationCanceledEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslationCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationCanceledEventArgs", function() { return _ConversationTranslationCanceledEventArgs__WEBPACK_IMPORTED_MODULE_4__["ConversationTranslationCanceledEventArgs"]; });

/* harmony import */ var _ConversationTranslationEventArgs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslationEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationEventArgs", function() { return _ConversationTranslationEventArgs__WEBPACK_IMPORTED_MODULE_5__["ConversationTranslationEventArgs"]; });

/* harmony import */ var _ConversationTranslationResult__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationTranslationResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslationResult", function() { return _ConversationTranslationResult__WEBPACK_IMPORTED_MODULE_6__["ConversationTranslationResult"]; });

/* harmony import */ var _ConversationTranslator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ConversationTranslator */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranslator", function() { return _ConversationTranslator__WEBPACK_IMPORTED_MODULE_7__["ConversationTranslator"]; });

/* harmony import */ var _ConversationTranscriber__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationTranscriber */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ConversationTranscriber", function() { return _ConversationTranscriber__WEBPACK_IMPORTED_MODULE_8__["ConversationTranscriber"]; });

/* harmony import */ var _IParticipant__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./IParticipant */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Participant", function() { return _IParticipant__WEBPACK_IMPORTED_MODULE_9__["Participant"]; });

/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "User", function() { return _IParticipant__WEBPACK_IMPORTED_MODULE_9__["User"]; });

/* harmony import */ var _ParticipantChangedReason__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./ParticipantChangedReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ParticipantChangedReason", function() { return _ParticipantChangedReason__WEBPACK_IMPORTED_MODULE_10__["ParticipantChangedReason"]; });

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.












//# sourceMappingURL=Exports.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js ***!
  \******************************************************************************************************************/
/*! exports provided: User, Participant */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "User", function() { return User; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Participant", function() { return Participant; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class User {
    constructor(userId) {
        this.privUserId = userId;
    }
    get userId() {
        return this.privUserId;
    }
}
// tslint:disable-next-line: max-classes-per-file
class Participant {
    constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {
        this.privId = id;
        this.privAvatar = avatar;
        this.privDisplayName = displayName;
        this.privIsHost = isHost;
        this.privIsMuted = isMuted;
        this.privIsUsingTts = isUsingTts;
        this.privPreferredLanguage = preferredLanguage;
        this.privVoice = voice;
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyCollection"]();
    }
    static From(id, language, voice) {
        return new Participant(id, "", id, false, false, false, language, voice);
    }
    get avatar() {
        return this.privAvatar;
    }
    get displayName() {
        return this.privDisplayName;
    }
    get id() {
        return this.privId;
    }
    get preferredLanguage() {
        return this.privPreferredLanguage;
    }
    get isHost() {
        return this.privIsHost;
    }
    get isMuted() {
        return this.privIsMuted;
    }
    get isUsingTts() {
        return this.privIsUsingTts;
    }
    get voice() {
        return this.privVoice;
    }
    get properties() {
        return this.privProperties;
    }
}

//# sourceMappingURL=IParticipant.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \******************************************************************************************************************************/
/*! exports provided: ParticipantChangedReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ParticipantChangedReason", function() { return ParticipantChangedReason; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var ParticipantChangedReason;
(function (ParticipantChangedReason) {
    /** Participant has joined the conversation. */
    ParticipantChangedReason[ParticipantChangedReason["JoinedConversation"] = 0] = "JoinedConversation";
    /** Participant has left the conversation. This could be voluntary, or involuntary
     *  (e.g. they are experiencing networking issues).
     */
    ParticipantChangedReason[ParticipantChangedReason["LeftConversation"] = 1] = "LeftConversation";
    /** The participants' state has changed (e.g. they became muted, changed their nickname). */
    ParticipantChangedReason[ParticipantChangedReason["Updated"] = 2] = "Updated";
})(ParticipantChangedReason || (ParticipantChangedReason = {}));

//# sourceMappingURL=ParticipantChangedReason.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: TranslationRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionCanceledEventArgs", function() { return TranslationRecognitionCanceledEventArgs; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define payload of speech recognition canceled result events.
 * @class TranslationRecognitionCanceledEventArgs
 */
class TranslationRecognitionCanceledEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} sessionid - The session id.
     * @param {CancellationReason} cancellationReason - The cancellation reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {TranslationRecognitionResult} result - The result.
     */
    constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {
        this.privCancelReason = cancellationReason;
        this.privErrorDetails = errorDetails;
        this.privResult = result;
        this.privSessionId = sessionid;
        this.privErrorCode = errorCode;
    }
    /**
     * Specifies the recognition result.
     * @member TranslationRecognitionCanceledEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
    /**
     * Specifies the session identifier.
     * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId
     * @function
     * @public
     * @returns {string} the session identifier.
     */
    get sessionId() {
        return this.privSessionId;
    }
    /**
     * The reason the recognition was canceled.
     * @member TranslationRecognitionCanceledEventArgs.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privCancelReason;
    }
    /**
     * The error code in case of an unsuccessful recognition.
     * Added in version 1.1.0.
     * @return An error code that represents the error reason.
     */
    get errorCode() {
        return this.privErrorCode;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
}

//# sourceMappingURL=TranslationRecognitionCanceledEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js ***!
  \***********************************************************************************************************************/
/*! exports provided: TranslationRecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionEventArgs", function() { return TranslationRecognitionEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation text result event arguments.
 * @class TranslationRecognitionEventArgs
 */
class TranslationRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {TranslationRecognitionResult} result - The translation recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @member TranslationRecognitionEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}

//# sourceMappingURL=TranslationRecognitionEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js ***!
  \********************************************************************************************************************/
/*! exports provided: TranslationRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognitionResult", function() { return TranslationRecognitionResult; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation text result.
 * @class TranslationRecognitionResult
 */
class TranslationRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SpeechRecognitionResult"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {Translations} translations - The translations.
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(translations, resultId, reason, text, duration, offset, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, undefined, undefined, undefined, errorDetails, json, properties);
        this.privTranslations = translations;
    }
    /**
     * Presents the translation results. Each item in the dictionary represents
     * a translation result in one of target languages, where the key is the name
     * of the target language, in BCP-47 format, and the value is the translation
     * text in the specified language.
     * @member TranslationRecognitionResult.prototype.translations
     * @function
     * @public
     * @returns {Translations} the current translation map that holds all translations requested.
     */
    get translations() {
        return this.privTranslations;
    }
}

//# sourceMappingURL=TranslationRecognitionResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js ***!
  \*************************************************************************************************************/
/*! exports provided: TranslationRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationRecognizer", function() { return TranslationRecognizer; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Connection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};





/**
 * Translation recognizer
 * @class TranslationRecognizer
 */
class TranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_4__["Recognizer"] {
    /**
     * Initializes an instance of the TranslationRecognizer.
     * @constructor
     * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.
     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
     */
    constructor(speechConfig, audioConfig) {
        const configImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNull(configImpl, "speechConfig");
        super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["TranslationConnectionFactory"]());
        this.privDisposedTranslationRecognizer = false;
        this.privProperties = configImpl.properties.clone();
        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {
            _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationVoice), _Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationVoice]);
        }
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages), _Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages]);
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"][_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_RecoLanguage]);
    }
    /**
     * Gets the language name that was set when the recognizer was created.
     * @member TranslationRecognizer.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} Gets the language name that was set when the recognizer was created.
     */
    get speechRecognitionLanguage() {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets target languages for translation that were set when the recognizer was created.
     * The language is specified in BCP-47 format. The translation will provide translated text for each of language.
     * @member TranslationRecognizer.prototype.targetLanguages
     * @function
     * @public
     * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.
     */
    get targetLanguages() {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages).split(",");
    }
    /**
     * Gets the name of output voice.
     * @member TranslationRecognizer.prototype.voiceName
     * @function
     * @public
     * @returns {string} the name of output voice.
     */
    get voiceName() {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationVoice, undefined);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member TranslationRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member TranslationRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} value - Authorization token.
     */
    set authorizationToken(value) {
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceAuthorization_Token, value);
    }
    /**
     * The collection of properties and their values defined for this TranslationRecognizer.
     * @member TranslationRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts recognition and translation, and stops after the first utterance is recognized.
     * The task returns the translation text as result.
     * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitableonly
     *       for single shot recognition like command or query. For long-running recognition,
     *       use startContinuousRecognitionAsync() instead.
     * @member TranslationRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the result when the translation has completed.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(cb, err) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privDisposedTranslationRecognizer);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Conversation), cb, err);
    }
    /**
     * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.
     * User must subscribe to events to receive translation results.
     * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback that received the translation has started.
     * @param err - Callback invoked in case of an error.
     */
    startContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognitionMode"].Conversation), cb, err);
    }
    /**
     * Stops continuous recognition and translation.
     * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback that received the translation has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopContinuousRecognitionAsync(cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * dynamically remove a language from list of target language
     * (can be used while recognition is ongoing)
     * @member TranslationRecognizer.prototype.removeTargetLanguage
     * @function
     * @param lang - language to be removed
     * @public
     */
    removeTargetLanguage(lang) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrUndefined(lang, "language to be removed");
        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            const languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages).split(",");
            const index = languages.indexOf(lang);
            if (index > -1) {
                languages.splice(index, 1);
                this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, languages.join(","));
                this.updateLanguages(languages);
            }
        }
    }
    /**
     * dynamically add a language to list of target language
     * (can be used while recognition is ongoing)
     * @member TranslationRecognizer.prototype.addTargetLanguage
     * @function
     * @param lang - language to be added
     * @public
     */
    addTargetLanguage(lang) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfNullOrUndefined(lang, "language to be added");
        let languages = [];
        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages).split(",");
            if (!languages.includes(lang)) {
                languages.push(lang);
                this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, languages.join(","));
            }
        }
        else {
            this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__["PropertyId"].SpeechServiceConnection_TranslationToLanguages, lang);
            languages = [lang];
        }
        this.updateLanguages(languages);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member TranslationRecognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        _Contracts__WEBPACK_IMPORTED_MODULE_3__["Contracts"].throwIfDisposed(this.privDisposedTranslationRecognizer);
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])(this.dispose(true), cb, errorCb);
    }
    /**
     * handles ConnectionEstablishedEvent for conversation translation scenarios.
     * @member TranslationRecognizer.prototype.onConnection
     * @function
     * @public
     */
    /* tslint:disable:no-empty */
    onConnection() { }
    /**
     * handles disconnection events for conversation translation scenarios.
     * @member TranslationRecognizer.prototype.onDisconnection
     * @function
     * @public
     */
    /* tslint:disable:no-empty */
    onDisconnection() {
        return __awaiter(this, void 0, void 0, function* () { });
    }
    dispose(disposing) {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            if (this.privDisposedTranslationRecognizer) {
                return;
            }
            this.privDisposedTranslationRecognizer = true;
            if (disposing) {
                yield this.implRecognizerStop();
                yield _super.dispose.call(this, disposing);
            }
        });
    }
    createRecognizerConfig(speechConfig) {
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["RecognizerConfig"](speechConfig, this.properties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["TranslationServiceRecognizer"](authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
    updateLanguages(languages) {
        const conn = _Connection__WEBPACK_IMPORTED_MODULE_2__["Connection"].fromRecognizer(this);
        if (!!conn) {
            conn.setMessageProperty("speech.context", "translationcontext", { to: languages });
            conn.sendMessageAsync("event", JSON.stringify({
                id: "translation",
                name: "updateLanguage",
                to: languages
            }));
        }
    }
}

//# sourceMappingURL=TranslationRecognizer.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js ***!
  \*********************************************************************************************************************/
/*! exports provided: TranslationSynthesisEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisEventArgs", function() { return TranslationSynthesisEventArgs; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation Synthesis event arguments
 * @class TranslationSynthesisEventArgs
 */
class TranslationSynthesisEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__["SessionEventArgs"] {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {TranslationSynthesisResult} result - The translation synthesis result.
     * @param {string} sessionId - The session id.
     */
    constructor(result, sessionId) {
        super(sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the translation synthesis result.
     * @member TranslationSynthesisEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.
     */
    get result() {
        return this.privResult;
    }
}

//# sourceMappingURL=TranslationSynthesisEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js ***!
  \******************************************************************************************************************/
/*! exports provided: TranslationSynthesisResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TranslationSynthesisResult", function() { return TranslationSynthesisResult; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines translation synthesis result, i.e. the voice output of the translated
 * text in the target language.
 * @class TranslationSynthesisResult
 */
class TranslationSynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {ResultReason} reason - The synthesis reason.
     * @param {ArrayBuffer} audio - The audio data.
     */
    constructor(reason, audio) {
        this.privReason = reason;
        this.privAudio = audio;
    }
    /**
     * Translated text in the target language.
     * @member TranslationSynthesisResult.prototype.audio
     * @function
     * @public
     * @returns {ArrayBuffer} Translated audio in the target language.
     */
    get audio() {
        return this.privAudio;
    }
    /**
     * The synthesis status.
     * @member TranslationSynthesisResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} The synthesis status.
     */
    get reason() {
        return this.privReason;
    }
}

//# sourceMappingURL=TranslationSynthesisResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js ***!
  \****************************************************************************************************/
/*! exports provided: Translations */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Translations", function() { return Translations; });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents collection of parameters and their values.
 * @class Translations
 */
class Translations {
    constructor() {
        // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.
        this.privMap = new _Exports__WEBPACK_IMPORTED_MODULE_0__["PropertyCollection"]();
    }
    /**
     * Returns the parameter value in type String. The parameter must have the same type as String.
     * Currently only String, int and bool are allowed.
     * If the name is not available, the specified defaultValue is returned.
     * @member Translations.prototype.get
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} def - The default value which is returned if the parameter is not available in the collection.
     * @returns {string} value of the parameter.
     */
    get(key, def) {
        return this.privMap.getProperty(key, def);
    }
    /**
     * Sets the String value of the parameter specified by name.
     * @member Translations.prototype.set
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} value - The value of the parameter.
     */
    set(key, value) {
        this.privMap.setProperty(key, value);
    }
    /**
     * Get the languages in the object in a String array.
     * @member Translations.prototype.languages
     * @function
     * @public
     * @returns {string[]} languages in translations object.
     */
    get languages() {
        return this.privMap.keys;
    }
}

//# sourceMappingURL=Translations.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \*******************************************************************************************************************/
/*! exports provided: TurnStatusReceivedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TurnStatusReceivedEventArgs", function() { return TurnStatusReceivedEventArgs; });
/* harmony import */ var _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines contents of received message/events.
 * @class TurnStatusReceivedEventArgs
 */
class TurnStatusReceivedEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} turnStatus - The JSON-encoded turn status message.
     */
    constructor(turnStatus) {
        this.privTurnStatus = _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__["TurnStatusResponsePayload"].fromJSON(turnStatus);
    }
    /**
     * Gets the interaction identifier associated with this turn status event.
     * @member TurnStatusReceivedEventArgs.prototype.interactionId
     * @function
     * @public
     * @returns {any} the received interaction id.
     */
    get interactionId() {
        return this.privTurnStatus.interactionId;
    }
    /**
     * Gets the conversation identifier associated with this turn status event.
     * @member TurnStatusReceivedEventArgs.prototype.conversationId
     * @function
     * @public
     * @returns {any} the received conversation id.
     */
    get conversationId() {
        return this.privTurnStatus.conversationId;
    }
    /**
     * Gets the received turn status code.
     * @member TurnStatusReceivedEventArgs.prototype.statusCode
     * @function
     * @public
     * @returns {number} the received turn status.
     */
    get statusCode() {
        return this.privTurnStatus.statusCode;
    }
}

//# sourceMappingURL=TurnStatusReceivedEventArgs.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js ***!
  \****************************************************************************************************/
/*! exports provided: VoiceProfile */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfile", function() { return VoiceProfile; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines Voice Profile class for Speaker Recognition
 * @class VoiceProfile
 */
class VoiceProfile {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} profileId - profileId of this Voice Profile.
     * @param {VoiceProfileType} profileType - profileType of this Voice Profile.
     */
    constructor(profileId, profileType) {
        this.privId = profileId;
        this.privProfileType = profileType;
    }
    /**
     * profileId of this Voice Profile instance
     * @member VoiceProfile.prototype.profileId
     * @function
     * @public
     * @returns {string} profileId of this Voice Profile instance.
     */
    get profileId() {
        return this.privId;
    }
    /**
     * profileType of this Voice Profile instance
     * @member VoiceProfile.prototype.profileType
     * @function
     * @public
     * @returns {VoiceProfileType} profile type of this Voice Profile instance.
     */
    get profileType() {
        return this.privProfileType;
    }
}

//# sourceMappingURL=VoiceProfile.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js ***!
  \**********************************************************************************************************/
/*! exports provided: VoiceProfileClient */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileClient", function() { return VoiceProfileClient; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * Defines VoiceProfileClient class for Speaker Recognition
 * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)
 * @class VoiceProfileClient
 */
class VoiceProfileClient {
    /**
     * VoiceProfileClient constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)
     */
    constructor(speechConfig) {
        const speechConfigImpl = speechConfig;
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNull(speechConfigImpl, "speechConfig");
        this.privProperties = speechConfigImpl.properties.clone();
        this.implClientSetup();
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member VoiceProfileClient.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member VoiceProfileClient.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__["PropertyId"].SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this VoiceProfileClient.
     * @member VoiceProfileClient.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Create a speaker recognition voice profile
     * @member VoiceProfileClient.prototype.createProfileAsync
     * @function
     * @public
     * @param {VoiceProfileType} profileType Type of Voice Profile to be created
     *        specifies the keyword to be recognized.
     * @param {string} lang Language string (locale) for Voice Profile
     * @param cb - Callback invoked once Voice Profile has been created.
     * @param err - Callback invoked in case of an error.
     */
    createProfileAsync(profileType, lang, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.createProfile(profileType, lang);
            if (!result.ok) {
                throw new Error(`createProfileAsync failed with code: ${result.status}, message: ${result.statusText}`);
            }
            const response = result.json;
            const profile = new _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfile"](response.profileId, profileType);
            return profile;
        }))(), cb, err);
    }
    /**
     * Get current information of a voice profile
     * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync
     * @function
     * @public
     * @param {VoiceProfile} profile Voice Profile to retrieve info for
     * @param cb - Callback invoked once Voice Profile has been created.
     * @param err - Callback invoked in case of an error.
     */
    retrieveEnrollmentResultAsync(profile, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.getProfileStatus(profile);
            return new _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileEnrollmentResult"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].Canceled, result.data, result.statusText);
        }))(), cb, err);
    }
    /**
     * Get all voice profiles on account with given voice profile type
     * @member VoiceProfileClient.prototype.getAllProfilesAsync
     * @function
     * @public
     * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles
     * @param cb - Callback invoked once Profile list has been returned.
     * @param err - Callback invoked in case of an error.
     */
    getAllProfilesAsync(profileType, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.getProfiles(profileType);
            if (profileType === _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileType"].TextIndependentIdentification) {
                return _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileEnrollmentResult"].FromIdentificationProfileList(result.json);
            }
            return _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileEnrollmentResult"].FromVerificationProfileList(result.json);
        }))(), cb, err);
    }
    /**
     * Get valid authorization phrases for voice profile enrollment
     * @member VoiceProfileClient.prototype.getAuthorizationPhrasesAsync
     * @function
     * @public
     * @param {string} lang Language string (locale) for Voice Profile
     * @param cb - Callback invoked once phrases have been returned.
     * @param err - Callback invoked in case of an error.
     */
    getActivationPhrasesAsync(profileType, lang, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.getPhrases(profileType, lang);
            return new _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfilePhraseResult"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].EnrollingVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].Canceled, result.statusText, result.json);
        }))(), cb, err);
    }
    /**
     * Create a speaker recognition voice profile
     * @member VoiceProfileClient.prototype.enrollProfileAsync
     * @function
     * @public
     * @async
     * @param {VoiceProfile} profile Voice Profile to create enrollment for
     * @param {AudioConfig} audioConfig source info from which to create enrollment
     * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.
     */
    enrollProfileAsync(profile, audioConfig) {
        return __awaiter(this, void 0, void 0, function* () {
            const configImpl = audioConfig;
            _Contracts__WEBPACK_IMPORTED_MODULE_2__["Contracts"].throwIfNullOrUndefined(configImpl, "audioConfig");
            const result = yield this.privAdapter.createEnrollment(profile, configImpl);
            return new _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileEnrollmentResult"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].Canceled, result.data, result.statusText);
        });
    }
    /**
     * Delete a speaker recognition voice profile
     * @member VoiceProfileClient.prototype.deleteProfileAsync
     * @function
     * @public
     * @param {VoiceProfile} profile Voice Profile to be deleted
     * @param cb - Callback invoked once Voice Profile has been deleted.
     * @param err - Callback invoked in case of an error.
     */
    deleteProfileAsync(profile, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.deleteProfile(profile);
            return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].DeletedVoiceProfile);
        }))(), cb, err);
    }
    /**
     * Remove all enrollments for a speaker recognition voice profile
     * @member VoiceProfileClient.prototype.resetProfileAsync
     * @function
     * @public
     * @param {VoiceProfile} profile Voice Profile to be reset
     * @param cb - Callback invoked once Voice Profile has been reset.
     * @param err - Callback invoked in case of an error.
     */
    resetProfileAsync(profile, cb, err) {
        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__["marshalPromiseToCallbacks"])((() => __awaiter(this, void 0, void 0, function* () {
            const result = yield this.privAdapter.resetProfile(profile);
            return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].ResetVoiceProfile);
        }))(), cb, err);
    }
    /**
     * Included for compatibility
     * @member VoiceProfileClient.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
    // Does class setup, swiped from Recognizer.
    implClientSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeakerRecognitionConfig"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["Context"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["OS"](osPlatform, osName, osVersion)), this.privProperties);
        this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["SpeakerIdMessageAdapter"](recognizerConfig);
    }
    getResult(result, successReason, cb) {
        const response = new _Exports__WEBPACK_IMPORTED_MODULE_3__["VoiceProfileResult"](result.ok ? successReason : _Exports__WEBPACK_IMPORTED_MODULE_3__["ResultReason"].Canceled, result.statusText);
        return (response);
    }
}

//# sourceMappingURL=VoiceProfileClient.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js ***!
  \********************************************************************************************************************/
/*! exports provided: VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentResult", function() { return VoiceProfileEnrollmentResult; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileEnrollmentCancellationDetails", function() { return VoiceProfileEnrollmentCancellationDetails; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Output format
 * @class VoiceProfileEnrollmentResult
 */
class VoiceProfileEnrollmentResult {
    constructor(reason, json, statusText) {
        this.privReason = reason;
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__["PropertyCollection"]();
        if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled) {
            if (!!json) {
                this.privDetails = JSON.parse(json);
                if (this.privDetails.enrollmentStatus.toLowerCase() === "enrolling") {
                    this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].EnrollingVoiceProfile;
                }
            }
        }
        else {
            this.privErrorDetails = statusText;
            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].ServiceError]);
        }
    }
    static FromIdentificationProfileList(json) {
        const results = [];
        for (const item of json.profiles) {
            const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ?
                _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ?
                _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled;
            const result = new VoiceProfileEnrollmentResult(reason, null, null);
            result.privDetails = this.getIdentificationDetails(item);
            results.push(result);
        }
        return results;
    }
    static FromVerificationProfileList(json) {
        const results = [];
        for (const item of json.profiles) {
            const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ?
                _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ?
                _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__["ResultReason"].Canceled;
            const result = new VoiceProfileEnrollmentResult(reason, null, null);
            result.privDetails = this.getVerificationDetails(item);
            results.push(result);
        }
        return results;
    }
    get reason() {
        return this.privReason;
    }
    get enrollmentsCount() {
        return this.privDetails.enrollmentsCount;
    }
    get enrollmentsLength() {
        return this.privDetails.enrollmentsLength;
    }
    get properties() {
        return this.privProperties;
    }
    get enrollmentResultDetails() {
        return this.privDetails;
    }
    get errorDetails() {
        return this.privErrorDetails;
    }
    static getIdentificationDetails(json) {
        return {
            audioSpeechLength: json.speechTime ? parseFloat(json.speechTime) : 0,
            enrollmentStatus: json.enrollmentStatus,
            enrollmentsLength: json.enrollmentSpeechTime ? parseFloat(json.enrollmentSpeechTime) : 0,
            profileId: json.profileId || json.identificationProfileId,
            remainingEnrollmentSpeechLength: json.remainingEnrollmentSpeechTime ? parseFloat(json.remainingEnrollmentSpeechTime) : 0
        };
    }
    static getVerificationDetails(json) {
        return {
            enrollmentStatus: json.enrollmentStatus,
            enrollmentsCount: json.enrollmentsCount,
            profileId: json.profileId || json.verificationProfileId,
            remainingEnrollmentSpeechLength: json.remainingEnrollmentSpeechLength ? parseFloat(json.remainingEnrollmentSpeechLength) : 0,
            remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount
        };
    }
}
/**
 * @class VoiceProfileEnrollmentCancellationDetails
 */
// tslint:disable-next-line:max-classes-per-file
class VoiceProfileEnrollmentCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationDetailsBase"] {
    constructor(reason, errorDetails, errorCode) {
        super(reason, errorDetails, errorCode);
    }
    /**
     * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.
     * @member VoiceProfileEnrollmentCancellationDetails.fromResult
     * @function
     * @public
     * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.
     * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.
     */
    static fromResult(result) {
        const reason = _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationReason"].Error;
        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].NoError;
        if (!!result.properties) {
            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_1__["CancellationErrorCode"].NoError])];
        }
        return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);
    }
}

//# sourceMappingURL=VoiceProfileEnrollmentResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js ***!
  \****************************************************************************************************************/
/*! exports provided: VoiceProfilePhraseResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfilePhraseResult", function() { return VoiceProfilePhraseResult; });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Output format
 * @class VoiceProfilePhraseResult
 */
class VoiceProfilePhraseResult extends _Exports__WEBPACK_IMPORTED_MODULE_1__["VoiceProfileResult"] {
    constructor(reason, statusText, json) {
        super(reason, statusText);
        this.privPhrases = [];
        _Contracts__WEBPACK_IMPORTED_MODULE_0__["Contracts"].throwIfNullOrUndefined(json, "phrases array");
        for (const item of json) {
            this.privPhrases.push(item.passPhrase || item.activationPhrase);
        }
    }
    get phrases() {
        return this.privPhrases;
    }
}

//# sourceMappingURL=VoiceProfilePhraseResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js ***!
  \**********************************************************************************************************/
/*! exports provided: VoiceProfileResult, VoiceProfileCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileResult", function() { return VoiceProfileResult; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileCancellationDetails", function() { return VoiceProfileCancellationDetails; });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Output format
 * @class VoiceProfileResult
 */
class VoiceProfileResult {
    constructor(reason, statusText) {
        this.privReason = reason;
        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__["PropertyCollection"]();
        if (reason === _Exports__WEBPACK_IMPORTED_MODULE_2__["ResultReason"].Canceled) {
            _Contracts__WEBPACK_IMPORTED_MODULE_1__["Contracts"].throwIfNullOrUndefined(statusText, "statusText");
            this.privErrorDetails = statusText;
            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].ServiceError]);
        }
    }
    get reason() {
        return this.privReason;
    }
    get properties() {
        return this.privProperties;
    }
    get errorDetails() {
        return this.privErrorDetails;
    }
}
/**
 * @class VoiceProfileCancellationDetails
 */
// tslint:disable-next-line:max-classes-per-file
class VoiceProfileCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationDetailsBase"] {
    constructor(reason, errorDetails, errorCode) {
        super(reason, errorDetails, errorCode);
    }
    /**
     * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.
     * @member VoiceProfileCancellationDetails.fromResult
     * @function
     * @public
     * @param {VoiceProfileResult} result - The result that was canceled.
     * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.
     */
    static fromResult(result) {
        const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationReason"].Error;
        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError;
        if (!!result.properties) {
            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__["CancellationErrorCodePropertyName"], _Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"][_Exports__WEBPACK_IMPORTED_MODULE_2__["CancellationErrorCode"].NoError])];
        }
        return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);
    }
}

//# sourceMappingURL=VoiceProfileResult.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js ***!
  \********************************************************************************************************/
/*! exports provided: VoiceProfileType */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "VoiceProfileType", function() { return VoiceProfileType; });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Output format
 * @class VoiceProfileType
 */
var VoiceProfileType;
(function (VoiceProfileType) {
    /**
     * Text independent speaker identification
     * @member VoiceProfileType.TextIndependentIdentification
     */
    VoiceProfileType[VoiceProfileType["TextIndependentIdentification"] = 0] = "TextIndependentIdentification";
    /**
     * Text dependent speaker verification
     * @member VoiceProfileType.TextDependentVerification
     */
    VoiceProfileType[VoiceProfileType["TextDependentVerification"] = 1] = "TextDependentVerification";
    /**
     * Text independent speaker verification
     * @member VoiceProfileType.TextIndependentVerification
     */
    VoiceProfileType[VoiceProfileType["TextIndependentVerification"] = 2] = "TextIndependentVerification";
})(VoiceProfileType || (VoiceProfileType = {}));

//# sourceMappingURL=VoiceProfileType.js.map


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/index.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/index.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var v1 = __webpack_require__(/*! ./v1 */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v1.js");
var v4 = __webpack_require__(/*! ./v4 */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v4.js");

var uuid = v4;
uuid.v1 = v1;
uuid.v4 = v4;

module.exports = uuid;


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/bytesToUuid.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/bytesToUuid.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */
var byteToHex = [];
for (var i = 0; i < 256; ++i) {
  byteToHex[i] = (i + 0x100).toString(16).substr(1);
}

function bytesToUuid(buf, offset) {
  var i = offset || 0;
  var bth = byteToHex;
  // join used to fix memory issue caused by concatenation: https://bugs.chromium.org/p/v8/issues/detail?id=3175#c4
  return ([
    bth[buf[i++]], bth[buf[i++]],
    bth[buf[i++]], bth[buf[i++]], '-',
    bth[buf[i++]], bth[buf[i++]], '-',
    bth[buf[i++]], bth[buf[i++]], '-',
    bth[buf[i++]], bth[buf[i++]], '-',
    bth[buf[i++]], bth[buf[i++]],
    bth[buf[i++]], bth[buf[i++]],
    bth[buf[i++]], bth[buf[i++]]
  ]).join('');
}

module.exports = bytesToUuid;


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/rng-browser.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/rng-browser.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// Unique ID creation requires a high quality random # generator.  In the
// browser this is a little complicated due to unknown quality of Math.random()
// and inconsistent support for the `crypto` API.  We do the best we can via
// feature-detection

// getRandomValues needs to be invoked in a context where "this" is a Crypto
// implementation. Also, find the complete implementation of crypto on IE11.
var getRandomValues = (typeof(crypto) != 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto)) ||
                      (typeof(msCrypto) != 'undefined' && typeof window.msCrypto.getRandomValues == 'function' && msCrypto.getRandomValues.bind(msCrypto));

if (getRandomValues) {
  // WHATWG crypto RNG - http://wiki.whatwg.org/wiki/Crypto
  var rnds8 = new Uint8Array(16); // eslint-disable-line no-undef

  module.exports = function whatwgRNG() {
    getRandomValues(rnds8);
    return rnds8;
  };
} else {
  // Math.random()-based (RNG)
  //
  // If all else fails, use Math.random().  It's fast, but is of unspecified
  // quality.
  var rnds = new Array(16);

  module.exports = function mathRNG() {
    for (var i = 0, r; i < 16; i++) {
      if ((i & 0x03) === 0) r = Math.random() * 0x100000000;
      rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;
    }

    return rnds;
  };
}


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v1.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v1.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var rng = __webpack_require__(/*! ./lib/rng */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/rng-browser.js");
var bytesToUuid = __webpack_require__(/*! ./lib/bytesToUuid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/bytesToUuid.js");

// **`v1()` - Generate time-based UUID**
//
// Inspired by https://github.com/LiosK/UUID.js
// and http://docs.python.org/library/uuid.html

var _nodeId;
var _clockseq;

// Previous uuid creation time
var _lastMSecs = 0;
var _lastNSecs = 0;

// See https://github.com/uuidjs/uuid for API details
function v1(options, buf, offset) {
  var i = buf && offset || 0;
  var b = buf || [];

  options = options || {};
  var node = options.node || _nodeId;
  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq;

  // node and clockseq need to be initialized to random values if they're not
  // specified.  We do this lazily to minimize issues related to insufficient
  // system entropy.  See #189
  if (node == null || clockseq == null) {
    var seedBytes = rng();
    if (node == null) {
      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)
      node = _nodeId = [
        seedBytes[0] | 0x01,
        seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]
      ];
    }
    if (clockseq == null) {
      // Per 4.2.2, randomize (14 bit) clockseq
      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;
    }
  }

  // UUID timestamps are 100 nano-second units since the Gregorian epoch,
  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so
  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'
  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.
  var msecs = options.msecs !== undefined ? options.msecs : new Date().getTime();

  // Per 4.2.1.2, use count of uuid's generated during the current clock
  // cycle to simulate higher resolution clock
  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;

  // Time since last uuid creation (in msecs)
  var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;

  // Per 4.2.1.2, Bump clockseq on clock regression
  if (dt < 0 && options.clockseq === undefined) {
    clockseq = clockseq + 1 & 0x3fff;
  }

  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new
  // time interval
  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {
    nsecs = 0;
  }

  // Per 4.2.1.2 Throw error if too many uuids are requested
  if (nsecs >= 10000) {
    throw new Error('uuid.v1(): Can\'t create more than 10M uuids/sec');
  }

  _lastMSecs = msecs;
  _lastNSecs = nsecs;
  _clockseq = clockseq;

  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch
  msecs += 12219292800000;

  // `time_low`
  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;
  b[i++] = tl >>> 24 & 0xff;
  b[i++] = tl >>> 16 & 0xff;
  b[i++] = tl >>> 8 & 0xff;
  b[i++] = tl & 0xff;

  // `time_mid`
  var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;
  b[i++] = tmh >>> 8 & 0xff;
  b[i++] = tmh & 0xff;

  // `time_high_and_version`
  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version
  b[i++] = tmh >>> 16 & 0xff;

  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)
  b[i++] = clockseq >>> 8 | 0x80;

  // `clock_seq_low`
  b[i++] = clockseq & 0xff;

  // `node`
  for (var n = 0; n < 6; ++n) {
    b[i + n] = node[n];
  }

  return buf ? buf : bytesToUuid(b);
}

module.exports = v1;


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v4.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/v4.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var rng = __webpack_require__(/*! ./lib/rng */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/rng-browser.js");
var bytesToUuid = __webpack_require__(/*! ./lib/bytesToUuid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/lib/bytesToUuid.js");

function v4(options, buf, offset) {
  var i = buf && offset || 0;

  if (typeof(options) == 'string') {
    buf = options === 'binary' ? new Array(16) : null;
    options = null;
  }
  options = options || {};

  var rnds = options.random || (options.rng || rng)();

  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`
  rnds[6] = (rnds[6] & 0x0f) | 0x40;
  rnds[8] = (rnds[8] & 0x3f) | 0x80;

  // Copy bytes to buffer, if provided
  if (buf) {
    for (var ii = 0; ii < 16; ++ii) {
      buf[i + ii] = rnds[ii];
    }
  }

  return buf || bytesToUuid(rnds);
}

module.exports = v4;


/***/ }),

/***/ "./node_modules/process-nextick-args/index.js":
/*!****************************************************!*\
  !*** ./node_modules/process-nextick-args/index.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* WEBPACK VAR INJECTION */(function(process) {

if (typeof process === 'undefined' ||
    !process.version ||
    process.version.indexOf('v0.') === 0 ||
    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {
  module.exports = { nextTick: nextTick };
} else {
  module.exports = process
}

function nextTick(fn, arg1, arg2, arg3) {
  if (typeof fn !== 'function') {
    throw new TypeError('"callback" argument must be a function');
  }
  var len = arguments.length;
  var args, i;
  switch (len) {
  case 0:
  case 1:
    return process.nextTick(fn);
  case 2:
    return process.nextTick(function afterTickOne() {
      fn.call(null, arg1);
    });
  case 3:
    return process.nextTick(function afterTickTwo() {
      fn.call(null, arg1, arg2);
    });
  case 4:
    return process.nextTick(function afterTickThree() {
      fn.call(null, arg1, arg2, arg3);
    });
  default:
    args = new Array(len - 1);
    i = 0;
    while (i < args.length) {
      args[i++] = arguments[i];
    }
    return process.nextTick(function afterTick() {
      fn.apply(null, args);
    });
  }
}


/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ "./node_modules/process/browser.js")))

/***/ }),

/***/ "./node_modules/querystringify/index.js":
/*!**********************************************!*\
  !*** ./node_modules/querystringify/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


var has = Object.prototype.hasOwnProperty
  , undef;

/**
 * Decode a URI encoded string.
 *
 * @param {String} input The URI encoded string.
 * @returns {String|Null} The decoded string.
 * @api private
 */
function decode(input) {
  try {
    return decodeURIComponent(input.replace(/\+/g, ' '));
  } catch (e) {
    return null;
  }
}

/**
 * Attempts to encode a given input.
 *
 * @param {String} input The string that needs to be encoded.
 * @returns {String|Null} The encoded string.
 * @api private
 */
function encode(input) {
  try {
    return encodeURIComponent(input);
  } catch (e) {
    return null;
  }
}

/**
 * Simple query string parser.
 *
 * @param {String} query The query string that needs to be parsed.
 * @returns {Object}
 * @api public
 */
function querystring(query) {
  var parser = /([^=?#&]+)=?([^&]*)/g
    , result = {}
    , part;

  while (part = parser.exec(query)) {
    var key = decode(part[1])
      , value = decode(part[2]);

    //
    // Prevent overriding of existing properties. This ensures that build-in
    // methods like `toString` or __proto__ are not overriden by malicious
    // querystrings.
    //
    // In the case if failed decoding, we want to omit the key/value pairs
    // from the result.
    //
    if (key === null || value === null || key in result) continue;
    result[key] = value;
  }

  return result;
}

/**
 * Transform a query string to an object.
 *
 * @param {Object} obj Object that should be transformed.
 * @param {String} prefix Optional prefix.
 * @returns {String}
 * @api public
 */
function querystringify(obj, prefix) {
  prefix = prefix || '';

  var pairs = []
    , value
    , key;

  //
  // Optionally prefix with a '?' if needed
  //
  if ('string' !== typeof prefix) prefix = '?';

  for (key in obj) {
    if (has.call(obj, key)) {
      value = obj[key];

      //
      // Edge cases where we actually want to encode the value to an empty
      // string instead of the stringified value.
      //
      if (!value && (value === null || value === undef || isNaN(value))) {
        value = '';
      }

      key = encode(key);
      value = encode(value);

      //
      // If we failed to encode the strings, we should bail out as we don't
      // want to add invalid strings to the query.
      //
      if (key === null || value === null) continue;
      pairs.push(key +'='+ value);
    }
  }

  return pairs.length ? prefix + pairs.join('&') : '';
}

//
// Expose the module.
//
exports.stringify = querystringify;
exports.parse = querystring;


/***/ }),

/***/ "./node_modules/readable-stream/duplex-browser.js":
/*!********************************************************!*\
  !*** ./node_modules/readable-stream/duplex-browser.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = __webpack_require__(/*! ./lib/_stream_duplex.js */ "./node_modules/readable-stream/lib/_stream_duplex.js");


/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// a duplex stream is just a stream that is both readable and writable.
// Since JS doesn't have multiple prototypal inheritance, this class
// prototypally inherits from Readable, and then parasitically from
// Writable.



/*<replacement>*/

var pna = __webpack_require__(/*! process-nextick-args */ "./node_modules/process-nextick-args/index.js");
/*</replacement>*/

/*<replacement>*/
var objectKeys = Object.keys || function (obj) {
  var keys = [];
  for (var key in obj) {
    keys.push(key);
  }return keys;
};
/*</replacement>*/

module.exports = Duplex;

/*<replacement>*/
var util = Object.create(__webpack_require__(/*! core-util-is */ "./node_modules/core-util-is/lib/util.js"));
util.inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");
/*</replacement>*/

var Readable = __webpack_require__(/*! ./_stream_readable */ "./node_modules/readable-stream/lib/_stream_readable.js");
var Writable = __webpack_require__(/*! ./_stream_writable */ "./node_modules/readable-stream/lib/_stream_writable.js");

util.inherits(Duplex, Readable);

{
  // avoid scope creep, the keys array can then be collected
  var keys = objectKeys(Writable.prototype);
  for (var v = 0; v < keys.length; v++) {
    var method = keys[v];
    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];
  }
}

function Duplex(options) {
  if (!(this instanceof Duplex)) return new Duplex(options);

  Readable.call(this, options);
  Writable.call(this, options);

  if (options && options.readable === false) this.readable = false;

  if (options && options.writable === false) this.writable = false;

  this.allowHalfOpen = true;
  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;

  this.once('end', onend);
}

Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function () {
    return this._writableState.highWaterMark;
  }
});

// the no-half-open enforcer
function onend() {
  // if we allow half-open state, or if the writable side ended,
  // then we're ok.
  if (this.allowHalfOpen || this._writableState.ended) return;

  // no more data can be written.
  // But allow more writes to happen in this tick.
  pna.nextTick(onEndNT, this);
}

function onEndNT(self) {
  self.end();
}

Object.defineProperty(Duplex.prototype, 'destroyed', {
  get: function () {
    if (this._readableState === undefined || this._writableState === undefined) {
      return false;
    }
    return this._readableState.destroyed && this._writableState.destroyed;
  },
  set: function (value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (this._readableState === undefined || this._writableState === undefined) {
      return;
    }

    // backward compatibility, the user is explicitly
    // managing destroyed
    this._readableState.destroyed = value;
    this._writableState.destroyed = value;
  }
});

Duplex.prototype._destroy = function (err, cb) {
  this.push(null);
  this.end();

  pna.nextTick(cb, err);
};

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// a passthrough stream.
// basically just the most minimal sort of Transform stream.
// Every written chunk gets output as-is.



module.exports = PassThrough;

var Transform = __webpack_require__(/*! ./_stream_transform */ "./node_modules/readable-stream/lib/_stream_transform.js");

/*<replacement>*/
var util = Object.create(__webpack_require__(/*! core-util-is */ "./node_modules/core-util-is/lib/util.js"));
util.inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");
/*</replacement>*/

util.inherits(PassThrough, Transform);

function PassThrough(options) {
  if (!(this instanceof PassThrough)) return new PassThrough(options);

  Transform.call(this, options);
}

PassThrough.prototype._transform = function (chunk, encoding, cb) {
  cb(null, chunk);
};

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.



/*<replacement>*/

var pna = __webpack_require__(/*! process-nextick-args */ "./node_modules/process-nextick-args/index.js");
/*</replacement>*/

module.exports = Readable;

/*<replacement>*/
var isArray = __webpack_require__(/*! isarray */ "./node_modules/readable-stream/node_modules/isarray/index.js");
/*</replacement>*/

/*<replacement>*/
var Duplex;
/*</replacement>*/

Readable.ReadableState = ReadableState;

/*<replacement>*/
var EE = __webpack_require__(/*! events */ "./node_modules/events/events.js").EventEmitter;

var EElistenerCount = function (emitter, type) {
  return emitter.listeners(type).length;
};
/*</replacement>*/

/*<replacement>*/
var Stream = __webpack_require__(/*! ./internal/streams/stream */ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js");
/*</replacement>*/

/*<replacement>*/

var Buffer = __webpack_require__(/*! safe-buffer */ "./node_modules/readable-stream/node_modules/safe-buffer/index.js").Buffer;
var OurUint8Array = global.Uint8Array || function () {};
function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}
function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}

/*</replacement>*/

/*<replacement>*/
var util = Object.create(__webpack_require__(/*! core-util-is */ "./node_modules/core-util-is/lib/util.js"));
util.inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");
/*</replacement>*/

/*<replacement>*/
var debugUtil = __webpack_require__(/*! util */ 10);
var debug = void 0;
if (debugUtil && debugUtil.debuglog) {
  debug = debugUtil.debuglog('stream');
} else {
  debug = function () {};
}
/*</replacement>*/

var BufferList = __webpack_require__(/*! ./internal/streams/BufferList */ "./node_modules/readable-stream/lib/internal/streams/BufferList.js");
var destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ "./node_modules/readable-stream/lib/internal/streams/destroy.js");
var StringDecoder;

util.inherits(Readable, Stream);

var kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];

function prependListener(emitter, event, fn) {
  // Sadly this is not cacheable as some libraries bundle their own
  // event emitter implementation with them.
  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);

  // This is a hack to make sure that our error handler is attached before any
  // userland ones.  NEVER DO THIS. This is here only because this code needs
  // to continue to work with older versions of Node.js that do not include
  // the prependListener() method. The goal is to eventually remove this hack.
  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];
}

function ReadableState(options, stream) {
  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ "./node_modules/readable-stream/lib/_stream_duplex.js");

  options = options || {};

  // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream.
  // These options can be provided separately as readableXXX and writableXXX.
  var isDuplex = stream instanceof Duplex;

  // object stream flag. Used to make read(n) ignore n and to
  // make all the buffer merging and length checks go away
  this.objectMode = !!options.objectMode;

  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;

  // the point at which it stops calling _read() to fill the buffer
  // Note: 0 is a valid value, means "don't call _read preemptively ever"
  var hwm = options.highWaterMark;
  var readableHwm = options.readableHighWaterMark;
  var defaultHwm = this.objectMode ? 16 : 16 * 1024;

  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;

  // cast to ints.
  this.highWaterMark = Math.floor(this.highWaterMark);

  // A linked list is used to store data chunks instead of an array because the
  // linked list can remove elements from the beginning faster than
  // array.shift()
  this.buffer = new BufferList();
  this.length = 0;
  this.pipes = null;
  this.pipesCount = 0;
  this.flowing = null;
  this.ended = false;
  this.endEmitted = false;
  this.reading = false;

  // a flag to be able to tell if the event 'readable'/'data' is emitted
  // immediately, or on a later tick.  We set this to true at first, because
  // any actions that shouldn't happen until "later" should generally also
  // not happen before the first read call.
  this.sync = true;

  // whenever we return null, then we set a flag to say
  // that we're awaiting a 'readable' event emission.
  this.needReadable = false;
  this.emittedReadable = false;
  this.readableListening = false;
  this.resumeScheduled = false;

  // has it been destroyed
  this.destroyed = false;

  // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.
  this.defaultEncoding = options.defaultEncoding || 'utf8';

  // the number of writers that are awaiting a drain event in .pipe()s
  this.awaitDrain = 0;

  // if true, a maybeReadMore has been scheduled
  this.readingMore = false;

  this.decoder = null;
  this.encoding = null;
  if (options.encoding) {
    if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ "./node_modules/string_decoder/lib/string_decoder.js").StringDecoder;
    this.decoder = new StringDecoder(options.encoding);
    this.encoding = options.encoding;
  }
}

function Readable(options) {
  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ "./node_modules/readable-stream/lib/_stream_duplex.js");

  if (!(this instanceof Readable)) return new Readable(options);

  this._readableState = new ReadableState(options, this);

  // legacy
  this.readable = true;

  if (options) {
    if (typeof options.read === 'function') this._read = options.read;

    if (typeof options.destroy === 'function') this._destroy = options.destroy;
  }

  Stream.call(this);
}

Object.defineProperty(Readable.prototype, 'destroyed', {
  get: function () {
    if (this._readableState === undefined) {
      return false;
    }
    return this._readableState.destroyed;
  },
  set: function (value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._readableState) {
      return;
    }

    // backward compatibility, the user is explicitly
    // managing destroyed
    this._readableState.destroyed = value;
  }
});

Readable.prototype.destroy = destroyImpl.destroy;
Readable.prototype._undestroy = destroyImpl.undestroy;
Readable.prototype._destroy = function (err, cb) {
  this.push(null);
  cb(err);
};

// Manually shove something into the read() buffer.
// This returns true if the highWaterMark has not been hit yet,
// similar to how Writable.write() returns true if you should
// write() some more.
Readable.prototype.push = function (chunk, encoding) {
  var state = this._readableState;
  var skipChunkCheck;

  if (!state.objectMode) {
    if (typeof chunk === 'string') {
      encoding = encoding || state.defaultEncoding;
      if (encoding !== state.encoding) {
        chunk = Buffer.from(chunk, encoding);
        encoding = '';
      }
      skipChunkCheck = true;
    }
  } else {
    skipChunkCheck = true;
  }

  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);
};

// Unshift should *always* be something directly out of read()
Readable.prototype.unshift = function (chunk) {
  return readableAddChunk(this, chunk, null, true, false);
};

function readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {
  var state = stream._readableState;
  if (chunk === null) {
    state.reading = false;
    onEofChunk(stream, state);
  } else {
    var er;
    if (!skipChunkCheck) er = chunkInvalid(state, chunk);
    if (er) {
      stream.emit('error', er);
    } else if (state.objectMode || chunk && chunk.length > 0) {
      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {
        chunk = _uint8ArrayToBuffer(chunk);
      }

      if (addToFront) {
        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        stream.emit('error', new Error('stream.push() after EOF'));
      } else {
        state.reading = false;
        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.reading = false;
    }
  }

  return needMoreData(state);
}

function addChunk(stream, state, chunk, addToFront) {
  if (state.flowing && state.length === 0 && !state.sync) {
    stream.emit('data', chunk);
    stream.read(0);
  } else {
    // update the buffer info.
    state.length += state.objectMode ? 1 : chunk.length;
    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);

    if (state.needReadable) emitReadable(stream);
  }
  maybeReadMore(stream, state);
}

function chunkInvalid(state, chunk) {
  var er;
  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {
    er = new TypeError('Invalid non-string/buffer chunk');
  }
  return er;
}

// if it's past the high water mark, we can push in some more.
// Also, if we have no data yet, we can stand some
// more bytes.  This is to work around cases where hwm=0,
// such as the repl.  Also, if the push() triggered a
// readable event, and the user called read(largeNumber) such that
// needReadable was set, then we ought to push more, so that another
// 'readable' event will be triggered.
function needMoreData(state) {
  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);
}

Readable.prototype.isPaused = function () {
  return this._readableState.flowing === false;
};

// backwards compatibility.
Readable.prototype.setEncoding = function (enc) {
  if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ "./node_modules/string_decoder/lib/string_decoder.js").StringDecoder;
  this._readableState.decoder = new StringDecoder(enc);
  this._readableState.encoding = enc;
  return this;
};

// Don't raise the hwm > 8MB
var MAX_HWM = 0x800000;
function computeNewHighWaterMark(n) {
  if (n >= MAX_HWM) {
    n = MAX_HWM;
  } else {
    // Get the next highest power of 2 to prevent increasing hwm excessively in
    // tiny amounts
    n--;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    n++;
  }
  return n;
}

// This function is designed to be inlinable, so please take care when making
// changes to the function body.
function howMuchToRead(n, state) {
  if (n <= 0 || state.length === 0 && state.ended) return 0;
  if (state.objectMode) return 1;
  if (n !== n) {
    // Only flow one buffer at a time
    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;
  }
  // If we're asking for more than the current hwm, then raise the hwm.
  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
  if (n <= state.length) return n;
  // Don't have enough
  if (!state.ended) {
    state.needReadable = true;
    return 0;
  }
  return state.length;
}

// you can override either this method, or the async _read(n) below.
Readable.prototype.read = function (n) {
  debug('read', n);
  n = parseInt(n, 10);
  var state = this._readableState;
  var nOrig = n;

  if (n !== 0) state.emittedReadable = false;

  // if we're doing read(0) to trigger a readable event, but we
  // already have a bunch of data in the buffer, then just trigger
  // the 'readable' event and move on.
  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {
    debug('read: emitReadable', state.length, state.ended);
    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);
    return null;
  }

  n = howMuchToRead(n, state);

  // if we've ended, and we're now clear, then finish it up.
  if (n === 0 && state.ended) {
    if (state.length === 0) endReadable(this);
    return null;
  }

  // All the actual chunk generation logic needs to be
  // *below* the call to _read.  The reason is that in certain
  // synthetic stream cases, such as passthrough streams, _read
  // may be a completely synchronous operation which may change
  // the state of the read buffer, providing enough data when
  // before there was *not* enough.
  //
  // So, the steps are:
  // 1. Figure out what the state of things will be after we do
  // a read from the buffer.
  //
  // 2. If that resulting state will trigger a _read, then call _read.
  // Note that this may be asynchronous, or synchronous.  Yes, it is
  // deeply ugly to write APIs this way, but that still doesn't mean
  // that the Readable class should behave improperly, as streams are
  // designed to be sync/async agnostic.
  // Take note if the _read call is sync or async (ie, if the read call
  // has returned yet), so that we know whether or not it's safe to emit
  // 'readable' etc.
  //
  // 3. Actually pull the requested chunks out of the buffer and return.

  // if we need a readable event, then we need to do some reading.
  var doRead = state.needReadable;
  debug('need readable', doRead);

  // if we currently have less than the highWaterMark, then also read some
  if (state.length === 0 || state.length - n < state.highWaterMark) {
    doRead = true;
    debug('length less than watermark', doRead);
  }

  // however, if we've ended, then there's no point, and if we're already
  // reading, then it's unnecessary.
  if (state.ended || state.reading) {
    doRead = false;
    debug('reading or ended', doRead);
  } else if (doRead) {
    debug('do read');
    state.reading = true;
    state.sync = true;
    // if the length is currently zero, then we *need* a readable event.
    if (state.length === 0) state.needReadable = true;
    // call internal read method
    this._read(state.highWaterMark);
    state.sync = false;
    // If _read pushed data synchronously, then `reading` will be false,
    // and we need to re-evaluate how much data we can return to the user.
    if (!state.reading) n = howMuchToRead(nOrig, state);
  }

  var ret;
  if (n > 0) ret = fromList(n, state);else ret = null;

  if (ret === null) {
    state.needReadable = true;
    n = 0;
  } else {
    state.length -= n;
  }

  if (state.length === 0) {
    // If we have nothing in the buffer, then we want to know
    // as soon as we *do* get something into the buffer.
    if (!state.ended) state.needReadable = true;

    // If we tried to read() past the EOF, then emit end on the next tick.
    if (nOrig !== n && state.ended) endReadable(this);
  }

  if (ret !== null) this.emit('data', ret);

  return ret;
};

function onEofChunk(stream, state) {
  if (state.ended) return;
  if (state.decoder) {
    var chunk = state.decoder.end();
    if (chunk && chunk.length) {
      state.buffer.push(chunk);
      state.length += state.objectMode ? 1 : chunk.length;
    }
  }
  state.ended = true;

  // emit 'readable' now to make sure it gets picked up.
  emitReadable(stream);
}

// Don't emit readable right away in sync mode, because this can trigger
// another read() call => stack overflow.  This way, it might trigger
// a nextTick recursion warning, but that's not so bad.
function emitReadable(stream) {
  var state = stream._readableState;
  state.needReadable = false;
  if (!state.emittedReadable) {
    debug('emitReadable', state.flowing);
    state.emittedReadable = true;
    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);
  }
}

function emitReadable_(stream) {
  debug('emit readable');
  stream.emit('readable');
  flow(stream);
}

// at this point, the user has presumably seen the 'readable' event,
// and called read() to consume some data.  that may have triggered
// in turn another _read(n) call, in which case reading = true if
// it's in progress.
// However, if we're not ended, or reading, and the length < hwm,
// then go ahead and try to read some more preemptively.
function maybeReadMore(stream, state) {
  if (!state.readingMore) {
    state.readingMore = true;
    pna.nextTick(maybeReadMore_, stream, state);
  }
}

function maybeReadMore_(stream, state) {
  var len = state.length;
  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {
    debug('maybeReadMore read 0');
    stream.read(0);
    if (len === state.length)
      // didn't get any data, stop spinning.
      break;else len = state.length;
  }
  state.readingMore = false;
}

// abstract method.  to be overridden in specific implementation classes.
// call cb(er, data) where data is <= n in length.
// for virtual (non-string, non-buffer) streams, "length" is somewhat
// arbitrary, and perhaps not very meaningful.
Readable.prototype._read = function (n) {
  this.emit('error', new Error('_read() is not implemented'));
};

Readable.prototype.pipe = function (dest, pipeOpts) {
  var src = this;
  var state = this._readableState;

  switch (state.pipesCount) {
    case 0:
      state.pipes = dest;
      break;
    case 1:
      state.pipes = [state.pipes, dest];
      break;
    default:
      state.pipes.push(dest);
      break;
  }
  state.pipesCount += 1;
  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);

  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;

  var endFn = doEnd ? onend : unpipe;
  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);

  dest.on('unpipe', onunpipe);
  function onunpipe(readable, unpipeInfo) {
    debug('onunpipe');
    if (readable === src) {
      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
        unpipeInfo.hasUnpiped = true;
        cleanup();
      }
    }
  }

  function onend() {
    debug('onend');
    dest.end();
  }

  // when the dest drains, it reduces the awaitDrain counter
  // on the source.  This would be more elegant with a .once()
  // handler in flow(), but adding and removing repeatedly is
  // too slow.
  var ondrain = pipeOnDrain(src);
  dest.on('drain', ondrain);

  var cleanedUp = false;
  function cleanup() {
    debug('cleanup');
    // cleanup event handlers once the pipe is broken
    dest.removeListener('close', onclose);
    dest.removeListener('finish', onfinish);
    dest.removeListener('drain', ondrain);
    dest.removeListener('error', onerror);
    dest.removeListener('unpipe', onunpipe);
    src.removeListener('end', onend);
    src.removeListener('end', unpipe);
    src.removeListener('data', ondata);

    cleanedUp = true;

    // if the reader is waiting for a drain event from this
    // specific writer, then it would cause it to never start
    // flowing again.
    // So, if this is awaiting a drain, then we just call it now.
    // If we don't know, then assume that we are waiting for one.
    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();
  }

  // If the user pushes more data while we're writing to dest then we'll end up
  // in ondata again. However, we only want to increase awaitDrain once because
  // dest will only emit one 'drain' event for the multiple writes.
  // => Introduce a guard on increasing awaitDrain.
  var increasedAwaitDrain = false;
  src.on('data', ondata);
  function ondata(chunk) {
    debug('ondata');
    increasedAwaitDrain = false;
    var ret = dest.write(chunk);
    if (false === ret && !increasedAwaitDrain) {
      // If the user unpiped during `dest.write()`, it is possible
      // to get stuck in a permanently paused state if that write
      // also returned false.
      // => Check whether `dest` is still a piping destination.
      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {
        debug('false write response, pause', src._readableState.awaitDrain);
        src._readableState.awaitDrain++;
        increasedAwaitDrain = true;
      }
      src.pause();
    }
  }

  // if the dest has an error, then stop piping into it.
  // however, don't suppress the throwing behavior for this.
  function onerror(er) {
    debug('onerror', er);
    unpipe();
    dest.removeListener('error', onerror);
    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);
  }

  // Make sure our error handler is attached before userland ones.
  prependListener(dest, 'error', onerror);

  // Both close and finish should trigger unpipe, but only once.
  function onclose() {
    dest.removeListener('finish', onfinish);
    unpipe();
  }
  dest.once('close', onclose);
  function onfinish() {
    debug('onfinish');
    dest.removeListener('close', onclose);
    unpipe();
  }
  dest.once('finish', onfinish);

  function unpipe() {
    debug('unpipe');
    src.unpipe(dest);
  }

  // tell the dest that it's being piped to
  dest.emit('pipe', src);

  // start the flow if it hasn't been started already.
  if (!state.flowing) {
    debug('pipe resume');
    src.resume();
  }

  return dest;
};

function pipeOnDrain(src) {
  return function () {
    var state = src._readableState;
    debug('pipeOnDrain', state.awaitDrain);
    if (state.awaitDrain) state.awaitDrain--;
    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
      state.flowing = true;
      flow(src);
    }
  };
}

Readable.prototype.unpipe = function (dest) {
  var state = this._readableState;
  var unpipeInfo = { hasUnpiped: false };

  // if we're not piping anywhere, then do nothing.
  if (state.pipesCount === 0) return this;

  // just one destination.  most common case.
  if (state.pipesCount === 1) {
    // passed in one, but it's not the right one.
    if (dest && dest !== state.pipes) return this;

    if (!dest) dest = state.pipes;

    // got a match.
    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;
    if (dest) dest.emit('unpipe', this, unpipeInfo);
    return this;
  }

  // slow case. multiple pipe destinations.

  if (!dest) {
    // remove all.
    var dests = state.pipes;
    var len = state.pipesCount;
    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;

    for (var i = 0; i < len; i++) {
      dests[i].emit('unpipe', this, unpipeInfo);
    }return this;
  }

  // try to find the right one.
  var index = indexOf(state.pipes, dest);
  if (index === -1) return this;

  state.pipes.splice(index, 1);
  state.pipesCount -= 1;
  if (state.pipesCount === 1) state.pipes = state.pipes[0];

  dest.emit('unpipe', this, unpipeInfo);

  return this;
};

// set up data events if they are asked for
// Ensure readable listeners eventually get something
Readable.prototype.on = function (ev, fn) {
  var res = Stream.prototype.on.call(this, ev, fn);

  if (ev === 'data') {
    // Start flowing on next tick if stream isn't explicitly paused
    if (this._readableState.flowing !== false) this.resume();
  } else if (ev === 'readable') {
    var state = this._readableState;
    if (!state.endEmitted && !state.readableListening) {
      state.readableListening = state.needReadable = true;
      state.emittedReadable = false;
      if (!state.reading) {
        pna.nextTick(nReadingNextTick, this);
      } else if (state.length) {
        emitReadable(this);
      }
    }
  }

  return res;
};
Readable.prototype.addListener = Readable.prototype.on;

function nReadingNextTick(self) {
  debug('readable nexttick read 0');
  self.read(0);
}

// pause() and resume() are remnants of the legacy readable stream API
// If the user uses them, then switch into old mode.
Readable.prototype.resume = function () {
  var state = this._readableState;
  if (!state.flowing) {
    debug('resume');
    state.flowing = true;
    resume(this, state);
  }
  return this;
};

function resume(stream, state) {
  if (!state.resumeScheduled) {
    state.resumeScheduled = true;
    pna.nextTick(resume_, stream, state);
  }
}

function resume_(stream, state) {
  if (!state.reading) {
    debug('resume read 0');
    stream.read(0);
  }

  state.resumeScheduled = false;
  state.awaitDrain = 0;
  stream.emit('resume');
  flow(stream);
  if (state.flowing && !state.reading) stream.read(0);
}

Readable.prototype.pause = function () {
  debug('call pause flowing=%j', this._readableState.flowing);
  if (false !== this._readableState.flowing) {
    debug('pause');
    this._readableState.flowing = false;
    this.emit('pause');
  }
  return this;
};

function flow(stream) {
  var state = stream._readableState;
  debug('flow', state.flowing);
  while (state.flowing && stream.read() !== null) {}
}

// wrap an old-style stream as the async data source.
// This is *not* part of the readable stream interface.
// It is an ugly unfortunate mess of history.
Readable.prototype.wrap = function (stream) {
  var _this = this;

  var state = this._readableState;
  var paused = false;

  stream.on('end', function () {
    debug('wrapped end');
    if (state.decoder && !state.ended) {
      var chunk = state.decoder.end();
      if (chunk && chunk.length) _this.push(chunk);
    }

    _this.push(null);
  });

  stream.on('data', function (chunk) {
    debug('wrapped data');
    if (state.decoder) chunk = state.decoder.write(chunk);

    // don't skip over falsy values in objectMode
    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;

    var ret = _this.push(chunk);
    if (!ret) {
      paused = true;
      stream.pause();
    }
  });

  // proxy all the other methods.
  // important when wrapping filters and duplexes.
  for (var i in stream) {
    if (this[i] === undefined && typeof stream[i] === 'function') {
      this[i] = function (method) {
        return function () {
          return stream[method].apply(stream, arguments);
        };
      }(i);
    }
  }

  // proxy certain important events.
  for (var n = 0; n < kProxyEvents.length; n++) {
    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));
  }

  // when we try to consume some more bytes, simply unpause the
  // underlying stream.
  this._read = function (n) {
    debug('wrapped _read', n);
    if (paused) {
      paused = false;
      stream.resume();
    }
  };

  return this;
};

Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function () {
    return this._readableState.highWaterMark;
  }
});

// exposed for testing purposes only.
Readable._fromList = fromList;

// Pluck off n bytes from an array of buffers.
// Length is the combined lengths of all the buffers in the list.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.
function fromList(n, state) {
  // nothing buffered
  if (state.length === 0) return null;

  var ret;
  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {
    // read it all, truncate the list
    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);
    state.buffer.clear();
  } else {
    // read part of list
    ret = fromListPartial(n, state.buffer, state.decoder);
  }

  return ret;
}

// Extracts only enough buffered data to satisfy the amount requested.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.
function fromListPartial(n, list, hasStrings) {
  var ret;
  if (n < list.head.data.length) {
    // slice is the same for buffers and strings
    ret = list.head.data.slice(0, n);
    list.head.data = list.head.data.slice(n);
  } else if (n === list.head.data.length) {
    // first chunk is a perfect match
    ret = list.shift();
  } else {
    // result spans more than one buffer
    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);
  }
  return ret;
}

// Copies a specified amount of characters from the list of buffered data
// chunks.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.
function copyFromBufferString(n, list) {
  var p = list.head;
  var c = 1;
  var ret = p.data;
  n -= ret.length;
  while (p = p.next) {
    var str = p.data;
    var nb = n > str.length ? str.length : n;
    if (nb === str.length) ret += str;else ret += str.slice(0, n);
    n -= nb;
    if (n === 0) {
      if (nb === str.length) {
        ++c;
        if (p.next) list.head = p.next;else list.head = list.tail = null;
      } else {
        list.head = p;
        p.data = str.slice(nb);
      }
      break;
    }
    ++c;
  }
  list.length -= c;
  return ret;
}

// Copies a specified amount of bytes from the list of buffered data chunks.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.
function copyFromBuffer(n, list) {
  var ret = Buffer.allocUnsafe(n);
  var p = list.head;
  var c = 1;
  p.data.copy(ret);
  n -= p.data.length;
  while (p = p.next) {
    var buf = p.data;
    var nb = n > buf.length ? buf.length : n;
    buf.copy(ret, ret.length - n, 0, nb);
    n -= nb;
    if (n === 0) {
      if (nb === buf.length) {
        ++c;
        if (p.next) list.head = p.next;else list.head = list.tail = null;
      } else {
        list.head = p;
        p.data = buf.slice(nb);
      }
      break;
    }
    ++c;
  }
  list.length -= c;
  return ret;
}

function endReadable(stream) {
  var state = stream._readableState;

  // If we get here before consuming all the bytes, then that is a
  // bug in node.  Should never happen.
  if (state.length > 0) throw new Error('"endReadable()" called on non-empty stream');

  if (!state.endEmitted) {
    state.ended = true;
    pna.nextTick(endReadableNT, state, stream);
  }
}

function endReadableNT(state, stream) {
  // Check that we didn't get one last unshift.
  if (!state.endEmitted && state.length === 0) {
    state.endEmitted = true;
    stream.readable = false;
    stream.emit('end');
  }
}

function indexOf(xs, x) {
  for (var i = 0, l = xs.length; i < l; i++) {
    if (xs[i] === x) return i;
  }
  return -1;
}
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js"), __webpack_require__(/*! ./../../process/browser.js */ "./node_modules/process/browser.js")))

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// a transform stream is a readable/writable stream where you do
// something with the data.  Sometimes it's called a "filter",
// but that's not a great name for it, since that implies a thing where
// some bits pass through, and others are simply ignored.  (That would
// be a valid example of a transform, of course.)
//
// While the output is causally related to the input, it's not a
// necessarily symmetric or synchronous transformation.  For example,
// a zlib stream might take multiple plain-text writes(), and then
// emit a single compressed chunk some time in the future.
//
// Here's how this works:
//
// The Transform stream has all the aspects of the readable and writable
// stream classes.  When you write(chunk), that calls _write(chunk,cb)
// internally, and returns false if there's a lot of pending writes
// buffered up.  When you call read(), that calls _read(n) until
// there's enough pending readable data buffered up.
//
// In a transform stream, the written data is placed in a buffer.  When
// _read(n) is called, it transforms the queued up data, calling the
// buffered _write cb's as it consumes chunks.  If consuming a single
// written chunk would result in multiple output chunks, then the first
// outputted bit calls the readcb, and subsequent chunks just go into
// the read buffer, and will cause it to emit 'readable' if necessary.
//
// This way, back-pressure is actually determined by the reading side,
// since _read has to be called to start processing a new chunk.  However,
// a pathological inflate type of transform can cause excessive buffering
// here.  For example, imagine a stream where every byte of input is
// interpreted as an integer from 0-255, and then results in that many
// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in
// 1kb of data being output.  In this case, you could write a very small
// amount of input, and end up with a very large amount of output.  In
// such a pathological inflating mechanism, there'd be no way to tell
// the system to stop doing the transform.  A single 4MB write could
// cause the system to run out of memory.
//
// However, even in such a pathological case, only a single written chunk
// would be consumed, and then the rest would wait (un-transformed) until
// the results of the previous transformed chunk were consumed.



module.exports = Transform;

var Duplex = __webpack_require__(/*! ./_stream_duplex */ "./node_modules/readable-stream/lib/_stream_duplex.js");

/*<replacement>*/
var util = Object.create(__webpack_require__(/*! core-util-is */ "./node_modules/core-util-is/lib/util.js"));
util.inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");
/*</replacement>*/

util.inherits(Transform, Duplex);

function afterTransform(er, data) {
  var ts = this._transformState;
  ts.transforming = false;

  var cb = ts.writecb;

  if (!cb) {
    return this.emit('error', new Error('write callback called multiple times'));
  }

  ts.writechunk = null;
  ts.writecb = null;

  if (data != null) // single equals check for both `null` and `undefined`
    this.push(data);

  cb(er);

  var rs = this._readableState;
  rs.reading = false;
  if (rs.needReadable || rs.length < rs.highWaterMark) {
    this._read(rs.highWaterMark);
  }
}

function Transform(options) {
  if (!(this instanceof Transform)) return new Transform(options);

  Duplex.call(this, options);

  this._transformState = {
    afterTransform: afterTransform.bind(this),
    needTransform: false,
    transforming: false,
    writecb: null,
    writechunk: null,
    writeencoding: null
  };

  // start out asking for a readable event once data is transformed.
  this._readableState.needReadable = true;

  // we have implemented the _read method, and done the other things
  // that Readable wants before the first _read call, so unset the
  // sync guard flag.
  this._readableState.sync = false;

  if (options) {
    if (typeof options.transform === 'function') this._transform = options.transform;

    if (typeof options.flush === 'function') this._flush = options.flush;
  }

  // When the writable side finishes, then flush out anything remaining.
  this.on('prefinish', prefinish);
}

function prefinish() {
  var _this = this;

  if (typeof this._flush === 'function') {
    this._flush(function (er, data) {
      done(_this, er, data);
    });
  } else {
    done(this, null, null);
  }
}

Transform.prototype.push = function (chunk, encoding) {
  this._transformState.needTransform = false;
  return Duplex.prototype.push.call(this, chunk, encoding);
};

// This is the part where you do stuff!
// override this function in implementation classes.
// 'chunk' is an input chunk.
//
// Call `push(newChunk)` to pass along transformed output
// to the readable side.  You may call 'push' zero or more times.
//
// Call `cb(err)` when you are done with this chunk.  If you pass
// an error, then that'll put the hurt on the whole operation.  If you
// never call cb(), then you'll never get another chunk.
Transform.prototype._transform = function (chunk, encoding, cb) {
  throw new Error('_transform() is not implemented');
};

Transform.prototype._write = function (chunk, encoding, cb) {
  var ts = this._transformState;
  ts.writecb = cb;
  ts.writechunk = chunk;
  ts.writeencoding = encoding;
  if (!ts.transforming) {
    var rs = this._readableState;
    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);
  }
};

// Doesn't matter what the args are here.
// _transform does all the work.
// That we got here means that the readable side wants more data.
Transform.prototype._read = function (n) {
  var ts = this._transformState;

  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {
    ts.transforming = true;
    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);
  } else {
    // mark that we need a transform, so that any data that comes in
    // will get processed, now that we've asked for it.
    ts.needTransform = true;
  }
};

Transform.prototype._destroy = function (err, cb) {
  var _this2 = this;

  Duplex.prototype._destroy.call(this, err, function (err2) {
    cb(err2);
    _this2.emit('close');
  });
};

function done(stream, er, data) {
  if (er) return stream.emit('error', er);

  if (data != null) // single equals check for both `null` and `undefined`
    stream.push(data);

  // if there's nothing in the write buffer, then that means
  // that nothing more will ever be provided
  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');

  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');

  return stream.push(null);
}

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* WEBPACK VAR INJECTION */(function(process, setImmediate, global) {// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

// A bit simpler than readable streams.
// Implement an async ._write(chunk, encoding, cb), and it'll handle all
// the drain event emission and buffering.



/*<replacement>*/

var pna = __webpack_require__(/*! process-nextick-args */ "./node_modules/process-nextick-args/index.js");
/*</replacement>*/

module.exports = Writable;

/* <replacement> */
function WriteReq(chunk, encoding, cb) {
  this.chunk = chunk;
  this.encoding = encoding;
  this.callback = cb;
  this.next = null;
}

// It seems a linked list but it is not
// there will be only 2 of these for each stream
function CorkedRequest(state) {
  var _this = this;

  this.next = null;
  this.entry = null;
  this.finish = function () {
    onCorkedFinish(_this, state);
  };
}
/* </replacement> */

/*<replacement>*/
var asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;
/*</replacement>*/

/*<replacement>*/
var Duplex;
/*</replacement>*/

Writable.WritableState = WritableState;

/*<replacement>*/
var util = Object.create(__webpack_require__(/*! core-util-is */ "./node_modules/core-util-is/lib/util.js"));
util.inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");
/*</replacement>*/

/*<replacement>*/
var internalUtil = {
  deprecate: __webpack_require__(/*! util-deprecate */ "./node_modules/util-deprecate/browser.js")
};
/*</replacement>*/

/*<replacement>*/
var Stream = __webpack_require__(/*! ./internal/streams/stream */ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js");
/*</replacement>*/

/*<replacement>*/

var Buffer = __webpack_require__(/*! safe-buffer */ "./node_modules/readable-stream/node_modules/safe-buffer/index.js").Buffer;
var OurUint8Array = global.Uint8Array || function () {};
function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}
function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}

/*</replacement>*/

var destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ "./node_modules/readable-stream/lib/internal/streams/destroy.js");

util.inherits(Writable, Stream);

function nop() {}

function WritableState(options, stream) {
  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ "./node_modules/readable-stream/lib/_stream_duplex.js");

  options = options || {};

  // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream.
  // These options can be provided separately as readableXXX and writableXXX.
  var isDuplex = stream instanceof Duplex;

  // object stream flag to indicate whether or not this stream
  // contains buffers or objects.
  this.objectMode = !!options.objectMode;

  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;

  // the point at which write() starts returning false
  // Note: 0 is a valid value, means that we always return false if
  // the entire buffer is not flushed immediately on write()
  var hwm = options.highWaterMark;
  var writableHwm = options.writableHighWaterMark;
  var defaultHwm = this.objectMode ? 16 : 16 * 1024;

  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;

  // cast to ints.
  this.highWaterMark = Math.floor(this.highWaterMark);

  // if _final has been called
  this.finalCalled = false;

  // drain event flag.
  this.needDrain = false;
  // at the start of calling end()
  this.ending = false;
  // when end() has been called, and returned
  this.ended = false;
  // when 'finish' is emitted
  this.finished = false;

  // has it been destroyed
  this.destroyed = false;

  // should we decode strings into buffers before passing to _write?
  // this is here so that some node-core streams can optimize string
  // handling at a lower level.
  var noDecode = options.decodeStrings === false;
  this.decodeStrings = !noDecode;

  // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.
  this.defaultEncoding = options.defaultEncoding || 'utf8';

  // not an actual buffer we keep track of, but a measurement
  // of how much we're waiting to get pushed to some underlying
  // socket or file.
  this.length = 0;

  // a flag to see when we're in the middle of a write.
  this.writing = false;

  // when true all writes will be buffered until .uncork() call
  this.corked = 0;

  // a flag to be able to tell if the onwrite cb is called immediately,
  // or on a later tick.  We set this to true at first, because any
  // actions that shouldn't happen until "later" should generally also
  // not happen before the first write call.
  this.sync = true;

  // a flag to know if we're processing previously buffered items, which
  // may call the _write() callback in the same tick, so that we don't
  // end up in an overlapped onwrite situation.
  this.bufferProcessing = false;

  // the callback that's passed to _write(chunk,cb)
  this.onwrite = function (er) {
    onwrite(stream, er);
  };

  // the callback that the user supplies to write(chunk,encoding,cb)
  this.writecb = null;

  // the amount that is being written when _write is called.
  this.writelen = 0;

  this.bufferedRequest = null;
  this.lastBufferedRequest = null;

  // number of pending user-supplied write callbacks
  // this must be 0 before 'finish' can be emitted
  this.pendingcb = 0;

  // emit prefinish if the only thing we're waiting for is _write cbs
  // This is relevant for synchronous Transform streams
  this.prefinished = false;

  // True if the error was already emitted and should not be thrown again
  this.errorEmitted = false;

  // count buffered requests
  this.bufferedRequestCount = 0;

  // allocate the first CorkedRequest, there is always
  // one allocated and free to use, and we maintain at most two
  this.corkedRequestsFree = new CorkedRequest(this);
}

WritableState.prototype.getBuffer = function getBuffer() {
  var current = this.bufferedRequest;
  var out = [];
  while (current) {
    out.push(current);
    current = current.next;
  }
  return out;
};

(function () {
  try {
    Object.defineProperty(WritableState.prototype, 'buffer', {
      get: internalUtil.deprecate(function () {
        return this.getBuffer();
      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')
    });
  } catch (_) {}
})();

// Test _writableState for inheritance to account for Duplex streams,
// whose prototype chain only points to Readable.
var realHasInstance;
if (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {
  realHasInstance = Function.prototype[Symbol.hasInstance];
  Object.defineProperty(Writable, Symbol.hasInstance, {
    value: function (object) {
      if (realHasInstance.call(this, object)) return true;
      if (this !== Writable) return false;

      return object && object._writableState instanceof WritableState;
    }
  });
} else {
  realHasInstance = function (object) {
    return object instanceof this;
  };
}

function Writable(options) {
  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ "./node_modules/readable-stream/lib/_stream_duplex.js");

  // Writable ctor is applied to Duplexes, too.
  // `realHasInstance` is necessary because using plain `instanceof`
  // would return false, as no `_writableState` property is attached.

  // Trying to use the custom `instanceof` for Writable here will also break the
  // Node.js LazyTransform implementation, which has a non-trivial getter for
  // `_writableState` that would lead to infinite recursion.
  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {
    return new Writable(options);
  }

  this._writableState = new WritableState(options, this);

  // legacy.
  this.writable = true;

  if (options) {
    if (typeof options.write === 'function') this._write = options.write;

    if (typeof options.writev === 'function') this._writev = options.writev;

    if (typeof options.destroy === 'function') this._destroy = options.destroy;

    if (typeof options.final === 'function') this._final = options.final;
  }

  Stream.call(this);
}

// Otherwise people can pipe Writable streams, which is just wrong.
Writable.prototype.pipe = function () {
  this.emit('error', new Error('Cannot pipe, not readable'));
};

function writeAfterEnd(stream, cb) {
  var er = new Error('write after end');
  // TODO: defer error events consistently everywhere, not just the cb
  stream.emit('error', er);
  pna.nextTick(cb, er);
}

// Checks that a user-supplied chunk is valid, especially for the particular
// mode the stream is in. Currently this means that `null` is never accepted
// and undefined/non-string values are only allowed in object mode.
function validChunk(stream, state, chunk, cb) {
  var valid = true;
  var er = false;

  if (chunk === null) {
    er = new TypeError('May not write null values to stream');
  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {
    er = new TypeError('Invalid non-string/buffer chunk');
  }
  if (er) {
    stream.emit('error', er);
    pna.nextTick(cb, er);
    valid = false;
  }
  return valid;
}

Writable.prototype.write = function (chunk, encoding, cb) {
  var state = this._writableState;
  var ret = false;
  var isBuf = !state.objectMode && _isUint8Array(chunk);

  if (isBuf && !Buffer.isBuffer(chunk)) {
    chunk = _uint8ArrayToBuffer(chunk);
  }

  if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;

  if (typeof cb !== 'function') cb = nop;

  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {
    state.pendingcb++;
    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);
  }

  return ret;
};

Writable.prototype.cork = function () {
  var state = this._writableState;

  state.corked++;
};

Writable.prototype.uncork = function () {
  var state = this._writableState;

  if (state.corked) {
    state.corked--;

    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);
  }
};

Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
  // node::ParseEncoding() requires lower case.
  if (typeof encoding === 'string') encoding = encoding.toLowerCase();
  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);
  this._writableState.defaultEncoding = encoding;
  return this;
};

function decodeChunk(state, chunk, encoding) {
  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {
    chunk = Buffer.from(chunk, encoding);
  }
  return chunk;
}

Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function () {
    return this._writableState.highWaterMark;
  }
});

// if we're already writing something, then just put this
// in the queue, and wait our turn.  Otherwise, call _write
// If we return false, then we need a drain event, so set that flag.
function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
  if (!isBuf) {
    var newChunk = decodeChunk(state, chunk, encoding);
    if (chunk !== newChunk) {
      isBuf = true;
      encoding = 'buffer';
      chunk = newChunk;
    }
  }
  var len = state.objectMode ? 1 : chunk.length;

  state.length += len;

  var ret = state.length < state.highWaterMark;
  // we must ensure that previous needDrain will not be reset to false.
  if (!ret) state.needDrain = true;

  if (state.writing || state.corked) {
    var last = state.lastBufferedRequest;
    state.lastBufferedRequest = {
      chunk: chunk,
      encoding: encoding,
      isBuf: isBuf,
      callback: cb,
      next: null
    };
    if (last) {
      last.next = state.lastBufferedRequest;
    } else {
      state.bufferedRequest = state.lastBufferedRequest;
    }
    state.bufferedRequestCount += 1;
  } else {
    doWrite(stream, state, false, len, chunk, encoding, cb);
  }

  return ret;
}

function doWrite(stream, state, writev, len, chunk, encoding, cb) {
  state.writelen = len;
  state.writecb = cb;
  state.writing = true;
  state.sync = true;
  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);
  state.sync = false;
}

function onwriteError(stream, state, sync, er, cb) {
  --state.pendingcb;

  if (sync) {
    // defer the callback if we are being called synchronously
    // to avoid piling up things on the stack
    pna.nextTick(cb, er);
    // this can emit finish, and it will always happen
    // after error
    pna.nextTick(finishMaybe, stream, state);
    stream._writableState.errorEmitted = true;
    stream.emit('error', er);
  } else {
    // the caller expect this to happen before if
    // it is async
    cb(er);
    stream._writableState.errorEmitted = true;
    stream.emit('error', er);
    // this can emit finish, but finish must
    // always follow error
    finishMaybe(stream, state);
  }
}

function onwriteStateUpdate(state) {
  state.writing = false;
  state.writecb = null;
  state.length -= state.writelen;
  state.writelen = 0;
}

function onwrite(stream, er) {
  var state = stream._writableState;
  var sync = state.sync;
  var cb = state.writecb;

  onwriteStateUpdate(state);

  if (er) onwriteError(stream, state, sync, er, cb);else {
    // Check if we're actually ready to finish, but don't emit yet
    var finished = needFinish(state);

    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {
      clearBuffer(stream, state);
    }

    if (sync) {
      /*<replacement>*/
      asyncWrite(afterWrite, stream, state, finished, cb);
      /*</replacement>*/
    } else {
      afterWrite(stream, state, finished, cb);
    }
  }
}

function afterWrite(stream, state, finished, cb) {
  if (!finished) onwriteDrain(stream, state);
  state.pendingcb--;
  cb();
  finishMaybe(stream, state);
}

// Must force callback to be called on nextTick, so that we don't
// emit 'drain' before the write() consumer gets the 'false' return
// value, and has a chance to attach a 'drain' listener.
function onwriteDrain(stream, state) {
  if (state.length === 0 && state.needDrain) {
    state.needDrain = false;
    stream.emit('drain');
  }
}

// if there's something in the buffer waiting, then process it
function clearBuffer(stream, state) {
  state.bufferProcessing = true;
  var entry = state.bufferedRequest;

  if (stream._writev && entry && entry.next) {
    // Fast case, write everything using _writev()
    var l = state.bufferedRequestCount;
    var buffer = new Array(l);
    var holder = state.corkedRequestsFree;
    holder.entry = entry;

    var count = 0;
    var allBuffers = true;
    while (entry) {
      buffer[count] = entry;
      if (!entry.isBuf) allBuffers = false;
      entry = entry.next;
      count += 1;
    }
    buffer.allBuffers = allBuffers;

    doWrite(stream, state, true, state.length, buffer, '', holder.finish);

    // doWrite is almost always async, defer these to save a bit of time
    // as the hot path ends with doWrite
    state.pendingcb++;
    state.lastBufferedRequest = null;
    if (holder.next) {
      state.corkedRequestsFree = holder.next;
      holder.next = null;
    } else {
      state.corkedRequestsFree = new CorkedRequest(state);
    }
    state.bufferedRequestCount = 0;
  } else {
    // Slow case, write chunks one-by-one
    while (entry) {
      var chunk = entry.chunk;
      var encoding = entry.encoding;
      var cb = entry.callback;
      var len = state.objectMode ? 1 : chunk.length;

      doWrite(stream, state, false, len, chunk, encoding, cb);
      entry = entry.next;
      state.bufferedRequestCount--;
      // if we didn't call the onwrite immediately, then
      // it means that we need to wait until it does.
      // also, that means that the chunk and cb are currently
      // being processed, so move the buffer counter past them.
      if (state.writing) {
        break;
      }
    }

    if (entry === null) state.lastBufferedRequest = null;
  }

  state.bufferedRequest = entry;
  state.bufferProcessing = false;
}

Writable.prototype._write = function (chunk, encoding, cb) {
  cb(new Error('_write() is not implemented'));
};

Writable.prototype._writev = null;

Writable.prototype.end = function (chunk, encoding, cb) {
  var state = this._writableState;

  if (typeof chunk === 'function') {
    cb = chunk;
    chunk = null;
    encoding = null;
  } else if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);

  // .end() fully uncorks
  if (state.corked) {
    state.corked = 1;
    this.uncork();
  }

  // ignore unnecessary end() calls.
  if (!state.ending && !state.finished) endWritable(this, state, cb);
};

function needFinish(state) {
  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;
}
function callFinal(stream, state) {
  stream._final(function (err) {
    state.pendingcb--;
    if (err) {
      stream.emit('error', err);
    }
    state.prefinished = true;
    stream.emit('prefinish');
    finishMaybe(stream, state);
  });
}
function prefinish(stream, state) {
  if (!state.prefinished && !state.finalCalled) {
    if (typeof stream._final === 'function') {
      state.pendingcb++;
      state.finalCalled = true;
      pna.nextTick(callFinal, stream, state);
    } else {
      state.prefinished = true;
      stream.emit('prefinish');
    }
  }
}

function finishMaybe(stream, state) {
  var need = needFinish(state);
  if (need) {
    prefinish(stream, state);
    if (state.pendingcb === 0) {
      state.finished = true;
      stream.emit('finish');
    }
  }
  return need;
}

function endWritable(stream, state, cb) {
  state.ending = true;
  finishMaybe(stream, state);
  if (cb) {
    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);
  }
  state.ended = true;
  stream.writable = false;
}

function onCorkedFinish(corkReq, state, err) {
  var entry = corkReq.entry;
  corkReq.entry = null;
  while (entry) {
    var cb = entry.callback;
    state.pendingcb--;
    cb(err);
    entry = entry.next;
  }
  if (state.corkedRequestsFree) {
    state.corkedRequestsFree.next = corkReq;
  } else {
    state.corkedRequestsFree = corkReq;
  }
}

Object.defineProperty(Writable.prototype, 'destroyed', {
  get: function () {
    if (this._writableState === undefined) {
      return false;
    }
    return this._writableState.destroyed;
  },
  set: function (value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._writableState) {
      return;
    }

    // backward compatibility, the user is explicitly
    // managing destroyed
    this._writableState.destroyed = value;
  }
});

Writable.prototype.destroy = destroyImpl.destroy;
Writable.prototype._undestroy = destroyImpl.undestroy;
Writable.prototype._destroy = function (err, cb) {
  this.end();
  cb(err);
};
/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ "./node_modules/process/browser.js"), __webpack_require__(/*! ./../../timers-browserify/main.js */ "./node_modules/timers-browserify/main.js").setImmediate, __webpack_require__(/*! ./../../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/BufferList.js":
/*!*************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/BufferList.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

var Buffer = __webpack_require__(/*! safe-buffer */ "./node_modules/readable-stream/node_modules/safe-buffer/index.js").Buffer;
var util = __webpack_require__(/*! util */ 11);

function copyBuffer(src, target, offset) {
  src.copy(target, offset);
}

module.exports = function () {
  function BufferList() {
    _classCallCheck(this, BufferList);

    this.head = null;
    this.tail = null;
    this.length = 0;
  }

  BufferList.prototype.push = function push(v) {
    var entry = { data: v, next: null };
    if (this.length > 0) this.tail.next = entry;else this.head = entry;
    this.tail = entry;
    ++this.length;
  };

  BufferList.prototype.unshift = function unshift(v) {
    var entry = { data: v, next: this.head };
    if (this.length === 0) this.tail = entry;
    this.head = entry;
    ++this.length;
  };

  BufferList.prototype.shift = function shift() {
    if (this.length === 0) return;
    var ret = this.head.data;
    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;
    --this.length;
    return ret;
  };

  BufferList.prototype.clear = function clear() {
    this.head = this.tail = null;
    this.length = 0;
  };

  BufferList.prototype.join = function join(s) {
    if (this.length === 0) return '';
    var p = this.head;
    var ret = '' + p.data;
    while (p = p.next) {
      ret += s + p.data;
    }return ret;
  };

  BufferList.prototype.concat = function concat(n) {
    if (this.length === 0) return Buffer.alloc(0);
    if (this.length === 1) return this.head.data;
    var ret = Buffer.allocUnsafe(n >>> 0);
    var p = this.head;
    var i = 0;
    while (p) {
      copyBuffer(p.data, ret, i);
      i += p.data.length;
      p = p.next;
    }
    return ret;
  };

  return BufferList;
}();

if (util && util.inspect && util.inspect.custom) {
  module.exports.prototype[util.inspect.custom] = function () {
    var obj = util.inspect({ length: this.length });
    return this.constructor.name + ' ' + obj;
  };
}

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


/*<replacement>*/

var pna = __webpack_require__(/*! process-nextick-args */ "./node_modules/process-nextick-args/index.js");
/*</replacement>*/

// undocumented cb() API, needed for core, not for public API
function destroy(err, cb) {
  var _this = this;

  var readableDestroyed = this._readableState && this._readableState.destroyed;
  var writableDestroyed = this._writableState && this._writableState.destroyed;

  if (readableDestroyed || writableDestroyed) {
    if (cb) {
      cb(err);
    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {
      pna.nextTick(emitErrorNT, this, err);
    }
    return this;
  }

  // we set destroyed to true before firing error callbacks in order
  // to make it re-entrance safe in case destroy() is called within callbacks

  if (this._readableState) {
    this._readableState.destroyed = true;
  }

  // if this is a duplex stream mark the writable part as destroyed as well
  if (this._writableState) {
    this._writableState.destroyed = true;
  }

  this._destroy(err || null, function (err) {
    if (!cb && err) {
      pna.nextTick(emitErrorNT, _this, err);
      if (_this._writableState) {
        _this._writableState.errorEmitted = true;
      }
    } else if (cb) {
      cb(err);
    }
  });

  return this;
}

function undestroy() {
  if (this._readableState) {
    this._readableState.destroyed = false;
    this._readableState.reading = false;
    this._readableState.ended = false;
    this._readableState.endEmitted = false;
  }

  if (this._writableState) {
    this._writableState.destroyed = false;
    this._writableState.ended = false;
    this._writableState.ending = false;
    this._writableState.finished = false;
    this._writableState.errorEmitted = false;
  }
}

function emitErrorNT(self, err) {
  self.emit('error', err);
}

module.exports = {
  destroy: destroy,
  undestroy: undestroy
};

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = __webpack_require__(/*! events */ "./node_modules/events/events.js").EventEmitter;


/***/ }),

/***/ "./node_modules/readable-stream/node_modules/isarray/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/node_modules/isarray/index.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

var toString = {}.toString;

module.exports = Array.isArray || function (arr) {
  return toString.call(arr) == '[object Array]';
};


/***/ }),

/***/ "./node_modules/readable-stream/node_modules/safe-buffer/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/readable-stream/node_modules/safe-buffer/index.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* eslint-disable node/no-deprecated-api */
var buffer = __webpack_require__(/*! buffer */ "./node_modules/buffer/index.js")
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}


/***/ }),

/***/ "./node_modules/readable-stream/passthrough.js":
/*!*****************************************************!*\
  !*** ./node_modules/readable-stream/passthrough.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = __webpack_require__(/*! ./readable */ "./node_modules/readable-stream/readable-browser.js").PassThrough


/***/ }),

/***/ "./node_modules/readable-stream/readable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/readable-browser.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ "./node_modules/readable-stream/lib/_stream_readable.js");
exports.Stream = exports;
exports.Readable = exports;
exports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ "./node_modules/readable-stream/lib/_stream_writable.js");
exports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ "./node_modules/readable-stream/lib/_stream_duplex.js");
exports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ "./node_modules/readable-stream/lib/_stream_transform.js");
exports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ "./node_modules/readable-stream/lib/_stream_passthrough.js");


/***/ }),

/***/ "./node_modules/readable-stream/transform.js":
/*!***************************************************!*\
  !*** ./node_modules/readable-stream/transform.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = __webpack_require__(/*! ./readable */ "./node_modules/readable-stream/readable-browser.js").Transform


/***/ }),

/***/ "./node_modules/readable-stream/writable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/writable-browser.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = __webpack_require__(/*! ./lib/_stream_writable.js */ "./node_modules/readable-stream/lib/_stream_writable.js");


/***/ }),

/***/ "./node_modules/requires-port/index.js":
/*!*********************************************!*\
  !*** ./node_modules/requires-port/index.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


/**
 * Check if we're required to add a port number.
 *
 * @see https://url.spec.whatwg.org/#default-port
 * @param {Number|String} port Port number we need to check
 * @param {String} protocol Protocol we need to check against.
 * @returns {Boolean} Is it a default port for the given protocol
 * @api private
 */
module.exports = function required(port, protocol) {
  protocol = protocol.split(':')[0];
  port = +port;

  if (!port) return false;

  switch (protocol) {
    case 'http':
    case 'ws':
    return port !== 80;

    case 'https':
    case 'wss':
    return port !== 443;

    case 'ftp':
    return port !== 21;

    case 'gopher':
    return port !== 70;

    case 'file':
    return false;
  }

  return port !== 0;
};


/***/ }),

/***/ "./node_modules/socket.io-stream/index.js":
/*!************************************************!*\
  !*** ./node_modules/socket.io-stream/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


module.exports = __webpack_require__(/*! ./lib */ "./node_modules/socket.io-stream/lib/index.js");



/***/ }),

/***/ "./node_modules/socket.io-stream/lib/blob-read-stream.js":
/*!***************************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/blob-read-stream.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {var util = __webpack_require__(/*! util */ "./node_modules/util/util.js");
var Readable = __webpack_require__(/*! stream */ "./node_modules/stream-browserify/index.js").Readable;
var bind = __webpack_require__(/*! component-bind */ "./node_modules/component-bind/index.js");


module.exports = BlobReadStream;

util.inherits(BlobReadStream, Readable);

/**
 * Readable stream for Blob and File on browser.
 *
 * @param {Object} options
 * @api private
 */
function BlobReadStream(blob, options) {
  if (!(this instanceof BlobReadStream)) {
    return new BlobReadStream(blob, options);
  }

  Readable.call(this, options);

  options = options || {};
  this.blob = blob;
  this.slice = blob.slice || blob.webkitSlice || blob.mozSlice;
  this.start = 0;
  this.sync = options.synchronous || false;

  var fileReader;

  if (options.synchronous) {
    fileReader = this.fileReader = new FileReaderSync();
  } else {
    fileReader = this.fileReader = new FileReader();
  }

  fileReader.onload = bind(this, '_onload');
  fileReader.onerror = bind(this, '_onerror');
}

BlobReadStream.prototype._read = function(size) {
  var start = this.start;
  var end = this.start = this.start + size;
  var chunk = this.slice.call(this.blob, start, end);

  if (chunk.size) {
    if (this.sync) {
      var bufferChunk = new Buffer(new Uint8Array(this.fileReader.readAsArrayBuffer(chunk)));
      this.push(bufferChunk);
    } else {
      this.fileReader.readAsArrayBuffer(chunk);
    }
  } else {
    this.push(null);
  }
}

BlobReadStream.prototype._onload = function(e) {
  var chunk = new Buffer(new Uint8Array(e.target.result));
  this.push(chunk);
};

BlobReadStream.prototype._onerror = function(e) {
  var err = e.target.error;
  this.emit('error', err);
};


/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ "./node_modules/buffer/index.js").Buffer))

/***/ }),

/***/ "./node_modules/socket.io-stream/lib/index.js":
/*!****************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/index.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer) {var Socket = __webpack_require__(/*! ./socket */ "./node_modules/socket.io-stream/lib/socket.js");
var IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/socket.io-stream/lib/iostream.js");
var BlobReadStream = __webpack_require__(/*! ./blob-read-stream */ "./node_modules/socket.io-stream/lib/blob-read-stream.js");


exports = module.exports = lookup;

/**
 * Expose Node Buffer for browser.
 *
 * @api public
 */
exports.Buffer = Buffer;

/**
 * Expose Socket constructor.
 *
 * @api public
 */
exports.Socket = Socket;

/**
 * Expose IOStream constructor.
 *
 * @api public
 */
exports.IOStream = IOStream;

/**
 * Forces base 64 encoding when emitting. Must be set to true for Socket.IO v0.9 or lower.
 *
 * @api public
 */
exports.forceBase64 = false;

/**
 * Look up an existing Socket.
 *
 * @param {socket.io#Socket} socket.io
 * @param {Object} options
 * @return {Socket} Socket instance
 * @api public
 */
function lookup(sio, options) {
  options = options || {};
  if (null == options.forceBase64) {
    options.forceBase64 = exports.forceBase64;
  }

  if (!sio._streamSocket) {
    sio._streamSocket = new Socket(sio, options);
  }
  return sio._streamSocket;
}

/**
 * Creates a new duplex stream.
 *
 * @param {Object} options
 * @return {IOStream} duplex stream
 * @api public
 */
exports.createStream = function(options) {
  return new IOStream(options);
};

/**
 * Creates a new readable stream for Blob/File on browser.
 *
 * @param {Blob} blob
 * @param {Object} options
 * @return {BlobReadStream} stream
 * @api public
 */
exports.createBlobReadStream = function(blob, options) {
  return new BlobReadStream(blob, options);
};

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ "./node_modules/buffer/index.js").Buffer))

/***/ }),

/***/ "./node_modules/socket.io-stream/lib/iostream.js":
/*!*******************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/iostream.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var util = __webpack_require__(/*! util */ "./node_modules/util/util.js");
var Duplex = __webpack_require__(/*! stream */ "./node_modules/stream-browserify/index.js").Duplex;
var bind = __webpack_require__(/*! component-bind */ "./node_modules/component-bind/index.js");
var uuid = __webpack_require__(/*! ./uuid */ "./node_modules/socket.io-stream/lib/uuid.js");
var debug = __webpack_require__(/*! debug */ "./node_modules/socket.io-stream/node_modules/debug/browser.js")('socket.io-stream:iostream');


module.exports = IOStream;

util.inherits(IOStream, Duplex);

/**
 * Duplex
 *
 * @param {Object} options
 * @api private
 */
function IOStream(options) {
  if (!(this instanceof IOStream)) {
    return new IOStream(options);
  }

  IOStream.super_.call(this, options);

  this.options = options;
  this.id = uuid();
  this.socket = null;

  // Buffers
  this.pushBuffer = [];
  this.writeBuffer = [];

  // Op states
  this._readable = false;
  this._writable = false;
  this.destroyed = false;

  // default to *not* allowing half open sockets
  this.allowHalfOpen = options && options.allowHalfOpen || false;

  this.on('finish', this._onfinish);
  this.on('end', this._onend);
  this.on('error', this._onerror);
}

/**
 * Ensures that no more I/O activity happens on this stream.
 * Not necessary in the usual case.
 *
 * @api public
 */
IOStream.prototype.destroy = function() {
  debug('destroy');

  if (this.destroyed) {
    debug('already destroyed');
    return;
  }

  this.readable = this.writable = false;

  if (this.socket) {
    debug('clean up');
    this.socket.cleanup(this.id);
    this.socket = null;
  }

  this.destroyed = true;
};

/**
 * Local read
 *
 * @api private
 */
IOStream.prototype._read = function(size) {
  var push;

  // We can not read from the socket if it's destroyed obviously ...
  if (this.destroyed) return;

  if (this.pushBuffer.length) {
    // flush buffer and end if it exists.
    while (push = this.pushBuffer.shift()) {
      if (!push()) break;
    }
    return;
  }

  this._readable = true;

  // Go get data from remote stream
  // Calls
  // ._onread remotely
  // then
  // ._onwrite locally
  this.socket._read(this.id, size);
};


/**
 * Read from remote stream
 *
 * @api private
 */
IOStream.prototype._onread = function(size) {
  var write = this.writeBuffer.shift();
  if (write) return write();

  this._writable = true;
};

/**
 * Write local data to remote stream
 * Calls
 * remtote ._onwrite
 *
 * @api private
 */
IOStream.prototype._write = function(chunk, encoding, callback) {
  var self = this;

  function write() {
    // We can not write to the socket if it's destroyed obviously ...
    if (self.destroyed) return;

    self._writable = false;
    self.socket._write(self.id, chunk, encoding, callback);
  }

  if (this._writable) {
    write();
  } else {
    this.writeBuffer.push(write);
  }
};

/**
 * Write the data fetched remotely
 * so that we can now read locally
 *
 * @api private
 */
IOStream.prototype._onwrite = function(chunk, encoding, callback) {
  var self = this;

  function push() {
    self._readable = false;
    var ret = self.push(chunk || '', encoding);
    callback();
    return ret;
  }

  if (this._readable) {
    push();
  } else {
    this.pushBuffer.push(push);
  }
};

/**
 * When ending send 'end' event to remote stream
 *
 * @api private
 */
IOStream.prototype._end = function() {
  if (this.pushBuffer.length) {
    // end after flushing buffer.
    this.pushBuffer.push(bind(this, '_done'));
  } else {
    this._done();
  }
};

/**
 * Remote stream just ended
 *
 * @api private
 */
IOStream.prototype._done = function() {
  this._readable = false;

  // signal the end of the data.
  return this.push(null);
};

/**
 * the user has called .end(), and all the bytes have been
 * sent out to the other side.
 * If allowHalfOpen is false, or if the readable side has
 * ended already, then destroy.
 * If allowHalfOpen is true, then we need to set writable false,
 * so that only the writable side will be cleaned up.
 *
 * @api private
 */
IOStream.prototype._onfinish = function() {
  debug('_onfinish');
  // Local socket just finished
  // send 'end' event to remote
  if (this.socket) {
    this.socket._end(this.id);
  }

  this.writable = false;
  this._writableState.ended = true;

  if (!this.readable || this._readableState.ended) {
    debug('_onfinish: ended, destroy %s', this._readableState);
    return this.destroy();
  }

  debug('_onfinish: not ended');

  if (!this.allowHalfOpen) {
    this.push(null);

    // just in case we're waiting for an EOF.
    if (this.readable && !this._readableState.endEmitted) {
      this.read(0);
    }
  }
};

/**
 * the EOF has been received, and no more bytes are coming.
 * if the writable side has ended already, then clean everything
 * up.
 *
 * @api private
 */
IOStream.prototype._onend = function() {
  debug('_onend');
  this.readable = false;
  this._readableState.ended = true;

  if (!this.writable || this._writableState.finished) {
    debug('_onend: %s', this._writableState);
    return this.destroy();
  }

  debug('_onend: not finished');

  if (!this.allowHalfOpen) {
    this.end();
  }
};

/**
 * When error in local stream
 * notyify remote
 * if err.remote = true
 * then error happened on remote stream
 *
 * @api private
 */
IOStream.prototype._onerror = function(err) {
  // check if the error came from remote stream.
  if (!err.remote && this.socket) {
    // notify the error to the corresponding remote stream.
    this.socket._error(this.id, err);
  }

  this.destroy();
};


/***/ }),

/***/ "./node_modules/socket.io-stream/lib/parser.js":
/*!*****************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/parser.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var util = __webpack_require__(/*! util */ "./node_modules/util/util.js");
var EventEmitter = __webpack_require__(/*! events */ "./node_modules/events/events.js").EventEmitter;
var IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/socket.io-stream/lib/iostream.js");
var slice = Array.prototype.slice;

exports.Encoder = Encoder;
exports.Decoder = Decoder;

util.inherits(Encoder, EventEmitter);

function Encoder() {
  EventEmitter.call(this);
}

/**
 * Encode streams to placeholder objects.
 *
 * @api public
 */
Encoder.prototype.encode = function(v) {
  if (v instanceof IOStream) {
    return this.encodeStream(v);
  } else if (util.isArray(v)) {
    return this.encodeArray(v);
  } else if (v && 'object' == typeof v) {
    return this.encodeObject(v);
  }
  return v;
}

Encoder.prototype.encodeStream = function(stream) {
  this.emit('stream', stream);

  // represent a stream in an object.
  var v = { $stream: stream.id };
  if (stream.options) {
    v.options = stream.options;
  }
  return v;
}

Encoder.prototype.encodeArray = function(arr) {
  var v = [];
  for (var i = 0, len = arr.length; i < len; i++) {
    v.push(this.encode(arr[i]));
  }
  return v;
}

Encoder.prototype.encodeObject = function(obj) {
  var v = {};
  for (var k in obj) {
    if (obj.hasOwnProperty(k)) {
      v[k] = this.encode(obj[k]);
    }
  }
  return v;
}

util.inherits(Decoder, EventEmitter);

function Decoder() {
  EventEmitter.call(this);
}

/**
 * Decode placeholder objects to streams.
 *
 * @api public
 */
Decoder.prototype.decode = function(v) {
  if (v && v.$stream) {
    return this.decodeStream(v);
  } else if (util.isArray(v)) {
    return this.decodeArray(v);
  } else if (v && 'object' == typeof v) {
    return this.decodeObject(v);
  }
  return v;
}

Decoder.prototype.decodeStream = function(obj) {
  var stream = new IOStream(obj.options);
  stream.id = obj.$stream;
  this.emit('stream', stream);
  return stream;
}

Decoder.prototype.decodeArray = function(arr) {
  var v = [];
  for (var i = 0, len = arr.length; i < len; i++) {
    v.push(this.decode(arr[i]));
  }
  return v;
}

Decoder.prototype.decodeObject = function(obj) {
  var v = {};
  for (var k in obj) {
    if (obj.hasOwnProperty(k)) {
      v[k] = this.decode(obj[k]);
    }
  }
  return v;
}


/***/ }),

/***/ "./node_modules/socket.io-stream/lib/socket.js":
/*!*****************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/socket.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(Buffer, global) {var util = __webpack_require__(/*! util */ "./node_modules/util/util.js");
var EventEmitter = __webpack_require__(/*! events */ "./node_modules/events/events.js").EventEmitter;
var bind = __webpack_require__(/*! component-bind */ "./node_modules/component-bind/index.js");
var IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/socket.io-stream/lib/iostream.js");
var parser = __webpack_require__(/*! ./parser */ "./node_modules/socket.io-stream/lib/parser.js");
var debug = __webpack_require__(/*! debug */ "./node_modules/socket.io-stream/node_modules/debug/browser.js")('socket.io-stream:socket');
var emit = EventEmitter.prototype.emit;
var on = EventEmitter.prototype.on;
var slice = Array.prototype.slice;


exports = module.exports = Socket;

/**
 * Base event name for messaging.
 *
 * @api public
 */
exports.event = '$stream';

exports.events = [
  'error',
  'newListener',
  'removeListener'
];

util.inherits(Socket, EventEmitter);

/**
 * Bidirectional stream socket which wraps Socket.IO.
 *
 * @param {socket.io#Socket} socket.io
 * @api public
 */
function Socket(sio, options) {
  if (!(this instanceof Socket)) {
    return new Socket(sio, options);
  }

  EventEmitter.call(this);

  options = options || {};

  this.sio = sio;
  this.forceBase64 = !!options.forceBase64;
  this.streams = {};
  this.encoder = new parser.Encoder();
  this.decoder = new parser.Decoder();

  var eventName = exports.event;
  sio.on(eventName, bind(this, emit));
  sio.on(eventName + '-read', bind(this, '_onread'));
  sio.on(eventName + '-write', bind(this, '_onwrite'));
  sio.on(eventName + '-end', bind(this, '_onend'));
  sio.on(eventName + '-error', bind(this, '_onerror'));
  sio.on('error', bind(this, emit, 'error'));
  sio.on('disconnect', bind(this, '_ondisconnect'));

  this.encoder.on('stream', bind(this, '_onencode'));
  this.decoder.on('stream', bind(this, '_ondecode'));
}

/**
 * Original emit function.
 *
 * @api private
 */
Socket.prototype.$emit = emit;

/**
 * Emits streams to this corresponding server/client.
 *
 * @return {Socket} self
 * @api public
 */
Socket.prototype.emit = function(type) {
  if (~exports.events.indexOf(type)) {
    return emit.apply(this, arguments);
  }
  this._stream.apply(this, arguments);
  return this;
};

Socket.prototype.on = function(type, listener) {
  if (~exports.events.indexOf(type)) {
    return on.apply(this, arguments);
  }

  this._onstream(type, listener);
  return this;
};

/**
 * Sends a new stream request.
 *
 * @param {String} event type
 * @api private
 */
Socket.prototype._stream = function(type) {
  debug('sending new streams');

  var self = this;
  var args = slice.call(arguments, 1);
  var ack = args[args.length - 1];
  if ('function' == typeof ack) {
    args[args.length - 1] = function() {
      var args = slice.call(arguments);
      args = self.decoder.decode(args);
      ack.apply(this, args);
    };
  }

  args = this.encoder.encode(args);
  var sio = this.sio;
  sio.emit.apply(sio, [exports.event, type].concat(args));
};

/**
 * Notifies the read event.
 *
 * @api private
 */
Socket.prototype._read = function(id, size) {
  this.sio.emit(exports.event + '-read', id, size);
};

/**
 * Requests to write a chunk.
 *
 * @api private
 */
Socket.prototype._write = function(id, chunk, encoding, callback) {
  if (Buffer.isBuffer(chunk)) {
    if (this.forceBase64) {
      encoding = 'base64';
      chunk = chunk.toString(encoding);
    } else if (!global.Buffer) {
      // socket.io can't handle Buffer when using browserify.
      if (chunk.toArrayBuffer) {
        chunk = chunk.toArrayBuffer();
      } else {
        chunk = chunk.buffer;
      }
    }
  }
  this.sio.emit(exports.event + '-write', id, chunk, encoding, callback);
};

Socket.prototype._end = function(id) {
  this.sio.emit(exports.event + '-end', id);
};

Socket.prototype._error = function(id, err) {
  this.sio.emit(exports.event + '-error', id, err.message || err);
};

/**
 * Handles a new stream request.
 *
 * @param {String} event type
 * @param {Function} listener
 *
 * @api private
 */
Socket.prototype._onstream = function(type, listener) {
  if ('function' != typeof listener) {
    throw TypeError('listener must be a function');
  }

  function onstream() {
    debug('new streams');
    var self = this;
    var args = slice.call(arguments);
    var ack = args[args.length - 1];
    if ('function' == typeof ack) {
      args[args.length - 1] = function() {
        var args = slice.call(arguments);
        args = self.encoder.encode(args);
        ack.apply(this, args);
      };
    }

    args = this.decoder.decode(args);
    listener.apply(this, args);
  }

  // for removeListener
  onstream.listener = listener;

  on.call(this, type, onstream);
};

Socket.prototype._onread = function(id, size) {
  debug('read: "%s"', id);

  var stream = this.streams[id];
  if (stream) {
    stream._onread(size);
  } else {
    debug('ignore invalid stream id');
  }
};

Socket.prototype._onwrite = function(id, chunk, encoding, callback) {
  debug('write: "%s"', id);

  var stream = this.streams[id];
  if (!stream) {
    callback('invalid stream id: ' + id);
    return;
  }

  if (global.ArrayBuffer && chunk instanceof ArrayBuffer) {
    // make sure that chunk is a buffer for stream
    chunk = new Buffer(new Uint8Array(chunk));
  }
  stream._onwrite(chunk, encoding, callback);
};

Socket.prototype._onend = function(id) {
  debug('end: "%s"', id);

  var stream = this.streams[id];
  if (!stream) {
    debug('ignore non-existent stream id: "%s"', id);
    return;
  }

  stream._end();
};

Socket.prototype._onerror = function(id, message) {
  debug('error: "%s", "%s"', id, message);

  var stream = this.streams[id];
  if (!stream) {
    debug('invalid stream id: "%s"', id);
    return;
  }

  var err = new Error(message);
  err.remote = true;
  stream.emit('error', err);
};

Socket.prototype._ondisconnect = function() {
  var stream;
  for (var id in this.streams) {
    stream = this.streams[id];
    stream.destroy();

    // Close streams when the underlaying
    // socket.io connection is closed (regardless why)
    stream.emit('close');
    stream.emit('error', new Error('Connection aborted'));
  }
};

Socket.prototype._onencode = function(stream) {
  if (stream.socket || stream.destroyed) {
    throw new Error('stream has already been sent.');
  }

  var id = stream.id;
  if (this.streams[id]) {
    throw new Error('Encoded stream already exists: ' + id);
  }

  this.streams[id] = stream;
  stream.socket = this;
};

Socket.prototype._ondecode = function(stream) {
  var id = stream.id;
  if (this.streams[id]) {
    this._error(id, new Error('Decoded stream already exists: ' + id));
    return;
  }

  this.streams[id] = stream;
  stream.socket = this;
};

Socket.prototype.cleanup = function(id) {
  delete this.streams[id];
};


/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ "./node_modules/buffer/index.js").Buffer, __webpack_require__(/*! ./../../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/socket.io-stream/lib/uuid.js":
/*!***************************************************!*\
  !*** ./node_modules/socket.io-stream/lib/uuid.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

// UUID function from https://gist.github.com/jed/982883
// More lightweight than node-uuid
function b(
  a                  // placeholder
){
  return a           // if the placeholder was passed, return
    ? (              // a random number from 0 to 15
      a ^            // unless b is 8,
      Math.random()  // in which case
      * 16           // a random number from
      >> a/4         // 8 to 11
      ).toString(16) // in hexadecimal
    : (              // or otherwise a concatenated string:
      [1e7] +        // 10000000 +
      -1e3 +         // -1000 +
      -4e3 +         // -4000 +
      -8e3 +         // -80000000 +
      -1e11          // -100000000000,
      ).replace(     // replacing
        /[018]/g,    // zeroes, ones, and eights with
        b            // random hex digits
      )
}

module.exports = b;


/***/ }),

/***/ "./node_modules/socket.io-stream/node_modules/debug/browser.js":
/*!*********************************************************************!*\
  !*** ./node_modules/socket.io-stream/node_modules/debug/browser.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


/**
 * This is the web browser implementation of `debug()`.
 *
 * Expose `debug()` as the module.
 */

exports = module.exports = __webpack_require__(/*! ./debug */ "./node_modules/socket.io-stream/node_modules/debug/debug.js");
exports.log = log;
exports.formatArgs = formatArgs;
exports.save = save;
exports.load = load;
exports.useColors = useColors;
exports.storage = 'undefined' != typeof chrome
               && 'undefined' != typeof chrome.storage
                  ? chrome.storage.local
                  : localstorage();

/**
 * Colors.
 */

exports.colors = [
  'lightseagreen',
  'forestgreen',
  'goldenrod',
  'dodgerblue',
  'darkorchid',
  'crimson'
];

/**
 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
 * and the Firebug extension (any Firefox version) are known
 * to support "%c" CSS customizations.
 *
 * TODO: add a `localStorage` variable to explicitly enable/disable colors
 */

function useColors() {
  // is webkit? http://stackoverflow.com/a/16459606/376773
  return ('WebkitAppearance' in document.documentElement.style) ||
    // is firebug? http://stackoverflow.com/a/398120/376773
    (window.console && (console.firebug || (console.exception && console.table))) ||
    // is firefox >= v31?
    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
    (navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31);
}

/**
 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
 */

exports.formatters.j = function(v) {
  return JSON.stringify(v);
};


/**
 * Colorize log arguments if enabled.
 *
 * @api public
 */

function formatArgs() {
  var args = arguments;
  var useColors = this.useColors;

  args[0] = (useColors ? '%c' : '')
    + this.namespace
    + (useColors ? ' %c' : ' ')
    + args[0]
    + (useColors ? '%c ' : ' ')
    + '+' + exports.humanize(this.diff);

  if (!useColors) return args;

  var c = 'color: ' + this.color;
  args = [args[0], c, 'color: inherit'].concat(Array.prototype.slice.call(args, 1));

  // the final "%c" is somewhat tricky, because there could be other
  // arguments passed either before or after the %c, so we need to
  // figure out the correct index to insert the CSS into
  var index = 0;
  var lastC = 0;
  args[0].replace(/%[a-z%]/g, function(match) {
    if ('%%' === match) return;
    index++;
    if ('%c' === match) {
      // we only are interested in the *last* %c
      // (the user may have provided their own)
      lastC = index;
    }
  });

  args.splice(lastC, 0, c);
  return args;
}

/**
 * Invokes `console.log()` when available.
 * No-op when `console.log` is not a "function".
 *
 * @api public
 */

function log() {
  // this hackery is required for IE8/9, where
  // the `console.log` function doesn't have 'apply'
  return 'object' === typeof console
    && console.log
    && Function.prototype.apply.call(console.log, console, arguments);
}

/**
 * Save `namespaces`.
 *
 * @param {String} namespaces
 * @api private
 */

function save(namespaces) {
  try {
    if (null == namespaces) {
      exports.storage.removeItem('debug');
    } else {
      exports.storage.debug = namespaces;
    }
  } catch(e) {}
}

/**
 * Load `namespaces`.
 *
 * @return {String} returns the previously persisted debug modes
 * @api private
 */

function load() {
  var r;
  try {
    r = exports.storage.debug;
  } catch(e) {}
  return r;
}

/**
 * Enable namespaces listed in `localStorage.debug` initially.
 */

exports.enable(load());

/**
 * Localstorage attempts to return the localstorage.
 *
 * This is necessary because safari throws
 * when a user disables cookies/localstorage
 * and you attempt to access it.
 *
 * @return {LocalStorage}
 * @api private
 */

function localstorage(){
  try {
    return window.localStorage;
  } catch (e) {}
}


/***/ }),

/***/ "./node_modules/socket.io-stream/node_modules/debug/debug.js":
/*!*******************************************************************!*\
  !*** ./node_modules/socket.io-stream/node_modules/debug/debug.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 *
 * Expose `debug()` as the module.
 */

exports = module.exports = debug;
exports.coerce = coerce;
exports.disable = disable;
exports.enable = enable;
exports.enabled = enabled;
exports.humanize = __webpack_require__(/*! ms */ "./node_modules/socket.io-stream/node_modules/ms/index.js");

/**
 * The currently active debug mode names, and names to skip.
 */

exports.names = [];
exports.skips = [];

/**
 * Map of special "%n" handling functions, for the debug "format" argument.
 *
 * Valid key names are a single, lowercased letter, i.e. "n".
 */

exports.formatters = {};

/**
 * Previously assigned color.
 */

var prevColor = 0;

/**
 * Previous log timestamp.
 */

var prevTime;

/**
 * Select a color.
 *
 * @return {Number}
 * @api private
 */

function selectColor() {
  return exports.colors[prevColor++ % exports.colors.length];
}

/**
 * Create a debugger with the given `namespace`.
 *
 * @param {String} namespace
 * @return {Function}
 * @api public
 */

function debug(namespace) {

  // define the `disabled` version
  function disabled() {
  }
  disabled.enabled = false;

  // define the `enabled` version
  function enabled() {

    var self = enabled;

    // set `diff` timestamp
    var curr = +new Date();
    var ms = curr - (prevTime || curr);
    self.diff = ms;
    self.prev = prevTime;
    self.curr = curr;
    prevTime = curr;

    // add the `color` if not set
    if (null == self.useColors) self.useColors = exports.useColors();
    if (null == self.color && self.useColors) self.color = selectColor();

    var args = Array.prototype.slice.call(arguments);

    args[0] = exports.coerce(args[0]);

    if ('string' !== typeof args[0]) {
      // anything else let's inspect with %o
      args = ['%o'].concat(args);
    }

    // apply any `formatters` transformations
    var index = 0;
    args[0] = args[0].replace(/%([a-z%])/g, function(match, format) {
      // if we encounter an escaped % then don't increase the array index
      if (match === '%%') return match;
      index++;
      var formatter = exports.formatters[format];
      if ('function' === typeof formatter) {
        var val = args[index];
        match = formatter.call(self, val);

        // now we need to remove `args[index]` since it's inlined in the `format`
        args.splice(index, 1);
        index--;
      }
      return match;
    });

    if ('function' === typeof exports.formatArgs) {
      args = exports.formatArgs.apply(self, args);
    }
    var logFn = enabled.log || exports.log || console.log.bind(console);
    logFn.apply(self, args);
  }
  enabled.enabled = true;

  var fn = exports.enabled(namespace) ? enabled : disabled;

  fn.namespace = namespace;

  return fn;
}

/**
 * Enables a debug mode by namespaces. This can include modes
 * separated by a colon and wildcards.
 *
 * @param {String} namespaces
 * @api public
 */

function enable(namespaces) {
  exports.save(namespaces);

  var split = (namespaces || '').split(/[\s,]+/);
  var len = split.length;

  for (var i = 0; i < len; i++) {
    if (!split[i]) continue; // ignore empty strings
    namespaces = split[i].replace(/\*/g, '.*?');
    if (namespaces[0] === '-') {
      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));
    } else {
      exports.names.push(new RegExp('^' + namespaces + '$'));
    }
  }
}

/**
 * Disable debug output.
 *
 * @api public
 */

function disable() {
  exports.enable('');
}

/**
 * Returns true if the given mode name is enabled, false otherwise.
 *
 * @param {String} name
 * @return {Boolean}
 * @api public
 */

function enabled(name) {
  var i, len;
  for (i = 0, len = exports.skips.length; i < len; i++) {
    if (exports.skips[i].test(name)) {
      return false;
    }
  }
  for (i = 0, len = exports.names.length; i < len; i++) {
    if (exports.names[i].test(name)) {
      return true;
    }
  }
  return false;
}

/**
 * Coerce `val`.
 *
 * @param {Mixed} val
 * @return {Mixed}
 * @api private
 */

function coerce(val) {
  if (val instanceof Error) return val.stack || val.message;
  return val;
}


/***/ }),

/***/ "./node_modules/socket.io-stream/node_modules/ms/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/socket.io-stream/node_modules/ms/index.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/**
 * Helpers.
 */

var s = 1000;
var m = s * 60;
var h = m * 60;
var d = h * 24;
var y = d * 365.25;

/**
 * Parse or format the given `val`.
 *
 * Options:
 *
 *  - `long` verbose formatting [false]
 *
 * @param {String|Number} val
 * @param {Object} options
 * @return {String|Number}
 * @api public
 */

module.exports = function(val, options){
  options = options || {};
  if ('string' == typeof val) return parse(val);
  return options.long
    ? long(val)
    : short(val);
};

/**
 * Parse the given `str` and return milliseconds.
 *
 * @param {String} str
 * @return {Number}
 * @api private
 */

function parse(str) {
  str = '' + str;
  if (str.length > 10000) return;
  var match = /^((?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str);
  if (!match) return;
  var n = parseFloat(match[1]);
  var type = (match[2] || 'ms').toLowerCase();
  switch (type) {
    case 'years':
    case 'year':
    case 'yrs':
    case 'yr':
    case 'y':
      return n * y;
    case 'days':
    case 'day':
    case 'd':
      return n * d;
    case 'hours':
    case 'hour':
    case 'hrs':
    case 'hr':
    case 'h':
      return n * h;
    case 'minutes':
    case 'minute':
    case 'mins':
    case 'min':
    case 'm':
      return n * m;
    case 'seconds':
    case 'second':
    case 'secs':
    case 'sec':
    case 's':
      return n * s;
    case 'milliseconds':
    case 'millisecond':
    case 'msecs':
    case 'msec':
    case 'ms':
      return n;
  }
}

/**
 * Short format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function short(ms) {
  if (ms >= d) return Math.round(ms / d) + 'd';
  if (ms >= h) return Math.round(ms / h) + 'h';
  if (ms >= m) return Math.round(ms / m) + 'm';
  if (ms >= s) return Math.round(ms / s) + 's';
  return ms + 'ms';
}

/**
 * Long format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function long(ms) {
  return plural(ms, d, 'day')
    || plural(ms, h, 'hour')
    || plural(ms, m, 'minute')
    || plural(ms, s, 'second')
    || ms + ' ms';
}

/**
 * Pluralization helper.
 */

function plural(ms, n, name) {
  if (ms < n) return;
  if (ms < n * 1.5) return Math.floor(ms / n) + ' ' + name;
  return Math.ceil(ms / n) + ' ' + name + 's';
}


/***/ }),

/***/ "./node_modules/stream-browserify/index.js":
/*!*************************************************!*\
  !*** ./node_modules/stream-browserify/index.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

module.exports = Stream;

var EE = __webpack_require__(/*! events */ "./node_modules/events/events.js").EventEmitter;
var inherits = __webpack_require__(/*! inherits */ "./node_modules/inherits/inherits_browser.js");

inherits(Stream, EE);
Stream.Readable = __webpack_require__(/*! readable-stream/readable.js */ "./node_modules/readable-stream/readable-browser.js");
Stream.Writable = __webpack_require__(/*! readable-stream/writable.js */ "./node_modules/readable-stream/writable-browser.js");
Stream.Duplex = __webpack_require__(/*! readable-stream/duplex.js */ "./node_modules/readable-stream/duplex-browser.js");
Stream.Transform = __webpack_require__(/*! readable-stream/transform.js */ "./node_modules/readable-stream/transform.js");
Stream.PassThrough = __webpack_require__(/*! readable-stream/passthrough.js */ "./node_modules/readable-stream/passthrough.js");

// Backwards-compat with node 0.4.x
Stream.Stream = Stream;



// old-style streams.  Note that the pipe method (the only relevant
// part of this class) is overridden in the Readable class.

function Stream() {
  EE.call(this);
}

Stream.prototype.pipe = function(dest, options) {
  var source = this;

  function ondata(chunk) {
    if (dest.writable) {
      if (false === dest.write(chunk) && source.pause) {
        source.pause();
      }
    }
  }

  source.on('data', ondata);

  function ondrain() {
    if (source.readable && source.resume) {
      source.resume();
    }
  }

  dest.on('drain', ondrain);

  // If the 'end' option is not supplied, dest.end() will be called when
  // source gets the 'end' or 'close' events.  Only dest.end() once.
  if (!dest._isStdio && (!options || options.end !== false)) {
    source.on('end', onend);
    source.on('close', onclose);
  }

  var didOnEnd = false;
  function onend() {
    if (didOnEnd) return;
    didOnEnd = true;

    dest.end();
  }


  function onclose() {
    if (didOnEnd) return;
    didOnEnd = true;

    if (typeof dest.destroy === 'function') dest.destroy();
  }

  // don't leave dangling pipes when there are errors.
  function onerror(er) {
    cleanup();
    if (EE.listenerCount(this, 'error') === 0) {
      throw er; // Unhandled stream error in pipe.
    }
  }

  source.on('error', onerror);
  dest.on('error', onerror);

  // remove all the event listeners that were added.
  function cleanup() {
    source.removeListener('data', ondata);
    dest.removeListener('drain', ondrain);

    source.removeListener('end', onend);
    source.removeListener('close', onclose);

    source.removeListener('error', onerror);
    dest.removeListener('error', onerror);

    source.removeListener('end', cleanup);
    source.removeListener('close', cleanup);

    dest.removeListener('close', cleanup);
  }

  source.on('end', cleanup);
  source.on('close', cleanup);

  dest.on('close', cleanup);

  dest.emit('pipe', source);

  // Allow for unix-like usage: A.pipe(B).pipe(C)
  return dest;
};


/***/ }),

/***/ "./node_modules/string_decoder/lib/string_decoder.js":
/*!***********************************************************!*\
  !*** ./node_modules/string_decoder/lib/string_decoder.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.



/*<replacement>*/

var Buffer = __webpack_require__(/*! safe-buffer */ "./node_modules/string_decoder/node_modules/safe-buffer/index.js").Buffer;
/*</replacement>*/

var isEncoding = Buffer.isEncoding || function (encoding) {
  encoding = '' + encoding;
  switch (encoding && encoding.toLowerCase()) {
    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
      return true;
    default:
      return false;
  }
};

function _normalizeEncoding(enc) {
  if (!enc) return 'utf8';
  var retried;
  while (true) {
    switch (enc) {
      case 'utf8':
      case 'utf-8':
        return 'utf8';
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return 'utf16le';
      case 'latin1':
      case 'binary':
        return 'latin1';
      case 'base64':
      case 'ascii':
      case 'hex':
        return enc;
      default:
        if (retried) return; // undefined
        enc = ('' + enc).toLowerCase();
        retried = true;
    }
  }
};

// Do not cache `Buffer.isEncoding` when checking encoding names as some
// modules monkey-patch it to support additional encodings
function normalizeEncoding(enc) {
  var nenc = _normalizeEncoding(enc);
  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
  return nenc || enc;
}

// StringDecoder provides an interface for efficiently splitting a series of
// buffers into a series of JS strings without breaking apart multi-byte
// characters.
exports.StringDecoder = StringDecoder;
function StringDecoder(encoding) {
  this.encoding = normalizeEncoding(encoding);
  var nb;
  switch (this.encoding) {
    case 'utf16le':
      this.text = utf16Text;
      this.end = utf16End;
      nb = 4;
      break;
    case 'utf8':
      this.fillLast = utf8FillLast;
      nb = 4;
      break;
    case 'base64':
      this.text = base64Text;
      this.end = base64End;
      nb = 3;
      break;
    default:
      this.write = simpleWrite;
      this.end = simpleEnd;
      return;
  }
  this.lastNeed = 0;
  this.lastTotal = 0;
  this.lastChar = Buffer.allocUnsafe(nb);
}

StringDecoder.prototype.write = function (buf) {
  if (buf.length === 0) return '';
  var r;
  var i;
  if (this.lastNeed) {
    r = this.fillLast(buf);
    if (r === undefined) return '';
    i = this.lastNeed;
    this.lastNeed = 0;
  } else {
    i = 0;
  }
  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
  return r || '';
};

StringDecoder.prototype.end = utf8End;

// Returns only complete characters in a Buffer
StringDecoder.prototype.text = utf8Text;

// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
StringDecoder.prototype.fillLast = function (buf) {
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
  this.lastNeed -= buf.length;
};

// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
// continuation byte. If an invalid byte is detected, -2 is returned.
function utf8CheckByte(byte) {
  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
  return byte >> 6 === 0x02 ? -1 : -2;
}

// Checks at most 3 bytes at the end of a Buffer in order to detect an
// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
// needed to complete the UTF-8 character (if applicable) are returned.
function utf8CheckIncomplete(self, buf, i) {
  var j = buf.length - 1;
  if (j < i) return 0;
  var nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 1;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 2;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) {
      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
    }
    return nb;
  }
  return 0;
}

// Validates as many continuation bytes for a multi-byte UTF-8 character as
// needed or are available. If we see a non-continuation byte where we expect
// one, we "replace" the validated continuation bytes we've seen so far with
// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
// behavior. The continuation byte check is included three times in the case
// where all of the continuation bytes for a character exist in the same buffer.
// It is also done this way as a slight performance increase instead of using a
// loop.
function utf8CheckExtraBytes(self, buf, p) {
  if ((buf[0] & 0xC0) !== 0x80) {
    self.lastNeed = 0;
    return '\ufffd';
  }
  if (self.lastNeed > 1 && buf.length > 1) {
    if ((buf[1] & 0xC0) !== 0x80) {
      self.lastNeed = 1;
      return '\ufffd';
    }
    if (self.lastNeed > 2 && buf.length > 2) {
      if ((buf[2] & 0xC0) !== 0x80) {
        self.lastNeed = 2;
        return '\ufffd';
      }
    }
  }
}

// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
function utf8FillLast(buf) {
  var p = this.lastTotal - this.lastNeed;
  var r = utf8CheckExtraBytes(this, buf, p);
  if (r !== undefined) return r;
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, p, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, p, 0, buf.length);
  this.lastNeed -= buf.length;
}

// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
// partial character, the character's bytes are buffered until the required
// number of bytes are available.
function utf8Text(buf, i) {
  var total = utf8CheckIncomplete(this, buf, i);
  if (!this.lastNeed) return buf.toString('utf8', i);
  this.lastTotal = total;
  var end = buf.length - (total - this.lastNeed);
  buf.copy(this.lastChar, 0, end);
  return buf.toString('utf8', i, end);
}

// For UTF-8, a replacement character is added when ending on a partial
// character.
function utf8End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + '\ufffd';
  return r;
}

// UTF-16LE typically needs two bytes per character, but even if we have an even
// number of bytes available, we need to check if we end on a leading/high
// surrogate. In that case, we need to wait for the next two bytes in order to
// decode the last character properly.
function utf16Text(buf, i) {
  if ((buf.length - i) % 2 === 0) {
    var r = buf.toString('utf16le', i);
    if (r) {
      var c = r.charCodeAt(r.length - 1);
      if (c >= 0xD800 && c <= 0xDBFF) {
        this.lastNeed = 2;
        this.lastTotal = 4;
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
        return r.slice(0, -1);
      }
    }
    return r;
  }
  this.lastNeed = 1;
  this.lastTotal = 2;
  this.lastChar[0] = buf[buf.length - 1];
  return buf.toString('utf16le', i, buf.length - 1);
}

// For UTF-16LE we do not explicitly append special replacement characters if we
// end on a partial character, we simply let v8 handle that.
function utf16End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) {
    var end = this.lastTotal - this.lastNeed;
    return r + this.lastChar.toString('utf16le', 0, end);
  }
  return r;
}

function base64Text(buf, i) {
  var n = (buf.length - i) % 3;
  if (n === 0) return buf.toString('base64', i);
  this.lastNeed = 3 - n;
  this.lastTotal = 3;
  if (n === 1) {
    this.lastChar[0] = buf[buf.length - 1];
  } else {
    this.lastChar[0] = buf[buf.length - 2];
    this.lastChar[1] = buf[buf.length - 1];
  }
  return buf.toString('base64', i, buf.length - n);
}

function base64End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
  return r;
}

// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
function simpleWrite(buf) {
  return buf.toString(this.encoding);
}

function simpleEnd(buf) {
  return buf && buf.length ? this.write(buf) : '';
}

/***/ }),

/***/ "./node_modules/string_decoder/node_modules/safe-buffer/index.js":
/*!***********************************************************************!*\
  !*** ./node_modules/string_decoder/node_modules/safe-buffer/index.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* eslint-disable node/no-deprecated-api */
var buffer = __webpack_require__(/*! buffer */ "./node_modules/buffer/index.js")
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}


/***/ }),

/***/ "./node_modules/universal-cookie/es6/Cookies.js":
/*!******************************************************!*\
  !*** ./node_modules/universal-cookie/es6/Cookies.js ***!
  \******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var cookie__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! cookie */ "./node_modules/cookie/index.js");
/* harmony import */ var cookie__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(cookie__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ "./node_modules/universal-cookie/es6/utils.js");
var __assign = (undefined && undefined.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};


var Cookies = /** @class */ (function () {
    function Cookies(cookies, options) {
        var _this = this;
        this.changeListeners = [];
        this.HAS_DOCUMENT_COOKIE = false;
        this.cookies = Object(_utils__WEBPACK_IMPORTED_MODULE_1__["parseCookies"])(cookies, options);
        new Promise(function () {
            _this.HAS_DOCUMENT_COOKIE = Object(_utils__WEBPACK_IMPORTED_MODULE_1__["hasDocumentCookie"])();
        }).catch(function () { });
    }
    Cookies.prototype._updateBrowserValues = function (parseOptions) {
        if (!this.HAS_DOCUMENT_COOKIE) {
            return;
        }
        this.cookies = cookie__WEBPACK_IMPORTED_MODULE_0__["parse"](document.cookie, parseOptions);
    };
    Cookies.prototype._emitChange = function (params) {
        for (var i = 0; i < this.changeListeners.length; ++i) {
            this.changeListeners[i](params);
        }
    };
    Cookies.prototype.get = function (name, options, parseOptions) {
        if (options === void 0) { options = {}; }
        this._updateBrowserValues(parseOptions);
        return Object(_utils__WEBPACK_IMPORTED_MODULE_1__["readCookie"])(this.cookies[name], options);
    };
    Cookies.prototype.getAll = function (options, parseOptions) {
        if (options === void 0) { options = {}; }
        this._updateBrowserValues(parseOptions);
        var result = {};
        for (var name_1 in this.cookies) {
            result[name_1] = Object(_utils__WEBPACK_IMPORTED_MODULE_1__["readCookie"])(this.cookies[name_1], options);
        }
        return result;
    };
    Cookies.prototype.set = function (name, value, options) {
        var _a;
        if (typeof value === 'object') {
            value = JSON.stringify(value);
        }
        this.cookies = __assign(__assign({}, this.cookies), (_a = {}, _a[name] = value, _a));
        if (this.HAS_DOCUMENT_COOKIE) {
            document.cookie = cookie__WEBPACK_IMPORTED_MODULE_0__["serialize"](name, value, options);
        }
        this._emitChange({ name: name, value: value, options: options });
    };
    Cookies.prototype.remove = function (name, options) {
        var finalOptions = (options = __assign(__assign({}, options), { expires: new Date(1970, 1, 1, 0, 0, 1), maxAge: 0 }));
        this.cookies = __assign({}, this.cookies);
        delete this.cookies[name];
        if (this.HAS_DOCUMENT_COOKIE) {
            document.cookie = cookie__WEBPACK_IMPORTED_MODULE_0__["serialize"](name, '', finalOptions);
        }
        this._emitChange({ name: name, value: undefined, options: options });
    };
    Cookies.prototype.addChangeListener = function (callback) {
        this.changeListeners.push(callback);
    };
    Cookies.prototype.removeChangeListener = function (callback) {
        var idx = this.changeListeners.indexOf(callback);
        if (idx >= 0) {
            this.changeListeners.splice(idx, 1);
        }
    };
    return Cookies;
}());
/* harmony default export */ __webpack_exports__["default"] = (Cookies);


/***/ }),

/***/ "./node_modules/universal-cookie/es6/index.js":
/*!****************************************************!*\
  !*** ./node_modules/universal-cookie/es6/index.js ***!
  \****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _Cookies__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Cookies */ "./node_modules/universal-cookie/es6/Cookies.js");

/* harmony default export */ __webpack_exports__["default"] = (_Cookies__WEBPACK_IMPORTED_MODULE_0__["default"]);


/***/ }),

/***/ "./node_modules/universal-cookie/es6/utils.js":
/*!****************************************************!*\
  !*** ./node_modules/universal-cookie/es6/utils.js ***!
  \****************************************************/
/*! exports provided: hasDocumentCookie, cleanCookies, parseCookies, isParsingCookie, readCookie */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "hasDocumentCookie", function() { return hasDocumentCookie; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "cleanCookies", function() { return cleanCookies; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseCookies", function() { return parseCookies; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isParsingCookie", function() { return isParsingCookie; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "readCookie", function() { return readCookie; });
/* harmony import */ var cookie__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! cookie */ "./node_modules/cookie/index.js");
/* harmony import */ var cookie__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(cookie__WEBPACK_IMPORTED_MODULE_0__);

function hasDocumentCookie() {
    // Can we get/set cookies on document.cookie?
    return typeof document === 'object' && typeof document.cookie === 'string';
}
function cleanCookies() {
    document.cookie.split(';').forEach(function (c) {
        document.cookie = c
            .replace(/^ +/, '')
            .replace(/=.*/, '=;expires=' + new Date().toUTCString() + ';path=/');
    });
}
function parseCookies(cookies, options) {
    if (typeof cookies === 'string') {
        return cookie__WEBPACK_IMPORTED_MODULE_0__["parse"](cookies, options);
    }
    else if (typeof cookies === 'object' && cookies !== null) {
        return cookies;
    }
    else {
        return {};
    }
}
function isParsingCookie(value, doNotParse) {
    if (typeof doNotParse === 'undefined') {
        // We guess if the cookie start with { or [, it has been serialized
        doNotParse =
            !value || (value[0] !== '{' && value[0] !== '[' && value[0] !== '"');
    }
    return !doNotParse;
}
function readCookie(value, options) {
    if (options === void 0) { options = {}; }
    var cleanValue = cleanupCookieValue(value);
    if (isParsingCookie(cleanValue, options.doNotParse)) {
        try {
            return JSON.parse(cleanValue);
        }
        catch (e) {
            // At least we tried
        }
    }
    // Ignore clean value if we failed the deserialization
    // It is not relevant anymore to trim those values
    return value;
}
function cleanupCookieValue(value) {
    // express prepend j: before serializing a cookie
    if (value && value[0] === 'j' && value[1] === ':') {
        return value.substr(2);
    }
    return value;
}


/***/ }),

/***/ "./node_modules/url-parse/index.js":
/*!*****************************************!*\
  !*** ./node_modules/url-parse/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
/* WEBPACK VAR INJECTION */(function(global) {

var required = __webpack_require__(/*! requires-port */ "./node_modules/requires-port/index.js")
  , qs = __webpack_require__(/*! querystringify */ "./node_modules/querystringify/index.js")
  , slashes = /^[A-Za-z][A-Za-z0-9+-.]*:\/\//
  , protocolre = /^([a-z][a-z0-9.+-]*:)?(\/\/)?([\\/]+)?([\S\s]*)/i
  , windowsDriveLetter = /^[a-zA-Z]:/
  , whitespace = '[\\x09\\x0A\\x0B\\x0C\\x0D\\x20\\xA0\\u1680\\u180E\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u202F\\u205F\\u3000\\u2028\\u2029\\uFEFF]'
  , left = new RegExp('^'+ whitespace +'+');

/**
 * Trim a given string.
 *
 * @param {String} str String to trim.
 * @public
 */
function trimLeft(str) {
  return (str ? str : '').toString().replace(left, '');
}

/**
 * These are the parse rules for the URL parser, it informs the parser
 * about:
 *
 * 0. The char it Needs to parse, if it's a string it should be done using
 *    indexOf, RegExp using exec and NaN means set as current value.
 * 1. The property we should set when parsing this value.
 * 2. Indication if it's backwards or forward parsing, when set as number it's
 *    the value of extra chars that should be split off.
 * 3. Inherit from location if non existing in the parser.
 * 4. `toLowerCase` the resulting value.
 */
var rules = [
  ['#', 'hash'],                        // Extract from the back.
  ['?', 'query'],                       // Extract from the back.
  function sanitize(address, url) {     // Sanitize what is left of the address
    return isSpecial(url.protocol) ? address.replace(/\\/g, '/') : address;
  },
  ['/', 'pathname'],                    // Extract from the back.
  ['@', 'auth', 1],                     // Extract from the front.
  [NaN, 'host', undefined, 1, 1],       // Set left over value.
  [/:(\d+)$/, 'port', undefined, 1],    // RegExp the back.
  [NaN, 'hostname', undefined, 1, 1]    // Set left over.
];

/**
 * These properties should not be copied or inherited from. This is only needed
 * for all non blob URL's as a blob URL does not include a hash, only the
 * origin.
 *
 * @type {Object}
 * @private
 */
var ignore = { hash: 1, query: 1 };

/**
 * The location object differs when your code is loaded through a normal page,
 * Worker or through a worker using a blob. And with the blobble begins the
 * trouble as the location object will contain the URL of the blob, not the
 * location of the page where our code is loaded in. The actual origin is
 * encoded in the `pathname` so we can thankfully generate a good "default"
 * location from it so we can generate proper relative URL's again.
 *
 * @param {Object|String} loc Optional default location object.
 * @returns {Object} lolcation object.
 * @public
 */
function lolcation(loc) {
  var globalVar;

  if (typeof window !== 'undefined') globalVar = window;
  else if (typeof global !== 'undefined') globalVar = global;
  else if (typeof self !== 'undefined') globalVar = self;
  else globalVar = {};

  var location = globalVar.location || {};
  loc = loc || location;

  var finaldestination = {}
    , type = typeof loc
    , key;

  if ('blob:' === loc.protocol) {
    finaldestination = new Url(unescape(loc.pathname), {});
  } else if ('string' === type) {
    finaldestination = new Url(loc, {});
    for (key in ignore) delete finaldestination[key];
  } else if ('object' === type) {
    for (key in loc) {
      if (key in ignore) continue;
      finaldestination[key] = loc[key];
    }

    if (finaldestination.slashes === undefined) {
      finaldestination.slashes = slashes.test(loc.href);
    }
  }

  return finaldestination;
}

/**
 * Check whether a protocol scheme is special.
 *
 * @param {String} The protocol scheme of the URL
 * @return {Boolean} `true` if the protocol scheme is special, else `false`
 * @private
 */
function isSpecial(scheme) {
  return (
    scheme === 'file:' ||
    scheme === 'ftp:' ||
    scheme === 'http:' ||
    scheme === 'https:' ||
    scheme === 'ws:' ||
    scheme === 'wss:'
  );
}

/**
 * @typedef ProtocolExtract
 * @type Object
 * @property {String} protocol Protocol matched in the URL, in lowercase.
 * @property {Boolean} slashes `true` if protocol is followed by "//", else `false`.
 * @property {String} rest Rest of the URL that is not part of the protocol.
 */

/**
 * Extract protocol information from a URL with/without double slash ("//").
 *
 * @param {String} address URL we want to extract from.
 * @param {Object} location
 * @return {ProtocolExtract} Extracted information.
 * @private
 */
function extractProtocol(address, location) {
  address = trimLeft(address);
  location = location || {};

  var match = protocolre.exec(address);
  var protocol = match[1] ? match[1].toLowerCase() : '';
  var forwardSlashes = !!match[2];
  var otherSlashes = !!match[3];
  var slashesCount = 0;
  var rest;

  if (forwardSlashes) {
    if (otherSlashes) {
      rest = match[2] + match[3] + match[4];
      slashesCount = match[2].length + match[3].length;
    } else {
      rest = match[2] + match[4];
      slashesCount = match[2].length;
    }
  } else {
    if (otherSlashes) {
      rest = match[3] + match[4];
      slashesCount = match[3].length;
    } else {
      rest = match[4]
    }
  }

  if (protocol === 'file:') {
    if (slashesCount >= 2) {
      rest = rest.slice(2);
    }
  } else if (isSpecial(protocol)) {
    rest = match[4];
  } else if (protocol) {
    if (forwardSlashes) {
      rest = rest.slice(2);
    }
  } else if (slashesCount >= 2 && isSpecial(location.protocol)) {
    rest = match[4];
  }

  return {
    protocol: protocol,
    slashes: forwardSlashes || isSpecial(protocol),
    slashesCount: slashesCount,
    rest: rest
  };
}

/**
 * Resolve a relative URL pathname against a base URL pathname.
 *
 * @param {String} relative Pathname of the relative URL.
 * @param {String} base Pathname of the base URL.
 * @return {String} Resolved pathname.
 * @private
 */
function resolve(relative, base) {
  if (relative === '') return base;

  var path = (base || '/').split('/').slice(0, -1).concat(relative.split('/'))
    , i = path.length
    , last = path[i - 1]
    , unshift = false
    , up = 0;

  while (i--) {
    if (path[i] === '.') {
      path.splice(i, 1);
    } else if (path[i] === '..') {
      path.splice(i, 1);
      up++;
    } else if (up) {
      if (i === 0) unshift = true;
      path.splice(i, 1);
      up--;
    }
  }

  if (unshift) path.unshift('');
  if (last === '.' || last === '..') path.push('');

  return path.join('/');
}

/**
 * The actual URL instance. Instead of returning an object we've opted-in to
 * create an actual constructor as it's much more memory efficient and
 * faster and it pleases my OCD.
 *
 * It is worth noting that we should not use `URL` as class name to prevent
 * clashes with the global URL instance that got introduced in browsers.
 *
 * @constructor
 * @param {String} address URL we want to parse.
 * @param {Object|String} [location] Location defaults for relative paths.
 * @param {Boolean|Function} [parser] Parser for the query string.
 * @private
 */
function Url(address, location, parser) {
  address = trimLeft(address);

  if (!(this instanceof Url)) {
    return new Url(address, location, parser);
  }

  var relative, extracted, parse, instruction, index, key
    , instructions = rules.slice()
    , type = typeof location
    , url = this
    , i = 0;

  //
  // The following if statements allows this module two have compatibility with
  // 2 different API:
  //
  // 1. Node.js's `url.parse` api which accepts a URL, boolean as arguments
  //    where the boolean indicates that the query string should also be parsed.
  //
  // 2. The `URL` interface of the browser which accepts a URL, object as
  //    arguments. The supplied object will be used as default values / fall-back
  //    for relative paths.
  //
  if ('object' !== type && 'string' !== type) {
    parser = location;
    location = null;
  }

  if (parser && 'function' !== typeof parser) parser = qs.parse;

  location = lolcation(location);

  //
  // Extract protocol information before running the instructions.
  //
  extracted = extractProtocol(address || '', location);
  relative = !extracted.protocol && !extracted.slashes;
  url.slashes = extracted.slashes || relative && location.slashes;
  url.protocol = extracted.protocol || location.protocol || '';
  address = extracted.rest;

  //
  // When the authority component is absent the URL starts with a path
  // component.
  //
  if (
    extracted.protocol === 'file:' && (
      extracted.slashesCount !== 2 || windowsDriveLetter.test(address)) ||
    (!extracted.slashes &&
      (extracted.protocol ||
        extracted.slashesCount < 2 ||
        !isSpecial(url.protocol)))
  ) {
    instructions[3] = [/(.*)/, 'pathname'];
  }

  for (; i < instructions.length; i++) {
    instruction = instructions[i];

    if (typeof instruction === 'function') {
      address = instruction(address, url);
      continue;
    }

    parse = instruction[0];
    key = instruction[1];

    if (parse !== parse) {
      url[key] = address;
    } else if ('string' === typeof parse) {
      if (~(index = address.indexOf(parse))) {
        if ('number' === typeof instruction[2]) {
          url[key] = address.slice(0, index);
          address = address.slice(index + instruction[2]);
        } else {
          url[key] = address.slice(index);
          address = address.slice(0, index);
        }
      }
    } else if ((index = parse.exec(address))) {
      url[key] = index[1];
      address = address.slice(0, index.index);
    }

    url[key] = url[key] || (
      relative && instruction[3] ? location[key] || '' : ''
    );

    //
    // Hostname, host and protocol should be lowercased so they can be used to
    // create a proper `origin`.
    //
    if (instruction[4]) url[key] = url[key].toLowerCase();
  }

  //
  // Also parse the supplied query string in to an object. If we're supplied
  // with a custom parser as function use that instead of the default build-in
  // parser.
  //
  if (parser) url.query = parser(url.query);

  //
  // If the URL is relative, resolve the pathname against the base URL.
  //
  if (
      relative
    && location.slashes
    && url.pathname.charAt(0) !== '/'
    && (url.pathname !== '' || location.pathname !== '')
  ) {
    url.pathname = resolve(url.pathname, location.pathname);
  }

  //
  // Default to a / for pathname if none exists. This normalizes the URL
  // to always have a /
  //
  if (url.pathname.charAt(0) !== '/' && isSpecial(url.protocol)) {
    url.pathname = '/' + url.pathname;
  }

  //
  // We should not add port numbers if they are already the default port number
  // for a given protocol. As the host also contains the port number we're going
  // override it with the hostname which contains no port number.
  //
  if (!required(url.port, url.protocol)) {
    url.host = url.hostname;
    url.port = '';
  }

  //
  // Parse down the `auth` for the username and password.
  //
  url.username = url.password = '';
  if (url.auth) {
    instruction = url.auth.split(':');
    url.username = instruction[0] || '';
    url.password = instruction[1] || '';
  }

  url.origin = url.protocol !== 'file:' && isSpecial(url.protocol) && url.host
    ? url.protocol +'//'+ url.host
    : 'null';

  //
  // The href is just the compiled result.
  //
  url.href = url.toString();
}

/**
 * This is convenience method for changing properties in the URL instance to
 * insure that they all propagate correctly.
 *
 * @param {String} part          Property we need to adjust.
 * @param {Mixed} value          The newly assigned value.
 * @param {Boolean|Function} fn  When setting the query, it will be the function
 *                               used to parse the query.
 *                               When setting the protocol, double slash will be
 *                               removed from the final url if it is true.
 * @returns {URL} URL instance for chaining.
 * @public
 */
function set(part, value, fn) {
  var url = this;

  switch (part) {
    case 'query':
      if ('string' === typeof value && value.length) {
        value = (fn || qs.parse)(value);
      }

      url[part] = value;
      break;

    case 'port':
      url[part] = value;

      if (!required(value, url.protocol)) {
        url.host = url.hostname;
        url[part] = '';
      } else if (value) {
        url.host = url.hostname +':'+ value;
      }

      break;

    case 'hostname':
      url[part] = value;

      if (url.port) value += ':'+ url.port;
      url.host = value;
      break;

    case 'host':
      url[part] = value;

      if (/:\d+$/.test(value)) {
        value = value.split(':');
        url.port = value.pop();
        url.hostname = value.join(':');
      } else {
        url.hostname = value;
        url.port = '';
      }

      break;

    case 'protocol':
      url.protocol = value.toLowerCase();
      url.slashes = !fn;
      break;

    case 'pathname':
    case 'hash':
      if (value) {
        var char = part === 'pathname' ? '/' : '#';
        url[part] = value.charAt(0) !== char ? char + value : value;
      } else {
        url[part] = value;
      }
      break;

    default:
      url[part] = value;
  }

  for (var i = 0; i < rules.length; i++) {
    var ins = rules[i];

    if (ins[4]) url[ins[1]] = url[ins[1]].toLowerCase();
  }

  url.origin = url.protocol !== 'file:' && isSpecial(url.protocol) && url.host
    ? url.protocol +'//'+ url.host
    : 'null';

  url.href = url.toString();

  return url;
}

/**
 * Transform the properties back in to a valid and full URL string.
 *
 * @param {Function} stringify Optional query stringify function.
 * @returns {String} Compiled version of the URL.
 * @public
 */
function toString(stringify) {
  if (!stringify || 'function' !== typeof stringify) stringify = qs.stringify;

  var query
    , url = this
    , protocol = url.protocol;

  if (protocol && protocol.charAt(protocol.length - 1) !== ':') protocol += ':';

  var result = protocol + (url.slashes || isSpecial(url.protocol) ? '//' : '');

  if (url.username) {
    result += url.username;
    if (url.password) result += ':'+ url.password;
    result += '@';
  }

  result += url.host + url.pathname;

  query = 'object' === typeof url.query ? stringify(url.query) : url.query;
  if (query) result += '?' !== query.charAt(0) ? '?'+ query : query;

  if (url.hash) result += url.hash;

  return result;
}

Url.prototype = { set: set, toString: toString };

//
// Expose the URL parser and some additional properties that might be useful for
// others or testing.
//
Url.extractProtocol = extractProtocol;
Url.location = lolcation;
Url.trimLeft = trimLeft;
Url.qs = qs;

module.exports = Url;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/util-deprecate/browser.js":
/*!************************************************!*\
  !*** ./node_modules/util-deprecate/browser.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global) {
/**
 * Module exports.
 */

module.exports = deprecate;

/**
 * Mark that a method should not be used.
 * Returns a modified function which warns once by default.
 *
 * If `localStorage.noDeprecation = true` is set, then it is a no-op.
 *
 * If `localStorage.throwDeprecation = true` is set, then deprecated functions
 * will throw an Error when invoked.
 *
 * If `localStorage.traceDeprecation = true` is set, then deprecated functions
 * will invoke `console.trace()` instead of `console.error()`.
 *
 * @param {Function} fn - the function to deprecate
 * @param {String} msg - the string to print to the console when `fn` is invoked
 * @returns {Function} a new "deprecated" version of `fn`
 * @api public
 */

function deprecate (fn, msg) {
  if (config('noDeprecation')) {
    return fn;
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (config('throwDeprecation')) {
        throw new Error(msg);
      } else if (config('traceDeprecation')) {
        console.trace(msg);
      } else {
        console.warn(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
}

/**
 * Checks `localStorage` for boolean values for the given `name`.
 *
 * @param {String} name
 * @returns {Boolean}
 * @api private
 */

function config (name) {
  // accessing global.localStorage can trigger a DOMException in sandboxed iframes
  try {
    if (!global.localStorage) return false;
  } catch (_) {
    return false;
  }
  var val = global.localStorage[name];
  if (null == val) return false;
  return String(val).toLowerCase() === 'true';
}

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ "./node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./node_modules/util/node_modules/inherits/inherits_browser.js":
/*!*********************************************************************!*\
  !*** ./node_modules/util/node_modules/inherits/inherits_browser.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    ctor.prototype = Object.create(superCtor.prototype, {
      constructor: {
        value: ctor,
        enumerable: false,
        writable: true,
        configurable: true
      }
    });
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    var TempCtor = function () {}
    TempCtor.prototype = superCtor.prototype
    ctor.prototype = new TempCtor()
    ctor.prototype.constructor = ctor
  }
}


/***/ }),

/***/ "./node_modules/util/support/isBufferBrowser.js":
/*!******************************************************!*\
  !*** ./node_modules/util/support/isBufferBrowser.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = function isBuffer(arg) {
  return arg && typeof arg === 'object'
    && typeof arg.copy === 'function'
    && typeof arg.fill === 'function'
    && typeof arg.readUInt8 === 'function';
}

/***/ }),

/***/ "./node_modules/util/util.js":
/*!***********************************!*\
  !*** ./node_modules/util/util.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var getOwnPropertyDescriptors = Object.getOwnPropertyDescriptors ||
  function getOwnPropertyDescriptors(obj) {
    var keys = Object.keys(obj);
    var descriptors = {};
    for (var i = 0; i < keys.length; i++) {
      descriptors[keys[i]] = Object.getOwnPropertyDescriptor(obj, keys[i]);
    }
    return descriptors;
  };

var formatRegExp = /%[sdj%]/g;
exports.format = function(f) {
  if (!isString(f)) {
    var objects = [];
    for (var i = 0; i < arguments.length; i++) {
      objects.push(inspect(arguments[i]));
    }
    return objects.join(' ');
  }

  var i = 1;
  var args = arguments;
  var len = args.length;
  var str = String(f).replace(formatRegExp, function(x) {
    if (x === '%%') return '%';
    if (i >= len) return x;
    switch (x) {
      case '%s': return String(args[i++]);
      case '%d': return Number(args[i++]);
      case '%j':
        try {
          return JSON.stringify(args[i++]);
        } catch (_) {
          return '[Circular]';
        }
      default:
        return x;
    }
  });
  for (var x = args[i]; i < len; x = args[++i]) {
    if (isNull(x) || !isObject(x)) {
      str += ' ' + x;
    } else {
      str += ' ' + inspect(x);
    }
  }
  return str;
};


// Mark that a method should not be used.
// Returns a modified function which warns once by default.
// If --no-deprecation is set, then it is a no-op.
exports.deprecate = function(fn, msg) {
  if (typeof process !== 'undefined' && process.noDeprecation === true) {
    return fn;
  }

  // Allow for deprecating things in the process of starting up.
  if (typeof process === 'undefined') {
    return function() {
      return exports.deprecate(fn, msg).apply(this, arguments);
    };
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (process.throwDeprecation) {
        throw new Error(msg);
      } else if (process.traceDeprecation) {
        console.trace(msg);
      } else {
        console.error(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
};


var debugs = {};
var debugEnviron;
exports.debuglog = function(set) {
  if (isUndefined(debugEnviron))
    debugEnviron = process.env.NODE_DEBUG || '';
  set = set.toUpperCase();
  if (!debugs[set]) {
    if (new RegExp('\\b' + set + '\\b', 'i').test(debugEnviron)) {
      var pid = process.pid;
      debugs[set] = function() {
        var msg = exports.format.apply(exports, arguments);
        console.error('%s %d: %s', set, pid, msg);
      };
    } else {
      debugs[set] = function() {};
    }
  }
  return debugs[set];
};


/**
 * Echos the value of a value. Trys to print the value out
 * in the best way possible given the different types.
 *
 * @param {Object} obj The object to print out.
 * @param {Object} opts Optional options object that alters the output.
 */
/* legacy: obj, showHidden, depth, colors*/
function inspect(obj, opts) {
  // default options
  var ctx = {
    seen: [],
    stylize: stylizeNoColor
  };
  // legacy...
  if (arguments.length >= 3) ctx.depth = arguments[2];
  if (arguments.length >= 4) ctx.colors = arguments[3];
  if (isBoolean(opts)) {
    // legacy...
    ctx.showHidden = opts;
  } else if (opts) {
    // got an "options" object
    exports._extend(ctx, opts);
  }
  // set default options
  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;
  if (isUndefined(ctx.depth)) ctx.depth = 2;
  if (isUndefined(ctx.colors)) ctx.colors = false;
  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;
  if (ctx.colors) ctx.stylize = stylizeWithColor;
  return formatValue(ctx, obj, ctx.depth);
}
exports.inspect = inspect;


// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics
inspect.colors = {
  'bold' : [1, 22],
  'italic' : [3, 23],
  'underline' : [4, 24],
  'inverse' : [7, 27],
  'white' : [37, 39],
  'grey' : [90, 39],
  'black' : [30, 39],
  'blue' : [34, 39],
  'cyan' : [36, 39],
  'green' : [32, 39],
  'magenta' : [35, 39],
  'red' : [31, 39],
  'yellow' : [33, 39]
};

// Don't use 'blue' not visible on cmd.exe
inspect.styles = {
  'special': 'cyan',
  'number': 'yellow',
  'boolean': 'yellow',
  'undefined': 'grey',
  'null': 'bold',
  'string': 'green',
  'date': 'magenta',
  // "name": intentionally not styling
  'regexp': 'red'
};


function stylizeWithColor(str, styleType) {
  var style = inspect.styles[styleType];

  if (style) {
    return '\u001b[' + inspect.colors[style][0] + 'm' + str +
           '\u001b[' + inspect.colors[style][1] + 'm';
  } else {
    return str;
  }
}


function stylizeNoColor(str, styleType) {
  return str;
}


function arrayToHash(array) {
  var hash = {};

  array.forEach(function(val, idx) {
    hash[val] = true;
  });

  return hash;
}


function formatValue(ctx, value, recurseTimes) {
  // Provide a hook for user-specified inspect functions.
  // Check that value is an object with an inspect function on it
  if (ctx.customInspect &&
      value &&
      isFunction(value.inspect) &&
      // Filter out the util module, it's inspect function is special
      value.inspect !== exports.inspect &&
      // Also filter out any prototype objects using the circular check.
      !(value.constructor && value.constructor.prototype === value)) {
    var ret = value.inspect(recurseTimes, ctx);
    if (!isString(ret)) {
      ret = formatValue(ctx, ret, recurseTimes);
    }
    return ret;
  }

  // Primitive types cannot have properties
  var primitive = formatPrimitive(ctx, value);
  if (primitive) {
    return primitive;
  }

  // Look up the keys of the object.
  var keys = Object.keys(value);
  var visibleKeys = arrayToHash(keys);

  if (ctx.showHidden) {
    keys = Object.getOwnPropertyNames(value);
  }

  // IE doesn't make error fields non-enumerable
  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx
  if (isError(value)
      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {
    return formatError(value);
  }

  // Some type of object without properties can be shortcutted.
  if (keys.length === 0) {
    if (isFunction(value)) {
      var name = value.name ? ': ' + value.name : '';
      return ctx.stylize('[Function' + name + ']', 'special');
    }
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    }
    if (isDate(value)) {
      return ctx.stylize(Date.prototype.toString.call(value), 'date');
    }
    if (isError(value)) {
      return formatError(value);
    }
  }

  var base = '', array = false, braces = ['{', '}'];

  // Make Array say that they are Array
  if (isArray(value)) {
    array = true;
    braces = ['[', ']'];
  }

  // Make functions say that they are functions
  if (isFunction(value)) {
    var n = value.name ? ': ' + value.name : '';
    base = ' [Function' + n + ']';
  }

  // Make RegExps say that they are RegExps
  if (isRegExp(value)) {
    base = ' ' + RegExp.prototype.toString.call(value);
  }

  // Make dates with properties first say the date
  if (isDate(value)) {
    base = ' ' + Date.prototype.toUTCString.call(value);
  }

  // Make error with message first say the error
  if (isError(value)) {
    base = ' ' + formatError(value);
  }

  if (keys.length === 0 && (!array || value.length == 0)) {
    return braces[0] + base + braces[1];
  }

  if (recurseTimes < 0) {
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    } else {
      return ctx.stylize('[Object]', 'special');
    }
  }

  ctx.seen.push(value);

  var output;
  if (array) {
    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);
  } else {
    output = keys.map(function(key) {
      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);
    });
  }

  ctx.seen.pop();

  return reduceToSingleString(output, base, braces);
}


function formatPrimitive(ctx, value) {
  if (isUndefined(value))
    return ctx.stylize('undefined', 'undefined');
  if (isString(value)) {
    var simple = '\'' + JSON.stringify(value).replace(/^"|"$/g, '')
                                             .replace(/'/g, "\\'")
                                             .replace(/\\"/g, '"') + '\'';
    return ctx.stylize(simple, 'string');
  }
  if (isNumber(value))
    return ctx.stylize('' + value, 'number');
  if (isBoolean(value))
    return ctx.stylize('' + value, 'boolean');
  // For some reason typeof null is "object", so special case here.
  if (isNull(value))
    return ctx.stylize('null', 'null');
}


function formatError(value) {
  return '[' + Error.prototype.toString.call(value) + ']';
}


function formatArray(ctx, value, recurseTimes, visibleKeys, keys) {
  var output = [];
  for (var i = 0, l = value.length; i < l; ++i) {
    if (hasOwnProperty(value, String(i))) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          String(i), true));
    } else {
      output.push('');
    }
  }
  keys.forEach(function(key) {
    if (!key.match(/^\d+$/)) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          key, true));
    }
  });
  return output;
}


function formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {
  var name, str, desc;
  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };
  if (desc.get) {
    if (desc.set) {
      str = ctx.stylize('[Getter/Setter]', 'special');
    } else {
      str = ctx.stylize('[Getter]', 'special');
    }
  } else {
    if (desc.set) {
      str = ctx.stylize('[Setter]', 'special');
    }
  }
  if (!hasOwnProperty(visibleKeys, key)) {
    name = '[' + key + ']';
  }
  if (!str) {
    if (ctx.seen.indexOf(desc.value) < 0) {
      if (isNull(recurseTimes)) {
        str = formatValue(ctx, desc.value, null);
      } else {
        str = formatValue(ctx, desc.value, recurseTimes - 1);
      }
      if (str.indexOf('\n') > -1) {
        if (array) {
          str = str.split('\n').map(function(line) {
            return '  ' + line;
          }).join('\n').substr(2);
        } else {
          str = '\n' + str.split('\n').map(function(line) {
            return '   ' + line;
          }).join('\n');
        }
      }
    } else {
      str = ctx.stylize('[Circular]', 'special');
    }
  }
  if (isUndefined(name)) {
    if (array && key.match(/^\d+$/)) {
      return str;
    }
    name = JSON.stringify('' + key);
    if (name.match(/^"([a-zA-Z_][a-zA-Z_0-9]*)"$/)) {
      name = name.substr(1, name.length - 2);
      name = ctx.stylize(name, 'name');
    } else {
      name = name.replace(/'/g, "\\'")
                 .replace(/\\"/g, '"')
                 .replace(/(^"|"$)/g, "'");
      name = ctx.stylize(name, 'string');
    }
  }

  return name + ': ' + str;
}


function reduceToSingleString(output, base, braces) {
  var numLinesEst = 0;
  var length = output.reduce(function(prev, cur) {
    numLinesEst++;
    if (cur.indexOf('\n') >= 0) numLinesEst++;
    return prev + cur.replace(/\u001b\[\d\d?m/g, '').length + 1;
  }, 0);

  if (length > 60) {
    return braces[0] +
           (base === '' ? '' : base + '\n ') +
           ' ' +
           output.join(',\n  ') +
           ' ' +
           braces[1];
  }

  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];
}


// NOTE: These type checking functions intentionally don't use `instanceof`
// because it is fragile and can be easily faked with `Object.create()`.
function isArray(ar) {
  return Array.isArray(ar);
}
exports.isArray = isArray;

function isBoolean(arg) {
  return typeof arg === 'boolean';
}
exports.isBoolean = isBoolean;

function isNull(arg) {
  return arg === null;
}
exports.isNull = isNull;

function isNullOrUndefined(arg) {
  return arg == null;
}
exports.isNullOrUndefined = isNullOrUndefined;

function isNumber(arg) {
  return typeof arg === 'number';
}
exports.isNumber = isNumber;

function isString(arg) {
  return typeof arg === 'string';
}
exports.isString = isString;

function isSymbol(arg) {
  return typeof arg === 'symbol';
}
exports.isSymbol = isSymbol;

function isUndefined(arg) {
  return arg === void 0;
}
exports.isUndefined = isUndefined;

function isRegExp(re) {
  return isObject(re) && objectToString(re) === '[object RegExp]';
}
exports.isRegExp = isRegExp;

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}
exports.isObject = isObject;

function isDate(d) {
  return isObject(d) && objectToString(d) === '[object Date]';
}
exports.isDate = isDate;

function isError(e) {
  return isObject(e) &&
      (objectToString(e) === '[object Error]' || e instanceof Error);
}
exports.isError = isError;

function isFunction(arg) {
  return typeof arg === 'function';
}
exports.isFunction = isFunction;

function isPrimitive(arg) {
  return arg === null ||
         typeof arg === 'boolean' ||
         typeof arg === 'number' ||
         typeof arg === 'string' ||
         typeof arg === 'symbol' ||  // ES6 symbol
         typeof arg === 'undefined';
}
exports.isPrimitive = isPrimitive;

exports.isBuffer = __webpack_require__(/*! ./support/isBuffer */ "./node_modules/util/support/isBufferBrowser.js");

function objectToString(o) {
  return Object.prototype.toString.call(o);
}


function pad(n) {
  return n < 10 ? '0' + n.toString(10) : n.toString(10);
}


var months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
              'Oct', 'Nov', 'Dec'];

// 26 Feb 16:19:34
function timestamp() {
  var d = new Date();
  var time = [pad(d.getHours()),
              pad(d.getMinutes()),
              pad(d.getSeconds())].join(':');
  return [d.getDate(), months[d.getMonth()], time].join(' ');
}


// log is just a thin wrapper to console.log that prepends a timestamp
exports.log = function() {
  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));
};


/**
 * Inherit the prototype methods from one constructor into another.
 *
 * The Function.prototype.inherits from lang.js rewritten as a standalone
 * function (not on Function.prototype). NOTE: If this file is to be loaded
 * during bootstrapping this function needs to be rewritten using some native
 * functions as prototype setup using normal JavaScript does not work as
 * expected during bootstrapping (see mirror.js in r114903).
 *
 * @param {function} ctor Constructor function which needs to inherit the
 *     prototype.
 * @param {function} superCtor Constructor function to inherit prototype from.
 */
exports.inherits = __webpack_require__(/*! inherits */ "./node_modules/util/node_modules/inherits/inherits_browser.js");

exports._extend = function(origin, add) {
  // Don't do anything if add isn't an object
  if (!add || !isObject(add)) return origin;

  var keys = Object.keys(add);
  var i = keys.length;
  while (i--) {
    origin[keys[i]] = add[keys[i]];
  }
  return origin;
};

function hasOwnProperty(obj, prop) {
  return Object.prototype.hasOwnProperty.call(obj, prop);
}

var kCustomPromisifiedSymbol = typeof Symbol !== 'undefined' ? Symbol('util.promisify.custom') : undefined;

exports.promisify = function promisify(original) {
  if (typeof original !== 'function')
    throw new TypeError('The "original" argument must be of type Function');

  if (kCustomPromisifiedSymbol && original[kCustomPromisifiedSymbol]) {
    var fn = original[kCustomPromisifiedSymbol];
    if (typeof fn !== 'function') {
      throw new TypeError('The "util.promisify.custom" argument must be of type Function');
    }
    Object.defineProperty(fn, kCustomPromisifiedSymbol, {
      value: fn, enumerable: false, writable: false, configurable: true
    });
    return fn;
  }

  function fn() {
    var promiseResolve, promiseReject;
    var promise = new Promise(function (resolve, reject) {
      promiseResolve = resolve;
      promiseReject = reject;
    });

    var args = [];
    for (var i = 0; i < arguments.length; i++) {
      args.push(arguments[i]);
    }
    args.push(function (err, value) {
      if (err) {
        promiseReject(err);
      } else {
        promiseResolve(value);
      }
    });

    try {
      original.apply(this, args);
    } catch (err) {
      promiseReject(err);
    }

    return promise;
  }

  Object.setPrototypeOf(fn, Object.getPrototypeOf(original));

  if (kCustomPromisifiedSymbol) Object.defineProperty(fn, kCustomPromisifiedSymbol, {
    value: fn, enumerable: false, writable: false, configurable: true
  });
  return Object.defineProperties(
    fn,
    getOwnPropertyDescriptors(original)
  );
}

exports.promisify.custom = kCustomPromisifiedSymbol

function callbackifyOnRejected(reason, cb) {
  // `!reason` guard inspired by bluebird (Ref: https://goo.gl/t5IS6M).
  // Because `null` is a special error value in callbacks which means "no error
  // occurred", we error-wrap so the callback consumer can distinguish between
  // "the promise rejected with null" or "the promise fulfilled with undefined".
  if (!reason) {
    var newReason = new Error('Promise was rejected with a falsy value');
    newReason.reason = reason;
    reason = newReason;
  }
  return cb(reason);
}

function callbackify(original) {
  if (typeof original !== 'function') {
    throw new TypeError('The "original" argument must be of type Function');
  }

  // We DO NOT return the promise as it gives the user a false sense that
  // the promise is actually somehow related to the callback's execution
  // and that the callback throwing will reject the promise.
  function callbackified() {
    var args = [];
    for (var i = 0; i < arguments.length; i++) {
      args.push(arguments[i]);
    }

    var maybeCb = args.pop();
    if (typeof maybeCb !== 'function') {
      throw new TypeError('The last argument must be of type Function');
    }
    var self = this;
    var cb = function() {
      return maybeCb.apply(self, arguments);
    };
    // In true node style we process the callback on `nextTick` with all the
    // implications (stack, `uncaughtException`, `async_hooks`)
    original.apply(this, args)
      .then(function(ret) { process.nextTick(cb, null, ret) },
            function(rej) { process.nextTick(callbackifyOnRejected, rej, cb) });
  }

  Object.setPrototypeOf(callbackified, Object.getPrototypeOf(original));
  Object.defineProperties(callbackified,
                          getOwnPropertyDescriptors(original));
  return callbackified;
}
exports.callbackify = callbackify;

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ "./node_modules/process/browser.js")))

/***/ })

}]);
//# sourceMappingURL=live.js.map?id=b373f3b89d51997ebbd3